{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Soha1bklg4uLGEG1f2zuEfeYHnET-izx","authorship_tag":"ABX9TyO5oFyDRSztzBuq0vXx8sXK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install optuna\n","%pip install sparsemax # https://pypi.org/project/sparsemax/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Tc3NgvLqeox8","executionInfo":{"status":"ok","timestamp":1741163760352,"user_tz":-60,"elapsed":119677,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"dd38e851-d86c-4d07-87c2-1f1bc7ff878f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n","Collecting sparsemax\n","  Downloading sparsemax-0.1.9-py2.py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from sparsemax) (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->sparsemax)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sparsemax)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sparsemax)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sparsemax)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sparsemax)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sparsemax)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->sparsemax) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->sparsemax) (3.0.2)\n","Downloading sparsemax-0.1.9-py2.py3-none-any.whl (5.5 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sparsemax\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sparsemax-0.1.9\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sparsemax import Sparsemax\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_openml\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from scipy.stats import spearmanr\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import optuna\n","import json\n","import os\n","from urllib.request import urlretrieve\n","import gzip\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","sparsemax = Sparsemax(dim=-1)\n","\n","class TabularDataset(Dataset):\n","    \"\"\"Dataset for tabular data with continuous features\"\"\"\n","    def __init__(self, X, y=None):\n","        # Continuous features\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","\n","        # Target\n","        if y is not None:\n","            self.y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n","        else:\n","            self.y = None\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.X[idx], self.y[idx]\n","        else:\n","            return self.X[idx]\n","\n","'''\n","The code below has been adapted from the original codebase.\n","\n","For the implementation of the FT Transformer, please check out this repository: https://github.com/yandex-research/rtdl-revisiting-models\n","\n","For the implementation of the Piecewise Linear Embedding, please check out: https://github.com/yandex-research/rtdl-num-embeddings\n","'''\n","\n","\n","class LinearEmbedding(nn.Module):\n","    \"\"\"Linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token):\n","        super().__init__()\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(1, d_token) for _ in range(num_features)\n","        ])\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_cont_features)\n","        batch_size = x.shape[0]\n","        num_features = x.shape[1]\n","\n","        # Embed each continuous feature\n","        embedded = torch.zeros((batch_size, num_features, self.embeddings[0].out_features),\n","                              device=x.device)\n","\n","        for i in range(num_features):\n","            embedded[:, i] = self.embeddings[i](x[:, i].unsqueeze(-1)).squeeze(-1)\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","class PiecewiseLinearEmbedding(nn.Module):\n","    \"\"\"Piecewise linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token, num_bins=20):\n","        super().__init__()\n","        self.num_features = num_features\n","        self.d_token = d_token\n","        self.num_bins = num_bins\n","\n","        # Create embeddings for each feature\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(num_bins, d_token) for _ in range(num_features)\n","        ])\n","\n","        # Create parameters for bin boundaries (learnable)\n","        self.bin_boundaries = nn.Parameter(torch.randn(num_features, num_bins-1))\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        batch_size = x.shape[0]\n","\n","        # Output will contain embedded tokens for each feature\n","        embedded = torch.zeros((batch_size, self.num_features, self.d_token), device=x.device)\n","\n","        for i in range(self.num_features):\n","            # Get feature values for current feature\n","            feature_values = x[:, i].unsqueeze(1)  # (batch_size, 1)\n","\n","            # Get sorted boundaries for this feature\n","            boundaries = torch.sort(self.bin_boundaries[i]).values  # (num_bins-1)\n","\n","            # Calculate bin activations using cumulative distribution\n","            # Start with all in the first bin\n","            bin_activations = torch.ones((batch_size, self.num_bins), device=x.device)\n","\n","            # Update bin activations based on feature values and boundaries\n","            for j in range(self.num_bins-1):\n","                boundary = boundaries[j]\n","                # Calculate contribution to bins based on boundary comparison\n","                condition = feature_values > boundary\n","                # Move activations to next bin when condition is true\n","                bin_activations[:, j+1:] = torch.where(\n","                    condition.expand(-1, self.num_bins-j-1),\n","                    bin_activations[:, j:self.num_bins-1],\n","                    bin_activations[:, j+1:]\n","                )\n","                bin_activations[:, j] = torch.where(\n","                    condition.squeeze(1),\n","                    0.0,\n","                    bin_activations[:, j]\n","                )\n","\n","            # Apply linear transformation to get embeddings\n","            feature_embedding = self.embeddings[i](bin_activations)  # (batch_size, d_token)\n","            embedded[:, i] = feature_embedding\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","# Custom attention module to capture attention weights\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply softmax to get attention weights\n","        attention_weights = F.softmax(scores, dim=-1)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","# Custom transformer layer to capture attention weights\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=50):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            TransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for binary classification\n","        self.output_layer = nn.Linear(d_token, 1)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits) - no sigmoid here for BCEWithLogitsLoss\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","# Sparse attention variants\n","class sparseMultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply sparsemax to get attention weights\n","        attention_weights = sparsemax(scores)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","class sparseTransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = sparseMultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class sparseFTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=50):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            sparseTransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for classification\n","        self.output_layer = nn.Linear(d_token, 1)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","def calculate_pfi(model, X_val, y_val, num_permutations=5):\n","    \"\"\"Calculate Permutation Feature Importance (PFI) for classification\"\"\"\n","    # Convert to PyTorch tensors\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1).to(device)\n","\n","    # Get baseline performance\n","    model.eval()\n","    with torch.no_grad():\n","        baseline_preds = torch.sigmoid(model(X))\n","        baseline_loss = F.binary_cross_entropy(baseline_preds, y).item()\n","        baseline_preds_binary = (baseline_preds > 0.5).float()\n","        baseline_accuracy = (baseline_preds_binary == y).float().mean().item()\n","\n","    # Calculate importance for each feature\n","    importances = []\n","\n","    for feat_idx in range(X.shape[1]):\n","        accuracies = []\n","\n","        for _ in range(num_permutations):\n","            # Create a permuted copy of the data\n","            X_permuted = X.clone()\n","\n","            # Permute the feature\n","            perm_idx = torch.randperm(X.shape[0])\n","            X_permuted[:, feat_idx] = X_permuted[perm_idx, feat_idx]\n","\n","            # Calculate loss with permuted feature\n","            with torch.no_grad():\n","                perm_preds = torch.sigmoid(model(X_permuted))\n","                perm_preds_binary = (perm_preds > 0.5).float()\n","                perm_accuracy = (perm_preds_binary == y).float().mean().item()\n","\n","            # Feature importance is the decrease in accuracy (or increase in loss)\n","            # We'll use accuracy drop as it's more interpretable for classification\n","            accuracies.append(baseline_accuracy - perm_accuracy)\n","\n","        # Average over permutations (higher = more important)\n","        importances.append(np.mean(accuracies))\n","\n","    return np.array(importances)\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=100, early_stopping=16):\n","    \"\"\"Train the model with early stopping\"\"\"\n","    model.to(device)\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","    best_state = None\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            # Calculate accuracy\n","            predictions = (torch.sigmoid(outputs) > 0.5).float()\n","            train_correct += (predictions == y_batch).sum().item()\n","            train_total += y_batch.size(0)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","        val_preds = []\n","        val_targets = []\n","\n","        with torch.no_grad():\n","            for X_batch, y_batch in val_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                val_loss += loss.item()\n","\n","                # Calculate accuracy\n","                predictions = (torch.sigmoid(outputs) > 0.5).float()\n","                val_correct += (predictions == y_batch).sum().item()\n","                val_total += y_batch.size(0)\n","\n","                # Store predictions and targets for metrics\n","                val_preds.append(torch.sigmoid(outputs).cpu())\n","                val_targets.append(y_batch.cpu())\n","\n","        train_loss /= len(train_loader)\n","        train_accuracy = train_correct / train_total\n","        val_loss /= len(val_loader)\n","        val_accuracy = val_correct / val_total\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n","              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","            # Save best model state dict\n","            best_state = model.state_dict()\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= early_stopping:\n","                print(f\"Early stopping at epoch {epoch+1}\")\n","                break\n","\n","    # Load best model\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test, device):\n","    \"\"\"Evaluate model performance for classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    X = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1).to(device)\n","\n","    with torch.no_grad():\n","        logits = model(X)\n","        y_pred_proba = torch.sigmoid(logits).cpu().numpy()\n","        y_pred = (y_pred_proba > 0.5).astype(int)\n","\n","    y_test = y_test.reshape(-1, 1)\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    auc = roc_auc_score(y_test, y_pred_proba)\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","\n","    print(f\"Test Accuracy: {accuracy:.4f}\")\n","    print(f\"Test Precision: {precision:.4f}\")\n","    print(f\"Test Recall: {recall:.4f}\")\n","    print(f\"Test F1 Score: {f1:.4f}\")\n","    print(f\"Test AUC: {auc:.4f}\")\n","    print(f\"Confusion Matrix:\\n{cm}\")\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'auc': auc,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","def analyze_pfi_attention_correlation(model, X_val, y_val, feature_names, device):\n","    \"\"\"Analyze correlation between PFI and attention scores for classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    # Get attention scores\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        _ = model(X)  # Forward pass to compute attention\n","        attention_scores = model.get_cls_attention().cpu().numpy()\n","\n","    # Average attention scores across samples\n","    avg_attention = attention_scores.mean(axis=0)\n","\n","    # Calculate PFI\n","    pfi_scores = calculate_pfi(model, X_val, y_val)\n","\n","    # Calculate Spearman rank correlation\n","    correlation, p_value = spearmanr(pfi_scores, avg_attention)\n","\n","    print(f\"Spearman Rank Correlation: {correlation:.4f} (p-value: {p_value:.4f})\")\n","\n","    # Create a visualization\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    # Create a scatter plot\n","    scatter = ax.scatter(pfi_scores, avg_attention, alpha=0.7)\n","\n","    # Add feature labels\n","    for i, name in enumerate(feature_names):\n","        ax.annotate(name, (pfi_scores[i], avg_attention[i]),\n","                   textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8)\n","\n","    # Add best fit line\n","    z = np.polyfit(pfi_scores, avg_attention, 1)\n","    p = np.poly1d(z)\n","    ax.plot(np.sort(pfi_scores), p(np.sort(pfi_scores)), \"r--\", alpha=0.7)\n","\n","    # Add correlation information\n","    ax.text(0.05, 0.95, f\"Spearman ρ: {correlation:.4f}\\np-value: {p_value:.4f}\",\n","            transform=ax.transAxes, verticalalignment='top',\n","            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n","\n","    ax.set_xlabel('Permutation Feature Importance')\n","    ax.set_ylabel('CLS Token Attention Score')\n","    ax.set_title('PFI vs CLS Token Attention Correlation')\n","\n","    plt.tight_layout()\n","    plt.savefig('pfi_attention_correlation_higgs.png')\n","    plt.close()\n","\n","    # Return results\n","    results = {\n","        'correlation': correlation,\n","        'p_value': p_value,\n","        'pfi_scores': pfi_scores.tolist(),\n","        'attention_scores': avg_attention.tolist(),\n","        'feature_names': feature_names\n","    }\n","\n","    return results\n","\n","def load_higgs_dataset(sample_size=None):\n","    \"\"\"\n","    Load HIGGS dataset from OpenML with NaN accommodation using median imputation\n","\n","    Parameters:\n","    - sample_size (int, optional): Number of examples to load. If None, loads all examples.\n","\n","    Returns:\n","    - X_train, X_val, X_test, y_train, y_val, y_test, feature_names\n","    \"\"\"\n","    print(\"Fetching HIGGS dataset from OpenML...\")\n","    data = fetch_openml(data_id=23512, as_frame=False, parser='pandas')\n","    X = data.data\n","    y = data.target.astype(np.int32)  # Convert target to integer type\n","    feature_names = data.feature_names\n","\n","    # Subsample if needed\n","    if sample_size is not None:\n","        X, _, y, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=42)\n","\n","    # Split data into training, validation, and test sets\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","    # Impute missing values using median imputation on training data\n","    imputer = SimpleImputer(strategy='median')\n","    X_train = imputer.fit_transform(X_train)\n","    X_val = imputer.transform(X_val)\n","    X_test = imputer.transform(X_test)\n","\n","    # Standardize features\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","    X_test = scaler.transform(X_test)\n","\n","    print(\"Dataset shapes:\")\n","    print(f\"  X_train: {X_train.shape}\")\n","    print(f\"  X_val: {X_val.shape}\")\n","    print(f\"  X_test: {X_test.shape}\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test, feature_names\n","\n","def tune_hyperparameters(X_train, y_train, X_val, y_val, embedding_type='linear', n_trials=20, sparse=False):\n","    \"\"\"Tune hyperparameters using Optuna\"\"\"\n","\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=1024)\n","\n","    num_features = X_train.shape[1]\n","\n","    def objective(trial):\n","        # Define hyperparameters to tune\n","        d_token = trial.suggest_int('d_token', 32, 128)\n","        num_heads = trial.suggest_int('num_heads', 2, 8)\n","        num_layers = trial.suggest_int('num_layers', 1, 3)\n","        d_ffn = trial.suggest_int('d_ffn', 64, 256)\n","        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n","        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n","        n_bins = trial.suggest_int('n_bins', 2, 10)\n","\n","        # Ensure d_token is divisible by num_heads\n","        d_token = (d_token // num_heads) * num_heads\n","\n","        # Create model with trial hyperparameters\n","        if not sparse:\n","            model = FTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","        else:\n","            model = sparseFTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","\n","        # Define criterion and optimizer for binary classification\n","        criterion = nn.BCEWithLogitsLoss()\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","        # Train for a few epochs\n","        model.to(device)\n","        best_val_loss = float('inf')\n","\n","        patience = 5\n","        patience_counter = 0\n","        num_epochs = 20\n","\n","        # Short training loop for hyperparameter search\n","        for epoch in range(num_epochs):\n","            # Training\n","            model.train()\n","            for X_batch, y_batch in train_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                loss.backward()\n","                optimizer.step()\n","\n","            # Validation\n","            model.eval()\n","            val_loss = 0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for X_batch, y_batch in val_loader:\n","                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","                    outputs = model(X_batch)\n","                    loss = criterion(outputs, y_batch)\n","                    val_loss += loss.item()\n","\n","                    # Calculate accuracy\n","                    predictions = (torch.sigmoid(outputs) > 0.5).float()\n","                    val_correct += (predictions == y_batch).sum().item()\n","                    val_total += y_batch.size(0)\n","\n","            val_loss /= len(val_loader)\n","            val_accuracy = val_correct / val_total\n","\n","            # Update best validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter > patience:\n","                    break\n","\n","            trial.report(val_loss, epoch)\n","\n","            if trial.should_prune():\n","                raise optuna.TrialPruned()\n","\n","        return best_val_loss\n","\n","    # Create Optuna study\n","    study = optuna.create_study(\n","        direction=\"minimize\",\n","        pruner=optuna.pruners.MedianPruner( # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n","            n_startup_trials=5,\n","            n_warmup_steps=10,\n","            interval_steps=2\n","        )\n","    )\n","    study.optimize(objective, n_trials=n_trials, timeout=1800)\n","\n","    # Print best parameters\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","    print(f\"  Value (validation loss): {trial.value:.4f}\")\n","    print(\"  Params:\")\n","    for key, value in trial.params.items():\n","        print(f\"    {key}: {value}\")\n","\n","    # Return best parameters\n","    return trial.params\n","\n","def train_with_best_params(X_train, y_train, X_val, y_val, X_test, y_test, best_params,\n","                         embedding_type='linear', sparse=False):\n","    \"\"\"Train a model with the best hyperparameters\"\"\"\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=1024)\n","\n","    # Ensure d_token is divisible by num_heads\n","    d_token = (best_params['d_token'] // best_params['num_heads']) * best_params['num_heads']\n","\n","    # Create model with best hyperparameters\n","    if not sparse:\n","        model = FTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","    else:\n","        model = sparseFTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","\n","    # Define criterion for binary classification\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=1e-5)\n","\n","    # Train the model with early stopping\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        device=device,\n","        epochs=100\n","    )\n","\n","    # Evaluate on test set\n","    results = evaluate_model(model, X_test, y_test, device)\n","\n","    return model, results\n","\n","def visualize_all_models(results, feature_names):\n","    \"\"\"Create a comprehensive visualization comparing all models\"\"\"\n","\n","    # Create a figure with 2x2 subplots\n","    fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n","\n","    # Plot performance metrics\n","    models = list(results.keys())\n","    acc_values = [results[model]['accuracy'] for model in models]\n","    f1_values = [results[model]['f1'] for model in models]\n","\n","    # Accuracy comparison\n","    axs[0, 0].bar(models, acc_values)\n","    axs[0, 0].set_title('Accuracy Comparison (HIGGS)')\n","    axs[0, 0].set_ylabel('Accuracy')\n","    axs[0, 0].tick_params(axis='x', rotation=45)\n","\n","    # F1 comparison\n","    axs[0, 1].bar(models, f1_values)\n","    axs[0, 1].set_title('F1 Score Comparison (HIGGS)')\n","    axs[0, 1].set_ylabel('F1 Score')\n","    axs[0, 1].tick_params(axis='x', rotation=45)\n","\n","    # Correlation comparison\n","    correlations = [results[model]['correlation_analysis']['correlation'] for model in models]\n","    p_values = [results[model]['correlation_analysis']['p_value'] for model in models]\n","\n","    axs[1, 0].bar(models, correlations)\n","    axs[1, 0].set_title('PFI-Attention Correlation Comparison (HIGGS)')\n","    axs[1, 0].set_ylabel('Spearman Correlation')\n","    axs[1, 0].tick_params(axis='x', rotation=45)\n","\n","    # Feature importance comparison across models (top 3 features)\n","    axs[1, 1].axis('off')  # Turn off the axis for the text summary\n","\n","    summary_text = \"Feature Importance Summary:\\n\\n\"\n","\n","    for model in models:\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Get top 3 features by PFI\n","        pfi_top_indices = np.argsort(-pfi_scores)[:3]\n","        pfi_top_features = [feature_names[i] for i in pfi_top_indices]\n","\n","        # Get top 3 features by attention\n","        attn_top_indices = np.argsort(-attn_scores)[:3]\n","        attn_top_features = [feature_names[i] for i in attn_top_indices]\n","\n","        summary_text += f\"{model}:\\n\"\n","        summary_text += f\"  Top PFI features: {', '.join(pfi_top_features)}\\n\"\n","        summary_text += f\"  Top attention features: {', '.join(attn_top_features)}\\n\\n\"\n","\n","    axs[1, 1].text(0.05, 0.95, summary_text, transform=axs[1, 1].transAxes,\n","                 verticalalignment='top', fontsize=12)\n","\n","    plt.tight_layout()\n","    plt.savefig('model_comparison_higgs.png')\n","    plt.close()\n","\n","    # Create additional visualization for feature importance comparison\n","    # For top 10 features only to avoid cluttering\n","    num_top_features = min(10, len(feature_names))\n","    fig, axs = plt.subplots(len(models), 1, figsize=(14, 5 * len(models)))\n","\n","    if len(models) == 1:\n","        axs = [axs]  # Convert to list if there's only one model\n","\n","    for i, model in enumerate(models):\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Sort features by PFI for visualization (top 10)\n","        sorted_indices = np.argsort(-pfi_scores)[:num_top_features]\n","        sorted_features = [feature_names[j] for j in sorted_indices]\n","        sorted_pfi = [pfi_scores[j] for j in sorted_indices]\n","        sorted_attn = [attn_scores[j] for j in sorted_indices]\n","\n","        x = np.arange(len(sorted_features))\n","        width = 0.35\n","\n","        axs[i].bar(x - width/2, sorted_pfi, width, label='PFI')\n","        axs[i].bar(x + width/2, sorted_attn, width, label='Attention')\n","\n","        axs[i].set_title(f'Feature Importance (HIGGS): {model}')\n","        axs[i].set_ylabel('Importance Score')\n","        axs[i].set_xticks(x)\n","        axs[i].set_xticklabels(sorted_features, rotation=45, ha='right')\n","        axs[i].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig('feature_importance_comparison_higgs.png')\n","    plt.close()\n","\n","    print(\"\\nVisualizations saved as 'model_comparison_higgs.png' and 'feature_importance_comparison_higgs.png'\")\n","\n","def save_model(model, filename):\n","    torch.save(model.state_dict(), filename)\n","    print(f\"Model saved as {filename}\")\n","\n","def save_results(results, filename):\n","    # Convert numpy arrays to lists for json serialization\n","    for model in results:\n","        if 'correlation_analysis' in results[model]:\n","            if isinstance(results[model]['correlation_analysis']['pfi_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['pfi_scores'] = results[model]['correlation_analysis']['pfi_scores'].tolist()\n","            if isinstance(results[model]['correlation_analysis']['attention_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['attention_scores'] = results[model]['correlation_analysis']['attention_scores'].tolist()\n","\n","    with open(filename, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    print(f\"Results saved as {filename}\")\n","\n","def main_with_tuning():\n","    \"\"\"Main function to run the HIGGS dataset experiments\"\"\"\n","    # Set random seed for reproducibility\n","    torch.manual_seed(42)\n","    np.random.seed(42)\n","\n","    # Set device\n","    print(f\"Using device: {device}\")\n","\n","    # Load HIGGS dataset (with a sample for faster processing)\n","    # Note: For full evaluation, remove the sample_size parameter or set it to a larger value\n","    X_train, X_val, X_test, y_train, y_val, y_test, feature_names = load_higgs_dataset()\n","\n","    models = {}\n","    results = {}\n","\n","    # Tune hyperparameters for Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\")\n","    linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='linear',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Linear Embedding (Tuned) ===\")\n","    ft_linear_tuned, linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=linear_best_params,\n","        embedding_type='linear'\n","    )\n","\n","    save_model(ft_linear_tuned, 'ft_linear_tuned_higgs.pth')\n","\n","    models['ft_linear_tuned'] = ft_linear_tuned\n","    results['ft_linear_tuned'] = linear_results\n","\n","    # Analyze PFI and attention correlation for tuned linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\")\n","    linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_linear_tuned']['correlation_analysis'] = linear_tuned_correlation\n","\n","    # Tune hyperparameters for Piecewise Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\")\n","    piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='piecewise',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Piecewise Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    ft_piecewise_tuned, piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=piecewise_best_params,\n","        embedding_type='piecewise'\n","    )\n","\n","    save_model(ft_piecewise_tuned, 'ft_piecewise_tuned_higgs.pth')\n","\n","    models['ft_piecewise_tuned'] = ft_piecewise_tuned\n","    results['ft_piecewise_tuned'] = piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\")\n","    piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_piecewise_tuned']['correlation_analysis'] = piecewise_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\")\n","    sparse_linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='linear',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Linear Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\")\n","    sparse_ft_linear_tuned, sparse_linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_linear_best_params,\n","        embedding_type='linear',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_linear_tuned, 'sparse_ft_linear_tuned_higgs.pth')\n","\n","    models['sparse_ft_linear_tuned'] = sparse_ft_linear_tuned\n","    results['sparse_ft_linear_tuned'] = sparse_linear_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\")\n","    sparse_linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_linear_tuned']['correlation_analysis'] = sparse_linear_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\")\n","    sparse_piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='piecewise',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    sparse_ft_piecewise_tuned, sparse_piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_piecewise_best_params,\n","        embedding_type='piecewise',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_piecewise_tuned, 'sparse_ft_piecewise_tuned_higgs.pth')\n","\n","    models['sparse_ft_piecewise_tuned'] = sparse_ft_piecewise_tuned\n","    results['sparse_ft_piecewise_tuned'] = sparse_piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\")\n","    sparse_piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_piecewise_tuned']['correlation_analysis'] = sparse_piecewise_tuned_correlation\n","\n","    # Compare the results\n","    print(\"\\n=== Comparison of Tuned Models ===\")\n","    print(f\"FT Transformer (Linear Tuned): Accuracy={results['ft_linear_tuned']['accuracy']:.4f}, F1={results['ft_linear_tuned']['f1']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): Accuracy={results['ft_piecewise_tuned']['accuracy']:.4f}, F1={results['ft_piecewise_tuned']['f1']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): Accuracy={results['sparse_ft_linear_tuned']['accuracy']:.4f}, F1={results['sparse_ft_linear_tuned']['f1']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): Accuracy={results['sparse_ft_piecewise_tuned']['accuracy']:.4f}, F1={results['sparse_ft_piecewise_tuned']['f1']:.4f}\")\n","\n","    print(\"\\n=== Comparison of PFI-Attention Correlations (Tuned Models) ===\")\n","    print(f\"FT Transformer (Linear Tuned): ρ={linear_tuned_correlation['correlation']:.4f}, p-value={linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): ρ={piecewise_tuned_correlation['correlation']:.4f}, p-value={piecewise_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): ρ={sparse_linear_tuned_correlation['correlation']:.4f}, p-value={sparse_linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): ρ={sparse_piecewise_tuned_correlation['correlation']:.4f}, p-value={sparse_piecewise_tuned_correlation['p_value']:.4f}\")\n","\n","    # Create visualization comparing all models\n","    visualize_all_models(\n","        results=results,\n","        feature_names=feature_names\n","    )\n","\n","    save_results(results, 'results_higgs.json')\n","\n","    return models, results\n","\n","if __name__ == \"__main__\":\n","    main_with_tuning()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoLqkxBXcJLr","executionInfo":{"status":"ok","timestamp":1741172594946,"user_tz":-60,"elapsed":8704189,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"51d1ec18-5e89-44e3-9928-08f83cbf0f93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Fetching HIGGS dataset from OpenML...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 08:38:26,428] A new study created in memory with name: no-name-8094a943-496e-4889-9e05-142f39f067b7\n"]},{"output_type":"stream","name":"stdout","text":["Dataset shapes:\n","  X_train: (68635, 28)\n","  X_val: (14707, 28)\n","  X_test: (14708, 28)\n","\n","=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 08:38:59,290] Trial 0 finished with value: 0.5924715479214986 and parameters: {'d_token': 88, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 212, 'lr': 0.005346039033725334, 'dropout': 0.3866816361373727, 'n_bins': 6}. Best is trial 0 with value: 0.5924715479214986.\n","[I 2025-03-05 08:39:44,166] Trial 1 finished with value: 0.5540927529335022 and parameters: {'d_token': 82, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 131, 'lr': 0.0006704321810840772, 'dropout': 0.4052291761063001, 'n_bins': 4}. Best is trial 1 with value: 0.5540927529335022.\n","[I 2025-03-05 08:40:16,214] Trial 2 finished with value: 0.5713818271954855 and parameters: {'d_token': 125, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 84, 'lr': 0.002894802233548115, 'dropout': 0.1550222880089318, 'n_bins': 4}. Best is trial 1 with value: 0.5540927529335022.\n","[I 2025-03-05 08:41:30,099] Trial 3 finished with value: 0.5407290975252788 and parameters: {'d_token': 88, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 111, 'lr': 0.001137980004135959, 'dropout': 0.13830479229905945, 'n_bins': 6}. Best is trial 3 with value: 0.5407290975252788.\n","[I 2025-03-05 08:42:23,736] Trial 4 finished with value: 0.5441858490308126 and parameters: {'d_token': 84, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 84, 'lr': 0.001968492860518005, 'dropout': 0.10592637430797086, 'n_bins': 8}. Best is trial 3 with value: 0.5407290975252788.\n","[I 2025-03-05 08:43:10,454] Trial 5 finished with value: 0.543361779054006 and parameters: {'d_token': 93, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 189, 'lr': 0.0008911582367143289, 'dropout': 0.16271893062484216, 'n_bins': 6}. Best is trial 3 with value: 0.5407290975252788.\n","[I 2025-03-05 08:43:35,767] Trial 6 pruned. \n","[I 2025-03-05 08:44:32,148] Trial 7 finished with value: 0.5389148592948914 and parameters: {'d_token': 59, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 225, 'lr': 0.0025902194870565556, 'dropout': 0.06257303714730866, 'n_bins': 4}. Best is trial 7 with value: 0.5389148592948914.\n","[I 2025-03-05 08:45:32,270] Trial 8 finished with value: 0.5396527528762818 and parameters: {'d_token': 36, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 158, 'lr': 0.0009187524084503494, 'dropout': 0.13877240842047922, 'n_bins': 8}. Best is trial 7 with value: 0.5389148592948914.\n","[I 2025-03-05 08:46:21,725] Trial 9 pruned. \n","[I 2025-03-05 08:46:50,903] Trial 10 pruned. \n","[I 2025-03-05 08:47:24,687] Trial 11 pruned. \n","[I 2025-03-05 08:48:07,121] Trial 12 finished with value: 0.691150716940562 and parameters: {'d_token': 59, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 254, 'lr': 0.008373069832507681, 'dropout': 0.009358964458973454, 'n_bins': 9}. Best is trial 7 with value: 0.5389148592948914.\n","[I 2025-03-05 08:48:35,427] Trial 13 pruned. \n","[I 2025-03-05 08:49:17,018] Trial 14 pruned. \n","[I 2025-03-05 08:49:46,357] Trial 15 pruned. \n","[I 2025-03-05 08:50:22,131] Trial 16 pruned. \n","[I 2025-03-05 08:50:47,352] Trial 17 pruned. \n","[I 2025-03-05 08:51:23,447] Trial 18 pruned. \n","[I 2025-03-05 08:51:56,513] Trial 19 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.5389\n","  Params:\n","    d_token: 59\n","    num_heads: 5\n","    num_layers: 2\n","    d_ffn: 225\n","    lr: 0.0025902194870565556\n","    dropout: 0.06257303714730866\n","    n_bins: 4\n","\n","=== Training FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.6353, Train Acc: 0.6267, Val Loss: 0.5747, Val Acc: 0.6969\n","Epoch 2/100, Train Loss: 0.5648, Train Acc: 0.7019, Val Loss: 0.5661, Val Acc: 0.6995\n","Epoch 3/100, Train Loss: 0.5564, Train Acc: 0.7101, Val Loss: 0.5596, Val Acc: 0.7080\n","Epoch 4/100, Train Loss: 0.5506, Train Acc: 0.7114, Val Loss: 0.5572, Val Acc: 0.7071\n","Epoch 5/100, Train Loss: 0.5473, Train Acc: 0.7159, Val Loss: 0.5564, Val Acc: 0.7094\n","Epoch 6/100, Train Loss: 0.5423, Train Acc: 0.7176, Val Loss: 0.5601, Val Acc: 0.7025\n","Epoch 7/100, Train Loss: 0.5417, Train Acc: 0.7178, Val Loss: 0.5574, Val Acc: 0.7063\n","Epoch 8/100, Train Loss: 0.5400, Train Acc: 0.7200, Val Loss: 0.5520, Val Acc: 0.7089\n","Epoch 9/100, Train Loss: 0.5364, Train Acc: 0.7233, Val Loss: 0.5568, Val Acc: 0.7092\n","Epoch 10/100, Train Loss: 0.5364, Train Acc: 0.7240, Val Loss: 0.5500, Val Acc: 0.7156\n","Epoch 11/100, Train Loss: 0.5323, Train Acc: 0.7258, Val Loss: 0.5583, Val Acc: 0.7088\n","Epoch 12/100, Train Loss: 0.5315, Train Acc: 0.7281, Val Loss: 0.5514, Val Acc: 0.7131\n","Epoch 13/100, Train Loss: 0.5321, Train Acc: 0.7263, Val Loss: 0.5491, Val Acc: 0.7153\n","Epoch 14/100, Train Loss: 0.5320, Train Acc: 0.7261, Val Loss: 0.5472, Val Acc: 0.7201\n","Epoch 15/100, Train Loss: 0.5287, Train Acc: 0.7291, Val Loss: 0.5433, Val Acc: 0.7190\n","Epoch 16/100, Train Loss: 0.5267, Train Acc: 0.7285, Val Loss: 0.5514, Val Acc: 0.7141\n","Epoch 17/100, Train Loss: 0.5258, Train Acc: 0.7331, Val Loss: 0.5497, Val Acc: 0.7153\n","Epoch 18/100, Train Loss: 0.5240, Train Acc: 0.7308, Val Loss: 0.5536, Val Acc: 0.7150\n","Epoch 19/100, Train Loss: 0.5212, Train Acc: 0.7338, Val Loss: 0.5628, Val Acc: 0.7080\n","Epoch 20/100, Train Loss: 0.5207, Train Acc: 0.7337, Val Loss: 0.5484, Val Acc: 0.7220\n","Epoch 21/100, Train Loss: 0.5186, Train Acc: 0.7357, Val Loss: 0.5510, Val Acc: 0.7154\n","Epoch 22/100, Train Loss: 0.5197, Train Acc: 0.7348, Val Loss: 0.5487, Val Acc: 0.7186\n","Epoch 23/100, Train Loss: 0.5183, Train Acc: 0.7362, Val Loss: 0.5453, Val Acc: 0.7158\n","Epoch 24/100, Train Loss: 0.5180, Train Acc: 0.7371, Val Loss: 0.5425, Val Acc: 0.7180\n","Epoch 25/100, Train Loss: 0.5167, Train Acc: 0.7370, Val Loss: 0.5474, Val Acc: 0.7167\n","Epoch 26/100, Train Loss: 0.5144, Train Acc: 0.7396, Val Loss: 0.5493, Val Acc: 0.7175\n","Epoch 27/100, Train Loss: 0.5138, Train Acc: 0.7399, Val Loss: 0.5560, Val Acc: 0.7140\n","Epoch 28/100, Train Loss: 0.5140, Train Acc: 0.7386, Val Loss: 0.5525, Val Acc: 0.7192\n","Epoch 29/100, Train Loss: 0.5105, Train Acc: 0.7430, Val Loss: 0.5641, Val Acc: 0.7097\n","Epoch 30/100, Train Loss: 0.5096, Train Acc: 0.7429, Val Loss: 0.5586, Val Acc: 0.7120\n","Epoch 31/100, Train Loss: 0.5078, Train Acc: 0.7443, Val Loss: 0.5540, Val Acc: 0.7165\n","Epoch 32/100, Train Loss: 0.5084, Train Acc: 0.7457, Val Loss: 0.5522, Val Acc: 0.7176\n","Epoch 33/100, Train Loss: 0.5050, Train Acc: 0.7456, Val Loss: 0.5567, Val Acc: 0.7127\n","Epoch 34/100, Train Loss: 0.5034, Train Acc: 0.7468, Val Loss: 0.5523, Val Acc: 0.7160\n","Epoch 35/100, Train Loss: 0.5054, Train Acc: 0.7449, Val Loss: 0.5601, Val Acc: 0.7106\n","Epoch 36/100, Train Loss: 0.5031, Train Acc: 0.7470, Val Loss: 0.5583, Val Acc: 0.7139\n","Epoch 37/100, Train Loss: 0.5012, Train Acc: 0.7466, Val Loss: 0.5539, Val Acc: 0.7173\n","Epoch 38/100, Train Loss: 0.4988, Train Acc: 0.7501, Val Loss: 0.5534, Val Acc: 0.7129\n","Epoch 39/100, Train Loss: 0.5002, Train Acc: 0.7512, Val Loss: 0.5544, Val Acc: 0.7119\n","Epoch 40/100, Train Loss: 0.5024, Train Acc: 0.7477, Val Loss: 0.5610, Val Acc: 0.7148\n","Early stopping at epoch 40\n","Test Accuracy: 0.7244\n","Test Precision: 0.7482\n","Test Recall: 0.7199\n","Test F1 Score: 0.7338\n","Test AUC: 0.8011\n","Confusion Matrix:\n","[[5069 1880]\n"," [2173 5586]]\n","Model saved as ft_linear_tuned_higgs.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.7515 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 08:54:30,709] A new study created in memory with name: no-name-f579968f-c468-4ae5-aae6-f78a0d64d6b3\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 08:56:15,621] Trial 0 finished with value: 0.618179190158844 and parameters: {'d_token': 37, 'num_heads': 2, 'num_layers': 3, 'd_ffn': 215, 'lr': 0.004075777130138326, 'dropout': 0.12583897643665848, 'n_bins': 4}. Best is trial 0 with value: 0.618179190158844.\n","[I 2025-03-05 08:57:24,095] Trial 1 finished with value: 0.6612763245900471 and parameters: {'d_token': 122, 'num_heads': 7, 'num_layers': 1, 'd_ffn': 184, 'lr': 0.0005922977147763887, 'dropout': 0.3178057485814755, 'n_bins': 2}. Best is trial 0 with value: 0.618179190158844.\n","[I 2025-03-05 09:00:12,514] Trial 2 finished with value: 0.5899850249290466 and parameters: {'d_token': 128, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 81, 'lr': 0.0001371799844031014, 'dropout': 0.23303418266272563, 'n_bins': 8}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:02:22,868] Trial 3 finished with value: 0.6122730175654093 and parameters: {'d_token': 38, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 218, 'lr': 0.0006302778405020797, 'dropout': 0.45296346488518036, 'n_bins': 6}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:04:13,816] Trial 4 finished with value: 0.6077152013778686 and parameters: {'d_token': 89, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 88, 'lr': 0.001749261730412993, 'dropout': 0.24209848818879043, 'n_bins': 5}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:05:02,822] Trial 5 pruned. \n","[I 2025-03-05 09:07:01,262] Trial 6 finished with value: 0.5918957908948262 and parameters: {'d_token': 77, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 102, 'lr': 0.0021993809810594302, 'dropout': 0.007548784371237238, 'n_bins': 6}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:07:48,723] Trial 7 finished with value: 0.6911606709162395 and parameters: {'d_token': 34, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 119, 'lr': 0.009005954451531559, 'dropout': 0.3952696877149075, 'n_bins': 7}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:08:56,008] Trial 8 finished with value: 0.6175320625305176 and parameters: {'d_token': 120, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 147, 'lr': 0.0032777247194886627, 'dropout': 0.24504266695792426, 'n_bins': 5}. Best is trial 2 with value: 0.5899850249290466.\n","[I 2025-03-05 09:11:26,276] Trial 9 finished with value: 0.5734905441602071 and parameters: {'d_token': 71, 'num_heads': 2, 'num_layers': 2, 'd_ffn': 80, 'lr': 0.0003656327685706044, 'dropout': 0.024496872145781612, 'n_bins': 9}. Best is trial 9 with value: 0.5734905441602071.\n","[I 2025-03-05 09:13:59,778] Trial 10 finished with value: 0.5955317338307698 and parameters: {'d_token': 59, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 138, 'lr': 0.0001341541308676095, 'dropout': 0.11037292777639263, 'n_bins': 10}. Best is trial 9 with value: 0.5734905441602071.\n","[I 2025-03-05 09:16:30,659] Trial 11 finished with value: 0.5834319472312928 and parameters: {'d_token': 101, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 74, 'lr': 0.00014581998165762573, 'dropout': 0.17159657950163085, 'n_bins': 9}. Best is trial 9 with value: 0.5734905441602071.\n","[I 2025-03-05 09:19:11,397] Trial 12 finished with value: 0.578859281539917 and parameters: {'d_token': 98, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 71, 'lr': 0.0002824280018530215, 'dropout': 0.15211027474746877, 'n_bins': 10}. Best is trial 9 with value: 0.5734905441602071.\n","[I 2025-03-05 09:20:36,096] Trial 13 pruned. \n","[I 2025-03-05 09:21:54,740] Trial 14 pruned. \n","[I 2025-03-05 09:24:21,943] Trial 15 finished with value: 0.5798951586087545 and parameters: {'d_token': 60, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 125, 'lr': 0.0002942623884696437, 'dropout': 0.16756676582330546, 'n_bins': 9}. Best is trial 9 with value: 0.5734905441602071.\n","[I 2025-03-05 09:26:57,335] Trial 16 finished with value: 0.5808017094930013 and parameters: {'d_token': 95, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 245, 'lr': 0.0007400285079689437, 'dropout': 0.17745429679883867, 'n_bins': 10}. Best is trial 9 with value: 0.5734905441602071.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.5735\n","  Params:\n","    d_token: 71\n","    num_heads: 2\n","    num_layers: 2\n","    d_ffn: 80\n","    lr: 0.0003656327685706044\n","    dropout: 0.024496872145781612\n","    n_bins: 9\n","\n","=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.6614, Train Acc: 0.5964, Val Loss: 0.6286, Val Acc: 0.6298\n","Epoch 2/100, Train Loss: 0.6136, Train Acc: 0.6585, Val Loss: 0.6068, Val Acc: 0.6683\n","Epoch 3/100, Train Loss: 0.6017, Train Acc: 0.6706, Val Loss: 0.6089, Val Acc: 0.6676\n","Epoch 4/100, Train Loss: 0.6017, Train Acc: 0.6714, Val Loss: 0.6015, Val Acc: 0.6715\n","Epoch 5/100, Train Loss: 0.5950, Train Acc: 0.6779, Val Loss: 0.6035, Val Acc: 0.6676\n","Epoch 6/100, Train Loss: 0.5942, Train Acc: 0.6765, Val Loss: 0.5988, Val Acc: 0.6726\n","Epoch 7/100, Train Loss: 0.5938, Train Acc: 0.6777, Val Loss: 0.6121, Val Acc: 0.6700\n","Epoch 8/100, Train Loss: 0.5910, Train Acc: 0.6809, Val Loss: 0.5949, Val Acc: 0.6803\n","Epoch 9/100, Train Loss: 0.5899, Train Acc: 0.6823, Val Loss: 0.6069, Val Acc: 0.6649\n","Epoch 10/100, Train Loss: 0.5891, Train Acc: 0.6809, Val Loss: 0.6115, Val Acc: 0.6559\n","Epoch 11/100, Train Loss: 0.5899, Train Acc: 0.6799, Val Loss: 0.5922, Val Acc: 0.6804\n","Epoch 12/100, Train Loss: 0.5848, Train Acc: 0.6843, Val Loss: 0.5902, Val Acc: 0.6812\n","Epoch 13/100, Train Loss: 0.5838, Train Acc: 0.6862, Val Loss: 0.5922, Val Acc: 0.6806\n","Epoch 14/100, Train Loss: 0.5822, Train Acc: 0.6877, Val Loss: 0.5922, Val Acc: 0.6725\n","Epoch 15/100, Train Loss: 0.5812, Train Acc: 0.6872, Val Loss: 0.5903, Val Acc: 0.6791\n","Epoch 16/100, Train Loss: 0.5815, Train Acc: 0.6875, Val Loss: 0.5906, Val Acc: 0.6748\n","Epoch 17/100, Train Loss: 0.5787, Train Acc: 0.6892, Val Loss: 0.5933, Val Acc: 0.6780\n","Epoch 18/100, Train Loss: 0.5793, Train Acc: 0.6881, Val Loss: 0.5871, Val Acc: 0.6819\n","Epoch 19/100, Train Loss: 0.5782, Train Acc: 0.6910, Val Loss: 0.5840, Val Acc: 0.6838\n","Epoch 20/100, Train Loss: 0.5766, Train Acc: 0.6900, Val Loss: 0.5990, Val Acc: 0.6770\n","Epoch 21/100, Train Loss: 0.5787, Train Acc: 0.6909, Val Loss: 0.5877, Val Acc: 0.6817\n","Epoch 22/100, Train Loss: 0.5762, Train Acc: 0.6911, Val Loss: 0.5918, Val Acc: 0.6763\n","Epoch 23/100, Train Loss: 0.5758, Train Acc: 0.6907, Val Loss: 0.5843, Val Acc: 0.6823\n","Epoch 24/100, Train Loss: 0.5755, Train Acc: 0.6934, Val Loss: 0.5842, Val Acc: 0.6821\n","Epoch 25/100, Train Loss: 0.5746, Train Acc: 0.6923, Val Loss: 0.5849, Val Acc: 0.6825\n","Epoch 26/100, Train Loss: 0.5741, Train Acc: 0.6935, Val Loss: 0.5938, Val Acc: 0.6753\n","Epoch 27/100, Train Loss: 0.5731, Train Acc: 0.6944, Val Loss: 0.5827, Val Acc: 0.6855\n","Epoch 28/100, Train Loss: 0.5722, Train Acc: 0.6959, Val Loss: 0.5856, Val Acc: 0.6796\n","Epoch 29/100, Train Loss: 0.5719, Train Acc: 0.6968, Val Loss: 0.5872, Val Acc: 0.6837\n","Epoch 30/100, Train Loss: 0.5723, Train Acc: 0.6950, Val Loss: 0.5854, Val Acc: 0.6818\n","Epoch 31/100, Train Loss: 0.5721, Train Acc: 0.6972, Val Loss: 0.5821, Val Acc: 0.6855\n","Epoch 32/100, Train Loss: 0.5715, Train Acc: 0.6964, Val Loss: 0.5806, Val Acc: 0.6835\n","Epoch 33/100, Train Loss: 0.5696, Train Acc: 0.6970, Val Loss: 0.5821, Val Acc: 0.6848\n","Epoch 34/100, Train Loss: 0.5689, Train Acc: 0.6977, Val Loss: 0.5824, Val Acc: 0.6842\n","Epoch 35/100, Train Loss: 0.5708, Train Acc: 0.6973, Val Loss: 0.5821, Val Acc: 0.6827\n","Epoch 36/100, Train Loss: 0.5700, Train Acc: 0.6972, Val Loss: 0.5816, Val Acc: 0.6850\n","Epoch 37/100, Train Loss: 0.5686, Train Acc: 0.6985, Val Loss: 0.5949, Val Acc: 0.6756\n","Epoch 38/100, Train Loss: 0.5701, Train Acc: 0.6973, Val Loss: 0.5812, Val Acc: 0.6853\n","Epoch 39/100, Train Loss: 0.5681, Train Acc: 0.6993, Val Loss: 0.6002, Val Acc: 0.6694\n","Epoch 40/100, Train Loss: 0.5688, Train Acc: 0.6988, Val Loss: 0.5799, Val Acc: 0.6853\n","Epoch 41/100, Train Loss: 0.5662, Train Acc: 0.7013, Val Loss: 0.5825, Val Acc: 0.6847\n","Epoch 42/100, Train Loss: 0.5674, Train Acc: 0.6999, Val Loss: 0.5917, Val Acc: 0.6758\n","Epoch 43/100, Train Loss: 0.5676, Train Acc: 0.7003, Val Loss: 0.5815, Val Acc: 0.6836\n","Epoch 44/100, Train Loss: 0.5650, Train Acc: 0.7003, Val Loss: 0.5834, Val Acc: 0.6864\n","Epoch 45/100, Train Loss: 0.5650, Train Acc: 0.7013, Val Loss: 0.5838, Val Acc: 0.6824\n","Epoch 46/100, Train Loss: 0.5648, Train Acc: 0.7009, Val Loss: 0.5797, Val Acc: 0.6884\n","Epoch 47/100, Train Loss: 0.5646, Train Acc: 0.7014, Val Loss: 0.5827, Val Acc: 0.6833\n","Epoch 48/100, Train Loss: 0.5653, Train Acc: 0.7018, Val Loss: 0.5843, Val Acc: 0.6849\n","Epoch 49/100, Train Loss: 0.5624, Train Acc: 0.7015, Val Loss: 0.5880, Val Acc: 0.6839\n","Epoch 50/100, Train Loss: 0.5631, Train Acc: 0.7027, Val Loss: 0.5814, Val Acc: 0.6870\n","Epoch 51/100, Train Loss: 0.5628, Train Acc: 0.7030, Val Loss: 0.5785, Val Acc: 0.6850\n","Epoch 52/100, Train Loss: 0.5626, Train Acc: 0.7033, Val Loss: 0.5834, Val Acc: 0.6840\n","Epoch 53/100, Train Loss: 0.5618, Train Acc: 0.7050, Val Loss: 0.5853, Val Acc: 0.6850\n","Epoch 54/100, Train Loss: 0.5624, Train Acc: 0.7034, Val Loss: 0.5801, Val Acc: 0.6865\n","Epoch 55/100, Train Loss: 0.5603, Train Acc: 0.7052, Val Loss: 0.5837, Val Acc: 0.6840\n","Epoch 56/100, Train Loss: 0.5596, Train Acc: 0.7055, Val Loss: 0.5799, Val Acc: 0.6838\n","Epoch 57/100, Train Loss: 0.5609, Train Acc: 0.7040, Val Loss: 0.5848, Val Acc: 0.6844\n","Epoch 58/100, Train Loss: 0.5601, Train Acc: 0.7042, Val Loss: 0.5819, Val Acc: 0.6891\n","Epoch 59/100, Train Loss: 0.5600, Train Acc: 0.7056, Val Loss: 0.5870, Val Acc: 0.6816\n","Epoch 60/100, Train Loss: 0.5607, Train Acc: 0.7046, Val Loss: 0.5810, Val Acc: 0.6850\n","Epoch 61/100, Train Loss: 0.5577, Train Acc: 0.7057, Val Loss: 0.5789, Val Acc: 0.6884\n","Epoch 62/100, Train Loss: 0.5562, Train Acc: 0.7068, Val Loss: 0.5844, Val Acc: 0.6876\n","Epoch 63/100, Train Loss: 0.5573, Train Acc: 0.7079, Val Loss: 0.5934, Val Acc: 0.6785\n","Epoch 64/100, Train Loss: 0.5585, Train Acc: 0.7067, Val Loss: 0.5796, Val Acc: 0.6855\n","Epoch 65/100, Train Loss: 0.5561, Train Acc: 0.7088, Val Loss: 0.5788, Val Acc: 0.6856\n","Epoch 66/100, Train Loss: 0.5559, Train Acc: 0.7064, Val Loss: 0.5818, Val Acc: 0.6831\n","Epoch 67/100, Train Loss: 0.5575, Train Acc: 0.7065, Val Loss: 0.5804, Val Acc: 0.6854\n","Early stopping at epoch 67\n","Test Accuracy: 0.6960\n","Test Precision: 0.7201\n","Test Recall: 0.6933\n","Test F1 Score: 0.7064\n","Test AUC: 0.7668\n","Confusion Matrix:\n","[[4858 2091]\n"," [2380 5379]]\n","Model saved as ft_piecewise_tuned_higgs.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.6990 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 09:36:34,653] A new study created in memory with name: no-name-1f691e2e-0b32-4202-b2d5-b88fbe3c9460\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 09:39:33,400] Trial 0 finished with value: 0.5546574195226034 and parameters: {'d_token': 88, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 183, 'lr': 0.0017775712002695311, 'dropout': 0.38176751897850053, 'n_bins': 5}. Best is trial 0 with value: 0.5546574195226034.\n","[I 2025-03-05 09:40:32,592] Trial 1 finished with value: 0.6734628637631734 and parameters: {'d_token': 126, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 187, 'lr': 0.008707079065412144, 'dropout': 0.0828105657393311, 'n_bins': 5}. Best is trial 0 with value: 0.5546574195226034.\n","[I 2025-03-05 09:43:45,548] Trial 2 finished with value: 0.5434974273045857 and parameters: {'d_token': 123, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 203, 'lr': 0.00029221940762809645, 'dropout': 0.44583420434238047, 'n_bins': 5}. Best is trial 2 with value: 0.5434974273045857.\n","[I 2025-03-05 09:46:27,674] Trial 3 finished with value: 0.537414534886678 and parameters: {'d_token': 125, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 174, 'lr': 0.0004240321409648224, 'dropout': 0.29644785258263423, 'n_bins': 9}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 09:47:30,760] Trial 4 finished with value: 0.5655991951624553 and parameters: {'d_token': 100, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 228, 'lr': 0.0005069316936740479, 'dropout': 0.09054092703451327, 'n_bins': 10}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 09:48:06,808] Trial 5 pruned. \n","[I 2025-03-05 09:49:31,917] Trial 6 finished with value: 0.5496242801348369 and parameters: {'d_token': 35, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 206, 'lr': 0.002157795972683478, 'dropout': 0.18954194685277287, 'n_bins': 4}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 09:50:01,530] Trial 7 pruned. \n","[I 2025-03-05 09:50:42,786] Trial 8 pruned. \n","[I 2025-03-05 09:51:13,080] Trial 9 pruned. \n","[I 2025-03-05 09:53:50,904] Trial 10 finished with value: 0.5442593018213908 and parameters: {'d_token': 106, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 129, 'lr': 0.00011906578327012928, 'dropout': 0.3033191224868209, 'n_bins': 10}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 09:57:40,615] Trial 11 finished with value: 0.5419076999028524 and parameters: {'d_token': 113, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 153, 'lr': 0.0003421318062533824, 'dropout': 0.4923836221740345, 'n_bins': 2}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 10:00:19,255] Trial 12 finished with value: 0.5413498640060425 and parameters: {'d_token': 109, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 140, 'lr': 0.00033105700434878815, 'dropout': 0.2746854788822393, 'n_bins': 2}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 10:02:32,337] Trial 13 finished with value: 0.5468221227327983 and parameters: {'d_token': 95, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 131, 'lr': 0.0009689014871156334, 'dropout': 0.25288196805199054, 'n_bins': 9}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 10:06:05,774] Trial 14 finished with value: 0.5406538446744283 and parameters: {'d_token': 111, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 80, 'lr': 0.00022070116368255217, 'dropout': 0.3334889449106844, 'n_bins': 2}. Best is trial 3 with value: 0.537414534886678.\n","[I 2025-03-05 10:07:21,965] Trial 15 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.5374\n","  Params:\n","    d_token: 125\n","    num_heads: 8\n","    num_layers: 2\n","    d_ffn: 174\n","    lr: 0.0004240321409648224\n","    dropout: 0.29644785258263423\n","    n_bins: 9\n","\n","=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.6046, Train Acc: 0.6666, Val Loss: 0.5966, Val Acc: 0.6806\n","Epoch 2/100, Train Loss: 0.5685, Train Acc: 0.6995, Val Loss: 0.5797, Val Acc: 0.6975\n","Epoch 3/100, Train Loss: 0.5569, Train Acc: 0.7092, Val Loss: 0.5763, Val Acc: 0.6972\n","Epoch 4/100, Train Loss: 0.5502, Train Acc: 0.7125, Val Loss: 0.5624, Val Acc: 0.7080\n","Epoch 5/100, Train Loss: 0.5461, Train Acc: 0.7184, Val Loss: 0.5520, Val Acc: 0.7124\n","Epoch 6/100, Train Loss: 0.5414, Train Acc: 0.7192, Val Loss: 0.5502, Val Acc: 0.7149\n","Epoch 7/100, Train Loss: 0.5379, Train Acc: 0.7226, Val Loss: 0.5581, Val Acc: 0.7099\n","Epoch 8/100, Train Loss: 0.5337, Train Acc: 0.7250, Val Loss: 0.5521, Val Acc: 0.7211\n","Epoch 9/100, Train Loss: 0.5307, Train Acc: 0.7254, Val Loss: 0.5493, Val Acc: 0.7191\n","Epoch 10/100, Train Loss: 0.5293, Train Acc: 0.7262, Val Loss: 0.5668, Val Acc: 0.7119\n","Epoch 11/100, Train Loss: 0.5287, Train Acc: 0.7307, Val Loss: 0.5478, Val Acc: 0.7226\n","Epoch 12/100, Train Loss: 0.5277, Train Acc: 0.7295, Val Loss: 0.5474, Val Acc: 0.7148\n","Epoch 13/100, Train Loss: 0.5238, Train Acc: 0.7328, Val Loss: 0.5513, Val Acc: 0.7173\n","Epoch 14/100, Train Loss: 0.5215, Train Acc: 0.7346, Val Loss: 0.5482, Val Acc: 0.7188\n","Epoch 15/100, Train Loss: 0.5199, Train Acc: 0.7354, Val Loss: 0.5508, Val Acc: 0.7184\n","Epoch 16/100, Train Loss: 0.5202, Train Acc: 0.7350, Val Loss: 0.5456, Val Acc: 0.7180\n","Epoch 17/100, Train Loss: 0.5168, Train Acc: 0.7368, Val Loss: 0.5505, Val Acc: 0.7170\n","Epoch 18/100, Train Loss: 0.5142, Train Acc: 0.7383, Val Loss: 0.5524, Val Acc: 0.7152\n","Epoch 19/100, Train Loss: 0.5136, Train Acc: 0.7391, Val Loss: 0.5520, Val Acc: 0.7202\n","Epoch 20/100, Train Loss: 0.5113, Train Acc: 0.7407, Val Loss: 0.5526, Val Acc: 0.7177\n","Epoch 21/100, Train Loss: 0.5117, Train Acc: 0.7432, Val Loss: 0.5514, Val Acc: 0.7183\n","Epoch 22/100, Train Loss: 0.5079, Train Acc: 0.7418, Val Loss: 0.5514, Val Acc: 0.7189\n","Epoch 23/100, Train Loss: 0.5111, Train Acc: 0.7416, Val Loss: 0.5582, Val Acc: 0.7126\n","Epoch 24/100, Train Loss: 0.5070, Train Acc: 0.7431, Val Loss: 0.5596, Val Acc: 0.7195\n","Epoch 25/100, Train Loss: 0.5067, Train Acc: 0.7446, Val Loss: 0.5491, Val Acc: 0.7205\n","Epoch 26/100, Train Loss: 0.5061, Train Acc: 0.7447, Val Loss: 0.5496, Val Acc: 0.7194\n","Epoch 27/100, Train Loss: 0.5029, Train Acc: 0.7465, Val Loss: 0.5512, Val Acc: 0.7225\n","Epoch 28/100, Train Loss: 0.4998, Train Acc: 0.7496, Val Loss: 0.5675, Val Acc: 0.7154\n","Epoch 29/100, Train Loss: 0.5002, Train Acc: 0.7481, Val Loss: 0.5615, Val Acc: 0.7131\n","Epoch 30/100, Train Loss: 0.5001, Train Acc: 0.7486, Val Loss: 0.5618, Val Acc: 0.7180\n","Epoch 31/100, Train Loss: 0.4958, Train Acc: 0.7524, Val Loss: 0.5592, Val Acc: 0.7202\n","Epoch 32/100, Train Loss: 0.4954, Train Acc: 0.7522, Val Loss: 0.5545, Val Acc: 0.7178\n","Early stopping at epoch 32\n","Test Accuracy: 0.7235\n","Test Precision: 0.7360\n","Test Recall: 0.7420\n","Test F1 Score: 0.7390\n","Test AUC: 0.8026\n","Confusion Matrix:\n","[[4884 2065]\n"," [2002 5757]]\n","Model saved as sparse_ft_linear_tuned_higgs.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.8489 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 10:14:36,329] A new study created in memory with name: no-name-c6c8e380-7eb1-45ac-92f1-ae3adcd0de8f\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 10:18:15,308] Trial 0 finished with value: 0.6494097908337911 and parameters: {'d_token': 120, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 134, 'lr': 0.0010108963734850563, 'dropout': 0.3610962811775675, 'n_bins': 3}. Best is trial 0 with value: 0.6494097908337911.\n","[I 2025-03-05 10:21:15,687] Trial 1 finished with value: 0.6244125882784526 and parameters: {'d_token': 119, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 242, 'lr': 0.002259225208310083, 'dropout': 0.42970014628700853, 'n_bins': 10}. Best is trial 1 with value: 0.6244125882784526.\n","[I 2025-03-05 10:23:02,261] Trial 2 finished with value: 0.6791223804155986 and parameters: {'d_token': 93, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 240, 'lr': 0.003196753024428784, 'dropout': 0.07263587765190954, 'n_bins': 4}. Best is trial 1 with value: 0.6244125882784526.\n","[I 2025-03-05 10:26:42,385] Trial 3 finished with value: 0.5881945848464966 and parameters: {'d_token': 57, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 93, 'lr': 0.00012500750962802777, 'dropout': 0.07659667372062445, 'n_bins': 7}. Best is trial 3 with value: 0.5881945848464966.\n","[I 2025-03-05 10:29:09,779] Trial 4 finished with value: 0.6872323314348857 and parameters: {'d_token': 99, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 117, 'lr': 0.009451745972579422, 'dropout': 0.08225091323339201, 'n_bins': 6}. Best is trial 3 with value: 0.5881945848464966.\n","[I 2025-03-05 10:32:29,185] Trial 5 finished with value: 0.6026610533396403 and parameters: {'d_token': 82, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 248, 'lr': 0.002547224142957361, 'dropout': 0.0494736046182318, 'n_bins': 6}. Best is trial 3 with value: 0.5881945848464966.\n","[I 2025-03-05 10:33:52,304] Trial 6 pruned. \n","[I 2025-03-05 10:35:17,342] Trial 7 pruned. \n","[I 2025-03-05 10:35:59,072] Trial 8 pruned. \n","[I 2025-03-05 10:38:14,234] Trial 9 pruned. \n","[I 2025-03-05 10:42:04,986] Trial 10 finished with value: 0.5927383502324423 and parameters: {'d_token': 54, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 175, 'lr': 0.00010931153572052848, 'dropout': 0.18170444591882337, 'n_bins': 8}. Best is trial 3 with value: 0.5881945848464966.\n","[I 2025-03-05 10:44:57,650] Trial 11 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.5882\n","  Params:\n","    d_token: 57\n","    num_heads: 8\n","    num_layers: 2\n","    d_ffn: 93\n","    lr: 0.00012500750962802777\n","    dropout: 0.07659667372062445\n","    n_bins: 7\n","\n","=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.6699, Train Acc: 0.5840, Val Loss: 0.6303, Val Acc: 0.6400\n","Epoch 2/100, Train Loss: 0.6190, Train Acc: 0.6517, Val Loss: 0.6165, Val Acc: 0.6584\n","Epoch 3/100, Train Loss: 0.6108, Train Acc: 0.6610, Val Loss: 0.6085, Val Acc: 0.6652\n","Epoch 4/100, Train Loss: 0.6058, Train Acc: 0.6641, Val Loss: 0.6064, Val Acc: 0.6660\n","Epoch 5/100, Train Loss: 0.6028, Train Acc: 0.6678, Val Loss: 0.6062, Val Acc: 0.6666\n","Epoch 6/100, Train Loss: 0.6013, Train Acc: 0.6683, Val Loss: 0.6176, Val Acc: 0.6520\n","Epoch 7/100, Train Loss: 0.6000, Train Acc: 0.6679, Val Loss: 0.6005, Val Acc: 0.6718\n","Epoch 8/100, Train Loss: 0.5963, Train Acc: 0.6721, Val Loss: 0.6009, Val Acc: 0.6738\n","Epoch 9/100, Train Loss: 0.5935, Train Acc: 0.6758, Val Loss: 0.5987, Val Acc: 0.6746\n","Epoch 10/100, Train Loss: 0.5926, Train Acc: 0.6750, Val Loss: 0.5968, Val Acc: 0.6729\n","Epoch 11/100, Train Loss: 0.5907, Train Acc: 0.6754, Val Loss: 0.5963, Val Acc: 0.6784\n","Epoch 12/100, Train Loss: 0.5901, Train Acc: 0.6781, Val Loss: 0.5951, Val Acc: 0.6774\n","Epoch 13/100, Train Loss: 0.5901, Train Acc: 0.6764, Val Loss: 0.5929, Val Acc: 0.6786\n","Epoch 14/100, Train Loss: 0.5885, Train Acc: 0.6808, Val Loss: 0.5932, Val Acc: 0.6781\n","Epoch 15/100, Train Loss: 0.5891, Train Acc: 0.6785, Val Loss: 0.5922, Val Acc: 0.6806\n","Epoch 16/100, Train Loss: 0.5860, Train Acc: 0.6812, Val Loss: 0.5903, Val Acc: 0.6802\n","Epoch 17/100, Train Loss: 0.5849, Train Acc: 0.6807, Val Loss: 0.5907, Val Acc: 0.6814\n","Epoch 18/100, Train Loss: 0.5842, Train Acc: 0.6814, Val Loss: 0.5901, Val Acc: 0.6807\n","Epoch 19/100, Train Loss: 0.5834, Train Acc: 0.6834, Val Loss: 0.5899, Val Acc: 0.6786\n","Epoch 20/100, Train Loss: 0.5828, Train Acc: 0.6833, Val Loss: 0.5903, Val Acc: 0.6808\n","Epoch 21/100, Train Loss: 0.5834, Train Acc: 0.6837, Val Loss: 0.5909, Val Acc: 0.6766\n","Epoch 22/100, Train Loss: 0.5807, Train Acc: 0.6854, Val Loss: 0.5877, Val Acc: 0.6819\n","Epoch 23/100, Train Loss: 0.5814, Train Acc: 0.6860, Val Loss: 0.5956, Val Acc: 0.6703\n","Epoch 24/100, Train Loss: 0.5818, Train Acc: 0.6850, Val Loss: 0.5930, Val Acc: 0.6730\n","Epoch 25/100, Train Loss: 0.5805, Train Acc: 0.6854, Val Loss: 0.5868, Val Acc: 0.6834\n","Epoch 26/100, Train Loss: 0.5784, Train Acc: 0.6874, Val Loss: 0.5875, Val Acc: 0.6812\n","Epoch 27/100, Train Loss: 0.5790, Train Acc: 0.6863, Val Loss: 0.5855, Val Acc: 0.6813\n","Epoch 28/100, Train Loss: 0.5777, Train Acc: 0.6881, Val Loss: 0.5869, Val Acc: 0.6815\n","Epoch 29/100, Train Loss: 0.5789, Train Acc: 0.6883, Val Loss: 0.5869, Val Acc: 0.6815\n","Epoch 30/100, Train Loss: 0.5781, Train Acc: 0.6877, Val Loss: 0.5861, Val Acc: 0.6785\n","Epoch 31/100, Train Loss: 0.5767, Train Acc: 0.6898, Val Loss: 0.5849, Val Acc: 0.6837\n","Epoch 32/100, Train Loss: 0.5766, Train Acc: 0.6890, Val Loss: 0.5862, Val Acc: 0.6818\n","Epoch 33/100, Train Loss: 0.5759, Train Acc: 0.6900, Val Loss: 0.5896, Val Acc: 0.6787\n","Epoch 34/100, Train Loss: 0.5764, Train Acc: 0.6887, Val Loss: 0.5876, Val Acc: 0.6825\n","Epoch 35/100, Train Loss: 0.5747, Train Acc: 0.6904, Val Loss: 0.5853, Val Acc: 0.6823\n","Epoch 36/100, Train Loss: 0.5735, Train Acc: 0.6899, Val Loss: 0.5837, Val Acc: 0.6837\n","Epoch 37/100, Train Loss: 0.5743, Train Acc: 0.6908, Val Loss: 0.5870, Val Acc: 0.6797\n","Epoch 38/100, Train Loss: 0.5749, Train Acc: 0.6904, Val Loss: 0.5837, Val Acc: 0.6853\n","Epoch 39/100, Train Loss: 0.5731, Train Acc: 0.6900, Val Loss: 0.5835, Val Acc: 0.6858\n","Epoch 40/100, Train Loss: 0.5722, Train Acc: 0.6916, Val Loss: 0.5863, Val Acc: 0.6839\n","Epoch 41/100, Train Loss: 0.5727, Train Acc: 0.6930, Val Loss: 0.5837, Val Acc: 0.6830\n","Epoch 42/100, Train Loss: 0.5725, Train Acc: 0.6932, Val Loss: 0.5850, Val Acc: 0.6855\n","Epoch 43/100, Train Loss: 0.5704, Train Acc: 0.6943, Val Loss: 0.5844, Val Acc: 0.6837\n","Epoch 44/100, Train Loss: 0.5704, Train Acc: 0.6937, Val Loss: 0.5850, Val Acc: 0.6823\n","Epoch 45/100, Train Loss: 0.5720, Train Acc: 0.6933, Val Loss: 0.5835, Val Acc: 0.6836\n","Epoch 46/100, Train Loss: 0.5692, Train Acc: 0.6944, Val Loss: 0.5837, Val Acc: 0.6842\n","Epoch 47/100, Train Loss: 0.5688, Train Acc: 0.6947, Val Loss: 0.5822, Val Acc: 0.6865\n","Epoch 48/100, Train Loss: 0.5710, Train Acc: 0.6933, Val Loss: 0.5819, Val Acc: 0.6859\n","Epoch 49/100, Train Loss: 0.5700, Train Acc: 0.6941, Val Loss: 0.5812, Val Acc: 0.6859\n","Epoch 50/100, Train Loss: 0.5684, Train Acc: 0.6972, Val Loss: 0.5819, Val Acc: 0.6860\n","Epoch 51/100, Train Loss: 0.5691, Train Acc: 0.6971, Val Loss: 0.5848, Val Acc: 0.6863\n","Epoch 52/100, Train Loss: 0.5673, Train Acc: 0.6952, Val Loss: 0.5855, Val Acc: 0.6840\n","Epoch 53/100, Train Loss: 0.5676, Train Acc: 0.6960, Val Loss: 0.5835, Val Acc: 0.6829\n","Epoch 54/100, Train Loss: 0.5677, Train Acc: 0.6963, Val Loss: 0.5817, Val Acc: 0.6882\n","Epoch 55/100, Train Loss: 0.5664, Train Acc: 0.6974, Val Loss: 0.5812, Val Acc: 0.6863\n","Epoch 56/100, Train Loss: 0.5665, Train Acc: 0.6972, Val Loss: 0.5810, Val Acc: 0.6884\n","Epoch 57/100, Train Loss: 0.5651, Train Acc: 0.6975, Val Loss: 0.5821, Val Acc: 0.6845\n","Epoch 58/100, Train Loss: 0.5665, Train Acc: 0.6976, Val Loss: 0.5815, Val Acc: 0.6836\n","Epoch 59/100, Train Loss: 0.5664, Train Acc: 0.6968, Val Loss: 0.5812, Val Acc: 0.6863\n","Epoch 60/100, Train Loss: 0.5638, Train Acc: 0.6996, Val Loss: 0.5812, Val Acc: 0.6893\n","Epoch 61/100, Train Loss: 0.5654, Train Acc: 0.6991, Val Loss: 0.5822, Val Acc: 0.6867\n","Epoch 62/100, Train Loss: 0.5654, Train Acc: 0.6970, Val Loss: 0.5806, Val Acc: 0.6867\n","Epoch 63/100, Train Loss: 0.5646, Train Acc: 0.6986, Val Loss: 0.5881, Val Acc: 0.6808\n","Epoch 64/100, Train Loss: 0.5650, Train Acc: 0.6981, Val Loss: 0.5816, Val Acc: 0.6874\n","Epoch 65/100, Train Loss: 0.5642, Train Acc: 0.6964, Val Loss: 0.5802, Val Acc: 0.6861\n","Epoch 66/100, Train Loss: 0.5641, Train Acc: 0.6990, Val Loss: 0.5788, Val Acc: 0.6893\n","Epoch 67/100, Train Loss: 0.5620, Train Acc: 0.7000, Val Loss: 0.5811, Val Acc: 0.6868\n","Epoch 68/100, Train Loss: 0.5637, Train Acc: 0.6993, Val Loss: 0.5826, Val Acc: 0.6840\n","Epoch 69/100, Train Loss: 0.5630, Train Acc: 0.6997, Val Loss: 0.5827, Val Acc: 0.6876\n","Epoch 70/100, Train Loss: 0.5624, Train Acc: 0.6983, Val Loss: 0.5814, Val Acc: 0.6858\n","Epoch 71/100, Train Loss: 0.5604, Train Acc: 0.7001, Val Loss: 0.5831, Val Acc: 0.6841\n","Epoch 72/100, Train Loss: 0.5622, Train Acc: 0.7007, Val Loss: 0.5824, Val Acc: 0.6823\n","Epoch 73/100, Train Loss: 0.5616, Train Acc: 0.7000, Val Loss: 0.5817, Val Acc: 0.6879\n","Epoch 74/100, Train Loss: 0.5610, Train Acc: 0.7018, Val Loss: 0.5790, Val Acc: 0.6871\n","Epoch 75/100, Train Loss: 0.5604, Train Acc: 0.7024, Val Loss: 0.5795, Val Acc: 0.6887\n","Epoch 76/100, Train Loss: 0.5600, Train Acc: 0.7021, Val Loss: 0.5798, Val Acc: 0.6855\n","Epoch 77/100, Train Loss: 0.5603, Train Acc: 0.7015, Val Loss: 0.5811, Val Acc: 0.6872\n","Epoch 78/100, Train Loss: 0.5607, Train Acc: 0.7029, Val Loss: 0.5789, Val Acc: 0.6891\n","Epoch 79/100, Train Loss: 0.5591, Train Acc: 0.7026, Val Loss: 0.5800, Val Acc: 0.6876\n","Epoch 80/100, Train Loss: 0.5591, Train Acc: 0.7046, Val Loss: 0.5834, Val Acc: 0.6864\n","Epoch 81/100, Train Loss: 0.5597, Train Acc: 0.6999, Val Loss: 0.5811, Val Acc: 0.6829\n","Epoch 82/100, Train Loss: 0.5589, Train Acc: 0.7031, Val Loss: 0.5815, Val Acc: 0.6859\n","Early stopping at epoch 82\n","Test Accuracy: 0.6921\n","Test Precision: 0.7051\n","Test Recall: 0.7156\n","Test F1 Score: 0.7103\n","Test AUC: 0.7634\n","Confusion Matrix:\n","[[4627 2322]\n"," [2207 5552]]\n","Model saved as sparse_ft_piecewise_tuned_higgs.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.7926 (p-value: 0.0000)\n","\n","=== Comparison of Tuned Models ===\n","FT Transformer (Linear Tuned): Accuracy=0.7244, F1=0.7338\n","FT Transformer (Piecewise Tuned): Accuracy=0.6960, F1=0.7064\n","Sparse FT Transformer (Linear Tuned): Accuracy=0.7235, F1=0.7390\n","Sparse FT Transformer (Piecewise Tuned): Accuracy=0.6921, F1=0.7103\n","\n","=== Comparison of PFI-Attention Correlations (Tuned Models) ===\n","FT Transformer (Linear Tuned): ρ=0.7515, p-value=0.0000\n","FT Transformer (Piecewise Tuned): ρ=0.6990, p-value=0.0000\n","Sparse FT Transformer (Linear Tuned): ρ=0.8489, p-value=0.0000\n","Sparse FT Transformer (Piecewise Tuned): ρ=0.7926, p-value=0.0000\n","\n","Visualizations saved as 'model_comparison_higgs.png' and 'feature_importance_comparison_higgs.png'\n","Results saved as results_higgs.json\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","def save_all_files_to_drive(folder_name='HIGGS_Files'):\n","  \"\"\"Saves all files in the current Colab environment to a new folder in Google Drive.\n","\n","  Args:\n","    folder_name: The name of the folder to create in Google Drive. Defaults to 'Colab_Files'.\n","  \"\"\"\n","\n","  # Mount Google Drive\n","  drive.mount('/content/drive')\n","\n","  # Create the folder in Google Drive\n","  folder_path = os.path.join('/content/drive/My Drive', folder_name)\n","  os.makedirs(folder_path, exist_ok=True)\n","\n","  # Get a list of all files in the current directory\n","  files = os.listdir('.')\n","\n","  # Copy each file to the Google Drive folder\n","  for file in files:\n","    source_path = os.path.join('.', file)\n","    destination_path = os.path.join(folder_path, file)\n","    os.system(f'cp \"{source_path}\" \"{destination_path}\"')  # Using os.system for file copying\n","\n","  print(f\"All files saved to Google Drive: /content/drive/My Drive/{folder_name}\")\n","\n","save_all_files_to_drive()"],"metadata":{"id":"-YCEi0O8cest","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741172866581,"user_tz":-60,"elapsed":3887,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"05edb77d-cd8d-4dda-959b-867818cb5f07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","All files saved to Google Drive: /content/drive/My Drive/HIGGS_Files\n"]}]}]}