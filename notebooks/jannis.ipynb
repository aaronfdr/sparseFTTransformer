{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyN8gSXRDqU7JtmHXEV9bamb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install optuna\n","%pip install sparsemax # https://pypi.org/project/sparsemax/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Tc3NgvLqeox8","executionInfo":{"status":"ok","timestamp":1741186294908,"user_tz":-60,"elapsed":77905,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"9aa7032c-a2ef-4e59-e6a7-ea755a5c8361"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n","Collecting sparsemax\n","  Downloading sparsemax-0.1.9-py2.py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from sparsemax) (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->sparsemax)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sparsemax)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sparsemax)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sparsemax)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sparsemax)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sparsemax)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->sparsemax) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->sparsemax) (3.0.2)\n","Downloading sparsemax-0.1.9-py2.py3-none-any.whl (5.5 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sparsemax\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sparsemax-0.1.9\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sparsemax import Sparsemax\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.datasets import fetch_openml\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","from scipy.stats import spearmanr\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import optuna\n","import json\n","import os\n","from urllib.request import urlretrieve\n","import zipfile\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","sparsemax = Sparsemax(dim=-1)\n","\n","class TabularDataset(Dataset):\n","    \"\"\"Dataset for tabular data with continuous features\"\"\"\n","    def __init__(self, X, y=None):\n","        # Continuous features\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","\n","        # Target for multi-class classification\n","        if y is not None:\n","            self.y = torch.tensor(y, dtype=torch.long)\n","        else:\n","            self.y = None\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.X[idx], self.y[idx]\n","        else:\n","            return self.X[idx]\n","\n","class LinearEmbedding(nn.Module):\n","    \"\"\"Linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token):\n","        super().__init__()\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(1, d_token) for _ in range(num_features)\n","        ])\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_cont_features)\n","        batch_size = x.shape[0]\n","        num_features = x.shape[1]\n","\n","        # Embed each continuous feature\n","        embedded = torch.zeros((batch_size, num_features, self.embeddings[0].out_features),\n","                              device=x.device)\n","\n","        for i in range(num_features):\n","            embedded[:, i] = self.embeddings[i](x[:, i].unsqueeze(-1)).squeeze(-1)\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","'''\n","The code below has been adapted from the original codebase.\n","\n","For the implementation of the FT Transformer, please check out this repository: https://github.com/yandex-research/rtdl-revisiting-models\n","\n","For the implementation of the Piecewise Linear Embedding, please check out: https://github.com/yandex-research/rtdl-num-embeddings\n","'''\n","\n","class PiecewiseLinearEmbedding(nn.Module):\n","    \"\"\"Piecewise linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token, num_bins=20):\n","        super().__init__()\n","        self.num_features = num_features\n","        self.d_token = d_token\n","        self.num_bins = num_bins\n","\n","        # Create embeddings for each feature\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(num_bins, d_token) for _ in range(num_features)\n","        ])\n","\n","        # Create parameters for bin boundaries (learnable)\n","        self.bin_boundaries = nn.Parameter(torch.randn(num_features, num_bins-1))\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        batch_size = x.shape[0]\n","\n","        # Output will contain embedded tokens for each feature\n","        embedded = torch.zeros((batch_size, self.num_features, self.d_token), device=x.device)\n","\n","        for i in range(self.num_features):\n","            # Get feature values for current feature\n","            feature_values = x[:, i].unsqueeze(1)  # (batch_size, 1)\n","\n","            # Get sorted boundaries for this feature\n","            boundaries = torch.sort(self.bin_boundaries[i]).values  # (num_bins-1)\n","\n","            # Calculate bin activations using cumulative distribution\n","            # Start with all in the first bin\n","            bin_activations = torch.ones((batch_size, self.num_bins), device=x.device)\n","\n","            # Update bin activations based on feature values and boundaries\n","            for j in range(self.num_bins-1):\n","                boundary = boundaries[j]\n","                # Calculate contribution to bins based on boundary comparison\n","                condition = feature_values > boundary\n","                # Move activations to next bin when condition is true\n","                bin_activations[:, j+1:] = torch.where(\n","                    condition.expand(-1, self.num_bins-j-1),\n","                    bin_activations[:, j:self.num_bins-1],\n","                    bin_activations[:, j+1:]\n","                )\n","                bin_activations[:, j] = torch.where(\n","                    condition.squeeze(1),\n","                    0.0,\n","                    bin_activations[:, j]\n","                )\n","\n","            # Apply linear transformation to get embeddings\n","            feature_embedding = self.embeddings[i](bin_activations)  # (batch_size, d_token)\n","            embedded[:, i] = feature_embedding\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","# Custom attention module to capture attention weights\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply softmax to get attention weights\n","        attention_weights = F.softmax(scores, dim=-1)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","# Custom transformer layer to capture attention weights\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, num_classes, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","        self.num_classes = num_classes\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            TransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for multi-class classification\n","        self.output_layer = nn.Linear(d_token, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","# Sparse attention variants\n","class sparseMultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply sparsemax to get attention weights\n","        attention_weights = sparsemax(scores)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","class sparseTransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = sparseMultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class sparseFTTransformer(nn.Module):\n","    def __init__(self, num_features, num_classes, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","        self.num_classes = num_classes\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers with sparse attention\n","        self.transformer_layers = nn.ModuleList([\n","            sparseTransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for multi-class classification\n","        self.output_layer = nn.Linear(d_token, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","def calculate_pfi(model, X_val, y_val, num_permutations=5):\n","    \"\"\"Calculate Permutation Feature Importance (PFI) for multi-class classification\"\"\"\n","    # Convert to PyTorch tensors\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_val, dtype=torch.long).to(device)\n","\n","    # Get baseline performance\n","    model.eval()\n","    with torch.no_grad():\n","        baseline_preds = model(X)\n","        baseline_loss = F.cross_entropy(baseline_preds, y).item()\n","        baseline_preds_class = torch.argmax(baseline_preds, dim=1)\n","        baseline_accuracy = (baseline_preds_class == y).float().mean().item()\n","\n","    # Calculate importance for each feature\n","    importances = []\n","\n","    for feat_idx in range(X.shape[1]):\n","        accuracies = []\n","\n","        for _ in range(num_permutations):\n","            # Create a permuted copy of the data\n","            X_permuted = X.clone()\n","\n","            # Permute the feature\n","            perm_idx = torch.randperm(X.shape[0])\n","            X_permuted[:, feat_idx] = X_permuted[perm_idx, feat_idx]\n","\n","            # Calculate loss with permuted feature\n","            with torch.no_grad():\n","                perm_preds = model(X_permuted)\n","                perm_preds_class = torch.argmax(perm_preds, dim=1)\n","                perm_accuracy = (perm_preds_class == y).float().mean().item()\n","\n","            # Feature importance is the decrease in accuracy\n","            accuracies.append(baseline_accuracy - perm_accuracy)\n","\n","        # Average over permutations (higher = more important)\n","        importances.append(np.mean(accuracies))\n","\n","    return np.array(importances)\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=100, early_stopping=16):\n","    \"\"\"Train the model with early stopping\"\"\"\n","    model.to(device)\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","    best_state = None\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            # Calculate accuracy\n","            predictions = torch.argmax(outputs, dim=1)\n","            train_correct += (predictions == y_batch).sum().item()\n","            train_total += y_batch.size(0)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","\n","        with torch.no_grad():\n","            for X_batch, y_batch in val_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                val_loss += loss.item()\n","\n","                # Calculate accuracy\n","                predictions = torch.argmax(outputs, dim=1)\n","                val_correct += (predictions == y_batch).sum().item()\n","                val_total += y_batch.size(0)\n","\n","        train_loss /= len(train_loader)\n","        train_accuracy = train_correct / train_total\n","        val_loss /= len(val_loader)\n","        val_accuracy = val_correct / val_total\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n","              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","            # Save best model state dict\n","            best_state = model.state_dict()\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= early_stopping:\n","                print(f\"Early stopping at epoch {epoch+1}\")\n","                break\n","\n","    # Load best model\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test, device):\n","    \"\"\"Evaluate model performance for multi-class classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    X = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_test, dtype=torch.long).to(device)\n","\n","    with torch.no_grad():\n","        logits = model(X)\n","        preds = torch.argmax(logits, dim=1).cpu().numpy()\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, preds)\n","    f1 = f1_score(y_test, preds, average='macro')\n","    cm = confusion_matrix(y_test, preds)\n","\n","    print(f\"Test Accuracy: {accuracy:.4f}\")\n","    print(f\"Test Macro F1 Score: {f1:.4f}\")\n","    print(f\"Confusion Matrix shape: {cm.shape}\")\n","\n","    return {\n","        'accuracy': accuracy,\n","        'f1_macro': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","def analyze_pfi_attention_correlation(model, X_val, y_val, feature_names, device):\n","    \"\"\"Analyze correlation between PFI and attention scores for multi-class classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    # Get attention scores\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        _ = model(X)  # Forward pass to compute attention\n","        attention_scores = model.get_cls_attention().cpu().numpy()\n","\n","    # Average attention scores across samples\n","    avg_attention = attention_scores.mean(axis=0)\n","\n","    # Calculate PFI\n","    pfi_scores = calculate_pfi(model, X_val, y_val)\n","\n","    # Calculate Spearman rank correlation\n","    correlation, p_value = spearmanr(pfi_scores, avg_attention)\n","\n","    print(f\"Spearman Rank Correlation: {correlation:.4f} (p-value: {p_value:.4f})\")\n","\n","    # Create a visualization\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    # Create a scatter plot\n","    scatter = ax.scatter(pfi_scores, avg_attention, alpha=0.7)\n","\n","    # Add feature labels if feature names are not too many\n","    if len(feature_names) <= 50:  # Only add labels if there aren't too many features\n","        for i, name in enumerate(feature_names):\n","            ax.annotate(name, (pfi_scores[i], avg_attention[i]),\n","                       textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8)\n","\n","    # Add best fit line\n","    z = np.polyfit(pfi_scores, avg_attention, 1)\n","    p = np.poly1d(z)\n","    ax.plot(np.sort(pfi_scores), p(np.sort(pfi_scores)), \"r--\", alpha=0.7)\n","\n","    # Add correlation information\n","    ax.text(0.05, 0.95, f\"Spearman ρ: {correlation:.4f}\\np-value: {p_value:.4f}\",\n","            transform=ax.transAxes, verticalalignment='top',\n","            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n","\n","    ax.set_xlabel('Permutation Feature Importance')\n","    ax.set_ylabel('CLS Token Attention Score')\n","    ax.set_title('PFI vs CLS Token Attention Correlation')\n","\n","    plt.tight_layout()\n","    plt.savefig('pfi_attention_correlation_jannis.png')\n","    plt.close()\n","\n","    # Return results\n","    results = {\n","        'correlation': correlation,\n","        'p_value': p_value,\n","        'pfi_scores': pfi_scores.tolist(),\n","        'attention_scores': avg_attention.tolist(),\n","        'feature_names': feature_names\n","    }\n","\n","    return results\n","\n","def load_jannis_dataset():\n","    \"\"\"\n","    Load the Jannis dataset from OpenML (data_id=44154) with median imputation.\n","    The target labels are encoded from strings to integers using LabelEncoder.\n","\n","    Returns:\n","    - X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes\n","    \"\"\"\n","    print(\"Fetching Jannis dataset from OpenML...\")\n","    data = fetch_openml(\"jannis\", version=1,  as_frame=False)\n","    X = data.data\n","    y = data.target  # targets are strings\n","\n","    # Encode string targets to integer codes\n","    le = LabelEncoder()\n","    y = le.fit_transform(y)\n","\n","    feature_names = data.feature_names if hasattr(data, \"feature_names\") else [f\"feature_{i+1}\" for i in range(X.shape[1])]\n","\n","    # Determine number of classes\n","    num_classes = len(np.unique(y))\n","\n","    # Split the data into training, validation, and test sets\n","    X_train, X_temp, y_train, y_temp = train_test_split(\n","        X, y, test_size=0.3, random_state=42, stratify=y\n","    )\n","    X_val, X_test, y_val, y_test = train_test_split(\n","        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n","    )\n","\n","    # Impute missing values using median imputation\n","    imputer = SimpleImputer(strategy='median')\n","    X_train = imputer.fit_transform(X_train)\n","    X_val = imputer.transform(X_val)\n","    X_test = imputer.transform(X_test)\n","\n","    # Standardize features\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","    X_test = scaler.transform(X_test)\n","\n","    print(f\"Dataset loaded - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n","    print(f\"Number of classes: {num_classes}\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes\n","def tune_hyperparameters(X_train, y_train, X_val, y_val, num_classes, embedding_type='linear', n_trials=20, sparse=False):\n","    \"\"\"Tune hyperparameters using Optuna\"\"\"\n","\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=8192)\n","\n","    num_features = X_train.shape[1]\n","\n","    def objective(trial):\n","        # Define hyperparameters to tune\n","        d_token = trial.suggest_int('d_token', 32, 128)\n","        num_heads = trial.suggest_int('num_heads', 2, 8)\n","        num_layers = trial.suggest_int('num_layers', 1, 3)\n","        d_ffn = trial.suggest_int('d_ffn', 64, 256)\n","        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n","        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n","        n_bins = trial.suggest_int('n_bins', 2, 10)\n","\n","        # Ensure d_token is divisible by num_heads\n","        d_token = (d_token // num_heads) * num_heads\n","\n","        # Create model with trial hyperparameters\n","        if not sparse:\n","            model = FTTransformer(\n","                num_features=num_features,\n","                num_classes=num_classes,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","        else:\n","            model = sparseFTTransformer(\n","                num_features=num_features,\n","                num_classes=num_classes,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","\n","        # Define criterion and optimizer for multi-class classification\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","        # Train for a few epochs\n","        model.to(device)\n","        best_val_loss = float('inf')\n","\n","        patience = 5\n","        patience_counter = 0\n","        num_epochs = 20\n","\n","        # Short training loop for hyperparameter search\n","        for epoch in range(num_epochs):\n","            # Training\n","            model.train()\n","            for X_batch, y_batch in train_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                loss.backward()\n","                optimizer.step()\n","\n","            # Validation\n","            model.eval()\n","            val_loss = 0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for X_batch, y_batch in val_loader:\n","                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","                    outputs = model(X_batch)\n","                    loss = criterion(outputs, y_batch)\n","                    val_loss += loss.item()\n","\n","                    # Calculate accuracy\n","                    predictions = torch.argmax(outputs, dim=1)\n","                    val_correct += (predictions == y_batch).sum().item()\n","                    val_total += y_batch.size(0)\n","\n","            val_loss /= len(val_loader)\n","            val_accuracy = val_correct / val_total\n","\n","            # Update best validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter > patience:\n","                    break\n","\n","            trial.report(val_loss, epoch)\n","\n","            if trial.should_prune():\n","                raise optuna.TrialPruned()\n","\n","        return best_val_loss\n","\n","    # Create Optuna study\n","    study = optuna.create_study(\n","        direction=\"minimize\",\n","        pruner=optuna.pruners.MedianPruner( # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n","            n_startup_trials=5,\n","            n_warmup_steps=10,\n","            interval_steps=2\n","        )\n","    )\n","    study.optimize(objective, n_trials=n_trials, timeout=1800)\n","\n","    # Print best parameters\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","    print(f\"  Value (validation loss): {trial.value:.4f}\")\n","    print(\"  Params:\")\n","    for key, value in trial.params.items():\n","        print(f\"    {key}: {value}\")\n","\n","    # Return best parameters\n","    return trial.params\n","\n","def train_with_best_params(X_train, y_train, X_val, y_val, X_test, y_test, num_classes, best_params,\n","                         embedding_type='linear', sparse=False):\n","    \"\"\"Train a model with the best hyperparameters\"\"\"\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=8192)\n","\n","    # Ensure d_token is divisible by num_heads\n","    d_token = (best_params['d_token'] // best_params['num_heads']) * best_params['num_heads']\n","\n","    # Create model with best hyperparameters\n","    if not sparse:\n","        model = FTTransformer(\n","            num_features=X_train.shape[1],\n","            num_classes=num_classes,\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","    else:\n","        model = sparseFTTransformer(\n","            num_features=X_train.shape[1],\n","            num_classes=num_classes,\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","\n","    # Define criterion for multi-class classification\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=1e-5)\n","\n","    # Train the model with early stopping\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        device=device,\n","        epochs=100\n","    )\n","\n","    # Evaluate on test set\n","    results = evaluate_model(model, X_test, y_test, device)\n","\n","    return model, results\n","\n","def visualize_all_models(results, feature_names):\n","    \"\"\"Create a comprehensive visualization comparing all models\"\"\"\n","\n","    # Create a figure with 2x2 subplots\n","    fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n","\n","    # Plot performance metrics\n","    models = list(results.keys())\n","    acc_values = [results[model]['accuracy'] for model in models]\n","    f1_values = [results[model]['f1_macro'] for model in models]\n","\n","    # Accuracy comparison\n","    axs[0, 0].bar(models, acc_values)\n","    axs[0, 0].set_title('Accuracy Comparison (Jannis)')\n","    axs[0, 0].set_ylabel('Accuracy')\n","    axs[0, 0].tick_params(axis='x', rotation=45)\n","\n","    # F1 comparison\n","    axs[0, 1].bar(models, f1_values)\n","    axs[0, 1].set_title('Macro F1 Score Comparison (Jannis)')\n","    axs[0, 1].set_ylabel('F1 Score')\n","    axs[0, 1].tick_params(axis='x', rotation=45)\n","\n","    # Correlation comparison\n","    correlations = [results[model]['correlation_analysis']['correlation'] for model in models]\n","    p_values = [results[model]['correlation_analysis']['p_value'] for model in models]\n","\n","    axs[1, 0].bar(models, correlations)\n","    axs[1, 0].set_title('PFI-Attention Correlation Comparison (Jannis)')\n","    axs[1, 0].set_ylabel('Spearman Correlation')\n","    axs[1, 0].tick_params(axis='x', rotation=45)\n","\n","    # Feature importance comparison across models (top 10 features)\n","    axs[1, 1].axis('off')  # Turn off the axis for the text summary\n","\n","    summary_text = \"Top 10 Important Features Summary:\\n\\n\"\n","\n","    for model in models:\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Get top 10 features by PFI\n","        pfi_top_indices = np.argsort(-pfi_scores)[:10]\n","        pfi_top_features = [feature_names[i] for i in pfi_top_indices]\n","\n","        # Get top 10 features by attention\n","        attn_top_indices = np.argsort(-attn_scores)[:10]\n","        attn_top_features = [feature_names[i] for i in attn_top_indices]\n","\n","        summary_text += f\"{model}:\\n\"\n","        summary_text += f\"  Top PFI features: {', '.join(pfi_top_features)}\\n\"\n","        summary_text += f\"  Top attention features: {', '.join(attn_top_features)}\\n\\n\"\n","\n","    axs[1, 1].text(0.05, 0.95, summary_text, transform=axs[1, 1].transAxes,\n","                 verticalalignment='top', fontsize=12)\n","\n","    plt.tight_layout()\n","    plt.savefig('model_comparison_jannis.png')\n","    plt.close()\n","\n","    # Create additional visualization for feature importance comparison\n","    # For top 20 features only to avoid cluttering\n","    num_top_features = min(20, len(feature_names))\n","    fig, axs = plt.subplots(len(models), 1, figsize=(14, 5 * len(models)))\n","\n","    if len(models) == 1:\n","        axs = [axs]  # Convert to list if there's only one model\n","\n","    for i, model in enumerate(models):\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Sort features by PFI for visualization (top 20)\n","        sorted_indices = np.argsort(-pfi_scores)[:num_top_features]\n","        sorted_features = [feature_names[j] for j in sorted_indices]\n","        sorted_pfi = [pfi_scores[j] for j in sorted_indices]\n","        sorted_attn = [attn_scores[j] for j in sorted_indices]\n","\n","        x = np.arange(len(sorted_features))\n","        width = 0.35\n","\n","        axs[i].bar(x - width/2, sorted_pfi, width, label='PFI')\n","        axs[i].bar(x + width/2, sorted_attn, width, label='Attention')\n","\n","        axs[i].set_title(f'Feature Importance (Jannis): {model}')\n","        axs[i].set_ylabel('Importance Score')\n","        axs[i].set_xticks(x)\n","        axs[i].set_xticklabels(sorted_features, rotation=45, ha='right')\n","        axs[i].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig('feature_importance_comparison_jannis.png')\n","    plt.close()\n","\n","    print(\"\\nVisualizations saved as 'model_comparison_jannis.png' and 'feature_importance_comparison_jannis.png'\")\n","\n","def save_model(model, filename):\n","    torch.save(model.state_dict(), filename)\n","    print(f\"Model saved as {filename}\")\n","\n","def save_results(results, filename):\n","    # Convert numpy arrays to lists for JSON serialization\n","    for model in results:\n","        if 'correlation_analysis' in results[model]:\n","            if isinstance(results[model]['correlation_analysis']['pfi_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['pfi_scores'] = results[model]['correlation_analysis']['pfi_scores'].tolist()\n","            if isinstance(results[model]['correlation_analysis']['attention_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['attention_scores'] = results[model]['correlation_analysis']['attention_scores'].tolist()\n","\n","    with open(filename, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    print(f\"Results saved as {filename}\")\n","\n","def main_with_tuning():\n","    \"\"\"Main function to run the Jannis dataset experiments\"\"\"\n","    # Set random seed for reproducibility\n","    torch.manual_seed(42)\n","    np.random.seed(42)\n","\n","    # Set device\n","    print(f\"Using device: {device}\")\n","\n","    # Load Jannis dataset\n","    X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes = load_jannis_dataset()\n","\n","    models = {}\n","    results = {}\n","\n","    # Tune hyperparameters for Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\")\n","    linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='linear',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Linear Embedding (Tuned) ===\")\n","    ft_linear_tuned, linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        num_classes=num_classes,\n","        best_params=linear_best_params,\n","        embedding_type='linear'\n","    )\n","\n","    save_model(ft_linear_tuned, 'ft_linear_tuned_jannis.pth')\n","\n","    models['ft_linear_tuned'] = ft_linear_tuned\n","    results['ft_linear_tuned'] = linear_results\n","\n","    # Analyze PFI and attention correlation for tuned linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\")\n","    linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_linear_tuned']['correlation_analysis'] = linear_tuned_correlation\n","\n","    # Tune hyperparameters for Piecewise Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\")\n","    piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='piecewise',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Piecewise Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    ft_piecewise_tuned, piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        num_classes=num_classes,\n","        best_params=piecewise_best_params,\n","        embedding_type='piecewise'\n","    )\n","\n","    save_model(ft_piecewise_tuned, 'ft_piecewise_tuned_jannis.pth')\n","\n","    models['ft_piecewise_tuned'] = ft_piecewise_tuned\n","    results['ft_piecewise_tuned'] = piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\")\n","    piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_piecewise_tuned']['correlation_analysis'] = piecewise_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\")\n","    sparse_linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='linear',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Linear Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\")\n","    sparse_ft_linear_tuned, sparse_linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        num_classes=num_classes,\n","        best_params=sparse_linear_best_params,\n","        embedding_type='linear',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_linear_tuned, 'sparse_ft_linear_tuned_jannis.pth')\n","\n","    models['sparse_ft_linear_tuned'] = sparse_ft_linear_tuned\n","    results['sparse_ft_linear_tuned'] = sparse_linear_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\")\n","    sparse_linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_linear_tuned']['correlation_analysis'] = sparse_linear_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\")\n","    sparse_piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='piecewise',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    sparse_ft_piecewise_tuned, sparse_piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        num_classes=num_classes,\n","        best_params=sparse_piecewise_best_params,\n","        embedding_type='piecewise',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_piecewise_tuned, 'sparse_ft_piecewise_tuned_jannis.pth')\n","\n","    models['sparse_ft_piecewise_tuned'] = sparse_ft_piecewise_tuned\n","    results['sparse_ft_piecewise_tuned'] = sparse_piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\")\n","    sparse_piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_piecewise_tuned']['correlation_analysis'] = sparse_piecewise_tuned_correlation\n","\n","    # Compare the results\n","    print(\"\\n=== Comparison of Tuned Models ===\")\n","    print(f\"FT Transformer (Linear Tuned): Accuracy={results['ft_linear_tuned']['accuracy']:.4f}, F1={results['ft_linear_tuned']['f1_macro']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): Accuracy={results['ft_piecewise_tuned']['accuracy']:.4f}, F1={results['ft_piecewise_tuned']['f1_macro']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): Accuracy={results['sparse_ft_linear_tuned']['accuracy']:.4f}, F1={results['sparse_ft_linear_tuned']['f1_macro']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): Accuracy={results['sparse_ft_piecewise_tuned']['accuracy']:.4f}, F1={results['sparse_ft_piecewise_tuned']['f1_macro']:.4f}\")\n","\n","    print(\"\\n=== Comparison of PFI-Attention Correlations (Tuned Models) ===\")\n","    print(f\"FT Transformer (Linear Tuned): ρ={linear_tuned_correlation['correlation']:.4f}, p-value={linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): ρ={piecewise_tuned_correlation['correlation']:.4f}, p-value={piecewise_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): ρ={sparse_linear_tuned_correlation['correlation']:.4f}, p-value={sparse_linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): ρ={sparse_piecewise_tuned_correlation['correlation']:.4f}, p-value={sparse_piecewise_tuned_correlation['p_value']:.4f}\")\n","\n","    # Create visualization comparing all models\n","    visualize_all_models(\n","        results=results,\n","        feature_names=feature_names\n","    )\n","\n","    save_results(results, 'results_jannis.json')\n","\n","    return models, results\n","\n","if __name__ == \"__main__\":\n","    main_with_tuning()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoLqkxBXcJLr","outputId":"696fbf4a-7c06-4cd7-8704-7357dc98f125","executionInfo":{"status":"ok","timestamp":1741196117771,"user_tz":-60,"elapsed":9807052,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Fetching Jannis dataset from OpenML...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 14:52:06,415] A new study created in memory with name: no-name-d2172333-1125-4068-80a7-8267aef3d8e0\n"]},{"output_type":"stream","name":"stdout","text":["Dataset loaded - Train: (58613, 54), Val: (12560, 54), Test: (12560, 54)\n","Number of classes: 4\n","\n","=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 14:53:06,941] Trial 0 finished with value: 0.7770492732524872 and parameters: {'d_token': 59, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 143, 'lr': 0.0014667096198782846, 'dropout': 0.4798128641617625, 'n_bins': 4}. Best is trial 0 with value: 0.7770492732524872.\n","[I 2025-03-05 14:54:14,837] Trial 1 finished with value: 0.6824339032173157 and parameters: {'d_token': 79, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 134, 'lr': 0.0003138694646484146, 'dropout': 0.006345328393438987, 'n_bins': 3}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 14:55:15,629] Trial 2 finished with value: 0.710288792848587 and parameters: {'d_token': 56, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 75, 'lr': 0.00040222278381696596, 'dropout': 0.16965242796897512, 'n_bins': 5}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 14:55:46,969] Trial 3 finished with value: 0.7829163372516632 and parameters: {'d_token': 127, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 178, 'lr': 0.004825439451297976, 'dropout': 0.08352709247927986, 'n_bins': 6}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 14:56:42,389] Trial 4 finished with value: 0.7212131321430206 and parameters: {'d_token': 51, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 81, 'lr': 0.0006807737733257656, 'dropout': 0.006259968189846421, 'n_bins': 4}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 14:57:13,701] Trial 5 pruned. \n","[I 2025-03-05 14:57:44,251] Trial 6 pruned. \n","[I 2025-03-05 14:58:14,590] Trial 7 pruned. \n","[I 2025-03-05 14:58:44,872] Trial 8 pruned. \n","[I 2025-03-05 14:59:14,947] Trial 9 pruned. \n","[I 2025-03-05 15:00:24,487] Trial 10 finished with value: 0.6953632533550262 and parameters: {'d_token': 81, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 209, 'lr': 0.00017704882009392982, 'dropout': 0.1912469135548776, 'n_bins': 2}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:01:02,924] Trial 11 pruned. \n","[I 2025-03-05 15:02:13,209] Trial 12 finished with value: 0.699398010969162 and parameters: {'d_token': 80, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 211, 'lr': 0.00018513012171881576, 'dropout': 0.1931045630063235, 'n_bins': 2}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:03:23,543] Trial 13 finished with value: 0.686391681432724 and parameters: {'d_token': 81, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 127, 'lr': 0.0002498481314123912, 'dropout': 0.11089767474991769, 'n_bins': 2}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:04:01,836] Trial 14 pruned. \n","[I 2025-03-05 15:05:05,626] Trial 15 finished with value: 0.6992388069629669 and parameters: {'d_token': 71, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 113, 'lr': 0.0003158622858654982, 'dropout': 0.10023665203798382, 'n_bins': 3}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:06:15,802] Trial 16 finished with value: 0.6878127455711365 and parameters: {'d_token': 92, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 134, 'lr': 0.0008994474341920499, 'dropout': 0.25278431198798235, 'n_bins': 10}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:07:25,938] Trial 17 finished with value: 0.6964506208896637 and parameters: {'d_token': 119, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 177, 'lr': 0.00011467040192204676, 'dropout': 0.1297625053176242, 'n_bins': 3}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:08:29,145] Trial 18 finished with value: 0.6948360502719879 and parameters: {'d_token': 70, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 104, 'lr': 0.00045501728310353307, 'dropout': 0.00138273562273461, 'n_bins': 8}. Best is trial 1 with value: 0.6824339032173157.\n","[I 2025-03-05 15:09:33,240] Trial 19 finished with value: 0.6938774585723877 and parameters: {'d_token': 90, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 172, 'lr': 0.001132193111605508, 'dropout': 0.23280636832118978, 'n_bins': 5}. Best is trial 1 with value: 0.6824339032173157.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.6824\n","  Params:\n","    d_token: 79\n","    num_heads: 6\n","    num_layers: 3\n","    d_ffn: 134\n","    lr: 0.0003138694646484146\n","    dropout: 0.006345328393438987\n","    n_bins: 3\n","\n","=== Training FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.0005, Train Acc: 0.5266, Val Loss: 0.8620, Val Acc: 0.6133\n","Epoch 2/100, Train Loss: 0.8154, Train Acc: 0.6467, Val Loss: 0.7924, Val Acc: 0.6586\n","Epoch 3/100, Train Loss: 0.7652, Train Acc: 0.6747, Val Loss: 0.7533, Val Acc: 0.6810\n","Epoch 4/100, Train Loss: 0.7412, Train Acc: 0.6880, Val Loss: 0.7395, Val Acc: 0.6879\n","Epoch 5/100, Train Loss: 0.7231, Train Acc: 0.6974, Val Loss: 0.7225, Val Acc: 0.6994\n","Epoch 6/100, Train Loss: 0.7133, Train Acc: 0.7050, Val Loss: 0.7252, Val Acc: 0.6956\n","Epoch 7/100, Train Loss: 0.7081, Train Acc: 0.7060, Val Loss: 0.7121, Val Acc: 0.7037\n","Epoch 8/100, Train Loss: 0.6961, Train Acc: 0.7113, Val Loss: 0.7027, Val Acc: 0.7078\n","Epoch 9/100, Train Loss: 0.6915, Train Acc: 0.7145, Val Loss: 0.7034, Val Acc: 0.7071\n","Epoch 10/100, Train Loss: 0.6872, Train Acc: 0.7179, Val Loss: 0.7000, Val Acc: 0.7113\n","Epoch 11/100, Train Loss: 0.6811, Train Acc: 0.7204, Val Loss: 0.7024, Val Acc: 0.7106\n","Epoch 12/100, Train Loss: 0.6791, Train Acc: 0.7207, Val Loss: 0.6956, Val Acc: 0.7122\n","Epoch 13/100, Train Loss: 0.6750, Train Acc: 0.7223, Val Loss: 0.6987, Val Acc: 0.7113\n","Epoch 14/100, Train Loss: 0.6702, Train Acc: 0.7251, Val Loss: 0.6938, Val Acc: 0.7152\n","Epoch 15/100, Train Loss: 0.6686, Train Acc: 0.7239, Val Loss: 0.6895, Val Acc: 0.7127\n","Epoch 16/100, Train Loss: 0.6639, Train Acc: 0.7289, Val Loss: 0.6911, Val Acc: 0.7175\n","Epoch 17/100, Train Loss: 0.6608, Train Acc: 0.7301, Val Loss: 0.6943, Val Acc: 0.7122\n","Epoch 18/100, Train Loss: 0.6567, Train Acc: 0.7323, Val Loss: 0.6872, Val Acc: 0.7172\n","Epoch 19/100, Train Loss: 0.6537, Train Acc: 0.7334, Val Loss: 0.6976, Val Acc: 0.7173\n","Epoch 20/100, Train Loss: 0.6506, Train Acc: 0.7350, Val Loss: 0.6982, Val Acc: 0.7121\n","Epoch 21/100, Train Loss: 0.6479, Train Acc: 0.7357, Val Loss: 0.6833, Val Acc: 0.7224\n","Epoch 22/100, Train Loss: 0.6444, Train Acc: 0.7387, Val Loss: 0.6863, Val Acc: 0.7206\n","Epoch 23/100, Train Loss: 0.6413, Train Acc: 0.7387, Val Loss: 0.6842, Val Acc: 0.7220\n","Epoch 24/100, Train Loss: 0.6389, Train Acc: 0.7409, Val Loss: 0.6850, Val Acc: 0.7220\n","Epoch 25/100, Train Loss: 0.6350, Train Acc: 0.7418, Val Loss: 0.6853, Val Acc: 0.7205\n","Epoch 26/100, Train Loss: 0.6310, Train Acc: 0.7438, Val Loss: 0.6843, Val Acc: 0.7210\n","Epoch 27/100, Train Loss: 0.6313, Train Acc: 0.7452, Val Loss: 0.6877, Val Acc: 0.7239\n","Epoch 28/100, Train Loss: 0.6281, Train Acc: 0.7463, Val Loss: 0.6901, Val Acc: 0.7216\n","Epoch 29/100, Train Loss: 0.6236, Train Acc: 0.7489, Val Loss: 0.6969, Val Acc: 0.7152\n","Epoch 30/100, Train Loss: 0.6199, Train Acc: 0.7476, Val Loss: 0.6871, Val Acc: 0.7229\n","Epoch 31/100, Train Loss: 0.6165, Train Acc: 0.7520, Val Loss: 0.6879, Val Acc: 0.7214\n","Epoch 32/100, Train Loss: 0.6131, Train Acc: 0.7530, Val Loss: 0.6892, Val Acc: 0.7225\n","Epoch 33/100, Train Loss: 0.6103, Train Acc: 0.7554, Val Loss: 0.6888, Val Acc: 0.7224\n","Epoch 34/100, Train Loss: 0.6079, Train Acc: 0.7545, Val Loss: 0.6864, Val Acc: 0.7212\n","Epoch 35/100, Train Loss: 0.6043, Train Acc: 0.7581, Val Loss: 0.6944, Val Acc: 0.7190\n","Epoch 36/100, Train Loss: 0.6014, Train Acc: 0.7594, Val Loss: 0.6955, Val Acc: 0.7229\n","Epoch 37/100, Train Loss: 0.5985, Train Acc: 0.7603, Val Loss: 0.6954, Val Acc: 0.7226\n","Early stopping at epoch 37\n","Test Accuracy: 0.7151\n","Test Macro F1 Score: 0.5510\n","Confusion Matrix shape: (4, 4)\n","Model saved as ft_linear_tuned_jannis.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.8116 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 15:12:19,182] A new study created in memory with name: no-name-b7726a2f-b03b-4e65-acba-8c09a4c2eaae\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 15:15:29,888] Trial 0 finished with value: 0.7744353711605072 and parameters: {'d_token': 89, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 90, 'lr': 0.003958415730283571, 'dropout': 0.3003008962405525, 'n_bins': 8}. Best is trial 0 with value: 0.7744353711605072.\n","[I 2025-03-05 15:17:37,590] Trial 1 finished with value: 0.8090647459030151 and parameters: {'d_token': 80, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 233, 'lr': 0.0013624256965898496, 'dropout': 0.2392947337059499, 'n_bins': 4}. Best is trial 0 with value: 0.7744353711605072.\n","[I 2025-03-05 15:21:04,830] Trial 2 finished with value: 0.7477202713489532 and parameters: {'d_token': 123, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 143, 'lr': 0.0008461088366235671, 'dropout': 0.29134374687149983, 'n_bins': 9}. Best is trial 2 with value: 0.7477202713489532.\n","[I 2025-03-05 15:23:35,260] Trial 3 finished with value: 0.7850295305252075 and parameters: {'d_token': 87, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 231, 'lr': 0.00020014357358310477, 'dropout': 0.35476334303081003, 'n_bins': 5}. Best is trial 2 with value: 0.7477202713489532.\n","[I 2025-03-05 15:26:36,689] Trial 4 finished with value: 0.76617631316185 and parameters: {'d_token': 50, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 195, 'lr': 0.0051137830371540465, 'dropout': 0.37812549279974916, 'n_bins': 7}. Best is trial 2 with value: 0.7477202713489532.\n","[I 2025-03-05 15:27:43,329] Trial 5 pruned. \n","[I 2025-03-05 15:29:00,657] Trial 6 pruned. \n","[I 2025-03-05 15:31:51,071] Trial 7 finished with value: 0.7407614290714264 and parameters: {'d_token': 50, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 181, 'lr': 0.0017359456510396467, 'dropout': 0.32347373994388734, 'n_bins': 6}. Best is trial 7 with value: 0.7407614290714264.\n","[I 2025-03-05 15:33:07,112] Trial 8 pruned. \n","[I 2025-03-05 15:34:42,246] Trial 9 pruned. \n","[I 2025-03-05 15:36:52,180] Trial 10 pruned. \n","[I 2025-03-05 15:40:42,380] Trial 11 finished with value: 0.7336371839046478 and parameters: {'d_token': 127, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 147, 'lr': 0.0006597836193115981, 'dropout': 0.4220232827125545, 'n_bins': 10}. Best is trial 11 with value: 0.7336371839046478.\n","[I 2025-03-05 15:41:35,557] Trial 12 pruned. \n","[I 2025-03-05 15:43:46,769] Trial 13 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.7336\n","  Params:\n","    d_token: 127\n","    num_heads: 6\n","    num_layers: 2\n","    d_ffn: 147\n","    lr: 0.0006597836193115981\n","    dropout: 0.4220232827125545\n","    n_bins: 10\n","\n","=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.9886, Train Acc: 0.5383, Val Loss: 0.8594, Val Acc: 0.6150\n","Epoch 2/100, Train Loss: 0.8318, Train Acc: 0.6351, Val Loss: 0.8247, Val Acc: 0.6312\n","Epoch 3/100, Train Loss: 0.7982, Train Acc: 0.6540, Val Loss: 0.7966, Val Acc: 0.6522\n","Epoch 4/100, Train Loss: 0.7816, Train Acc: 0.6621, Val Loss: 0.7861, Val Acc: 0.6535\n","Epoch 5/100, Train Loss: 0.7748, Train Acc: 0.6646, Val Loss: 0.7650, Val Acc: 0.6658\n","Epoch 6/100, Train Loss: 0.7633, Train Acc: 0.6710, Val Loss: 0.7615, Val Acc: 0.6705\n","Epoch 7/100, Train Loss: 0.7558, Train Acc: 0.6760, Val Loss: 0.7603, Val Acc: 0.6745\n","Epoch 8/100, Train Loss: 0.7548, Train Acc: 0.6780, Val Loss: 0.7557, Val Acc: 0.6775\n","Epoch 9/100, Train Loss: 0.7496, Train Acc: 0.6815, Val Loss: 0.7528, Val Acc: 0.6786\n","Epoch 10/100, Train Loss: 0.7450, Train Acc: 0.6834, Val Loss: 0.7533, Val Acc: 0.6784\n","Epoch 11/100, Train Loss: 0.7416, Train Acc: 0.6859, Val Loss: 0.7557, Val Acc: 0.6752\n","Epoch 12/100, Train Loss: 0.7403, Train Acc: 0.6880, Val Loss: 0.7487, Val Acc: 0.6854\n","Epoch 13/100, Train Loss: 0.7372, Train Acc: 0.6880, Val Loss: 0.7495, Val Acc: 0.6825\n","Epoch 14/100, Train Loss: 0.7343, Train Acc: 0.6890, Val Loss: 0.7434, Val Acc: 0.6850\n","Epoch 15/100, Train Loss: 0.7316, Train Acc: 0.6930, Val Loss: 0.7583, Val Acc: 0.6822\n","Epoch 16/100, Train Loss: 0.7326, Train Acc: 0.6920, Val Loss: 0.7529, Val Acc: 0.6789\n","Epoch 17/100, Train Loss: 0.7298, Train Acc: 0.6920, Val Loss: 0.7409, Val Acc: 0.6890\n","Epoch 18/100, Train Loss: 0.7259, Train Acc: 0.6960, Val Loss: 0.7460, Val Acc: 0.6855\n","Epoch 19/100, Train Loss: 0.7238, Train Acc: 0.6966, Val Loss: 0.7404, Val Acc: 0.6861\n","Epoch 20/100, Train Loss: 0.7207, Train Acc: 0.6991, Val Loss: 0.7406, Val Acc: 0.6867\n","Epoch 21/100, Train Loss: 0.7186, Train Acc: 0.7009, Val Loss: 0.7398, Val Acc: 0.6891\n","Epoch 22/100, Train Loss: 0.7185, Train Acc: 0.6980, Val Loss: 0.7445, Val Acc: 0.6868\n","Epoch 23/100, Train Loss: 0.7170, Train Acc: 0.7017, Val Loss: 0.7471, Val Acc: 0.6856\n","Epoch 24/100, Train Loss: 0.7157, Train Acc: 0.7007, Val Loss: 0.7397, Val Acc: 0.6872\n","Epoch 25/100, Train Loss: 0.7139, Train Acc: 0.7040, Val Loss: 0.7399, Val Acc: 0.6885\n","Epoch 26/100, Train Loss: 0.7133, Train Acc: 0.7023, Val Loss: 0.7392, Val Acc: 0.6879\n","Epoch 27/100, Train Loss: 0.7103, Train Acc: 0.7062, Val Loss: 0.7357, Val Acc: 0.6912\n","Epoch 28/100, Train Loss: 0.7090, Train Acc: 0.7053, Val Loss: 0.7464, Val Acc: 0.6886\n","Epoch 29/100, Train Loss: 0.7066, Train Acc: 0.7066, Val Loss: 0.7483, Val Acc: 0.6885\n","Epoch 30/100, Train Loss: 0.7067, Train Acc: 0.7078, Val Loss: 0.7324, Val Acc: 0.6939\n","Epoch 31/100, Train Loss: 0.7056, Train Acc: 0.7081, Val Loss: 0.7464, Val Acc: 0.6898\n","Epoch 32/100, Train Loss: 0.7031, Train Acc: 0.7081, Val Loss: 0.7369, Val Acc: 0.6904\n","Epoch 33/100, Train Loss: 0.7014, Train Acc: 0.7103, Val Loss: 0.7416, Val Acc: 0.6873\n","Epoch 34/100, Train Loss: 0.6993, Train Acc: 0.7113, Val Loss: 0.7345, Val Acc: 0.6939\n","Epoch 35/100, Train Loss: 0.6990, Train Acc: 0.7113, Val Loss: 0.7384, Val Acc: 0.6890\n","Epoch 36/100, Train Loss: 0.6975, Train Acc: 0.7124, Val Loss: 0.7398, Val Acc: 0.6885\n","Epoch 37/100, Train Loss: 0.6980, Train Acc: 0.7110, Val Loss: 0.7511, Val Acc: 0.6864\n","Epoch 38/100, Train Loss: 0.6960, Train Acc: 0.7101, Val Loss: 0.7417, Val Acc: 0.6904\n","Epoch 39/100, Train Loss: 0.6922, Train Acc: 0.7151, Val Loss: 0.7467, Val Acc: 0.6831\n","Epoch 40/100, Train Loss: 0.6927, Train Acc: 0.7144, Val Loss: 0.7461, Val Acc: 0.6874\n","Epoch 41/100, Train Loss: 0.6891, Train Acc: 0.7173, Val Loss: 0.7399, Val Acc: 0.6895\n","Epoch 42/100, Train Loss: 0.6893, Train Acc: 0.7180, Val Loss: 0.7396, Val Acc: 0.6940\n","Epoch 43/100, Train Loss: 0.6881, Train Acc: 0.7151, Val Loss: 0.7471, Val Acc: 0.6889\n","Epoch 44/100, Train Loss: 0.6864, Train Acc: 0.7173, Val Loss: 0.7552, Val Acc: 0.6936\n","Epoch 45/100, Train Loss: 0.6845, Train Acc: 0.7174, Val Loss: 0.7497, Val Acc: 0.6915\n","Epoch 46/100, Train Loss: 0.6859, Train Acc: 0.7170, Val Loss: 0.7460, Val Acc: 0.6897\n","Early stopping at epoch 46\n","Test Accuracy: 0.6943\n","Test Macro F1 Score: 0.5462\n","Confusion Matrix shape: (4, 4)\n","Model saved as ft_piecewise_tuned_jannis.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 15:53:20,208] A new study created in memory with name: no-name-2857e356-2a54-4622-ba42-b16203efff58\n"]},{"output_type":"stream","name":"stdout","text":["Spearman Rank Correlation: 0.8066 (p-value: 0.0000)\n","\n","=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 15:54:48,882] Trial 0 finished with value: 0.7464688122272491 and parameters: {'d_token': 59, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 208, 'lr': 0.005054364257485555, 'dropout': 0.025742655826536176, 'n_bins': 7}. Best is trial 0 with value: 0.7464688122272491.\n","[I 2025-03-05 15:57:13,679] Trial 1 finished with value: 0.7025158405303955 and parameters: {'d_token': 64, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 115, 'lr': 0.0015112840861588538, 'dropout': 0.22126499283623952, 'n_bins': 9}. Best is trial 1 with value: 0.7025158405303955.\n","[I 2025-03-05 15:58:18,669] Trial 2 finished with value: 0.8522636294364929 and parameters: {'d_token': 109, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 73, 'lr': 0.00884646928202192, 'dropout': 0.006301712885695865, 'n_bins': 5}. Best is trial 1 with value: 0.7025158405303955.\n","[I 2025-03-05 15:59:11,132] Trial 3 finished with value: 0.8047381639480591 and parameters: {'d_token': 100, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 138, 'lr': 0.0036305751789157473, 'dropout': 0.21226082971284244, 'n_bins': 7}. Best is trial 1 with value: 0.7025158405303955.\n","[I 2025-03-05 16:00:55,807] Trial 4 finished with value: 0.7262964248657227 and parameters: {'d_token': 108, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 198, 'lr': 0.0014950484222943498, 'dropout': 0.2887915699024621, 'n_bins': 8}. Best is trial 1 with value: 0.7025158405303955.\n","[I 2025-03-05 16:02:02,131] Trial 5 pruned. \n","[I 2025-03-05 16:02:44,157] Trial 6 pruned. \n","[I 2025-03-05 16:03:47,245] Trial 7 pruned. \n","[I 2025-03-05 16:06:15,545] Trial 8 finished with value: 0.6986217200756073 and parameters: {'d_token': 56, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 150, 'lr': 0.0007255259297003161, 'dropout': 0.329671663985978, 'n_bins': 7}. Best is trial 8 with value: 0.6986217200756073.\n","[I 2025-03-05 16:08:27,357] Trial 9 finished with value: 0.6987346112728119 and parameters: {'d_token': 101, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 96, 'lr': 0.00044594833044305984, 'dropout': 0.060129556181542865, 'n_bins': 7}. Best is trial 8 with value: 0.6986217200756073.\n","[I 2025-03-05 16:09:29,625] Trial 10 pruned. \n","[I 2025-03-05 16:11:49,482] Trial 11 pruned. \n","[I 2025-03-05 16:15:21,013] Trial 12 finished with value: 0.6907961964607239 and parameters: {'d_token': 88, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 124, 'lr': 0.0005644323320956766, 'dropout': 0.3721190899870446, 'n_bins': 10}. Best is trial 12 with value: 0.6907961964607239.\n","[I 2025-03-05 16:17:48,450] Trial 13 finished with value: 0.6965274810791016 and parameters: {'d_token': 81, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 149, 'lr': 0.0006233371179846793, 'dropout': 0.406760950434745, 'n_bins': 10}. Best is trial 12 with value: 0.6907961964607239.\n","[I 2025-03-05 16:21:26,578] Trial 14 finished with value: 0.6979594230651855 and parameters: {'d_token': 127, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 118, 'lr': 0.00021802047981758378, 'dropout': 0.43504776184695687, 'n_bins': 10}. Best is trial 12 with value: 0.6907961964607239.\n","[I 2025-03-05 16:22:47,907] Trial 15 pruned. \n","[I 2025-03-05 16:26:19,046] Trial 16 finished with value: 0.6985215842723846 and parameters: {'d_token': 91, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 130, 'lr': 0.0010108614079188418, 'dropout': 0.3982940328631004, 'n_bins': 9}. Best is trial 12 with value: 0.6907961964607239.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.6908\n","  Params:\n","    d_token: 88\n","    num_heads: 6\n","    num_layers: 3\n","    d_ffn: 124\n","    lr: 0.0005644323320956766\n","    dropout: 0.3721190899870446\n","    n_bins: 10\n","\n","=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 0.8978, Train Acc: 0.6009, Val Loss: 0.7970, Val Acc: 0.6575\n","Epoch 2/100, Train Loss: 0.7820, Train Acc: 0.6665, Val Loss: 0.7596, Val Acc: 0.6756\n","Epoch 3/100, Train Loss: 0.7577, Train Acc: 0.6787, Val Loss: 0.7394, Val Acc: 0.6908\n","Epoch 4/100, Train Loss: 0.7384, Train Acc: 0.6909, Val Loss: 0.7371, Val Acc: 0.6942\n","Epoch 5/100, Train Loss: 0.7321, Train Acc: 0.6939, Val Loss: 0.7254, Val Acc: 0.7011\n","Epoch 6/100, Train Loss: 0.7178, Train Acc: 0.7026, Val Loss: 0.7248, Val Acc: 0.7045\n","Epoch 7/100, Train Loss: 0.7130, Train Acc: 0.7047, Val Loss: 0.7146, Val Acc: 0.7053\n","Epoch 8/100, Train Loss: 0.7070, Train Acc: 0.7092, Val Loss: 0.7146, Val Acc: 0.7024\n","Epoch 9/100, Train Loss: 0.7019, Train Acc: 0.7095, Val Loss: 0.7079, Val Acc: 0.7135\n","Epoch 10/100, Train Loss: 0.6962, Train Acc: 0.7129, Val Loss: 0.7061, Val Acc: 0.7150\n","Epoch 11/100, Train Loss: 0.6930, Train Acc: 0.7154, Val Loss: 0.7038, Val Acc: 0.7123\n","Epoch 12/100, Train Loss: 0.6895, Train Acc: 0.7163, Val Loss: 0.7092, Val Acc: 0.7131\n","Epoch 13/100, Train Loss: 0.6858, Train Acc: 0.7184, Val Loss: 0.7050, Val Acc: 0.7133\n","Epoch 14/100, Train Loss: 0.6830, Train Acc: 0.7191, Val Loss: 0.6968, Val Acc: 0.7138\n","Epoch 15/100, Train Loss: 0.6795, Train Acc: 0.7237, Val Loss: 0.7099, Val Acc: 0.7124\n","Epoch 16/100, Train Loss: 0.6762, Train Acc: 0.7228, Val Loss: 0.7061, Val Acc: 0.7143\n","Epoch 17/100, Train Loss: 0.6745, Train Acc: 0.7243, Val Loss: 0.6952, Val Acc: 0.7156\n","Epoch 18/100, Train Loss: 0.6720, Train Acc: 0.7259, Val Loss: 0.7112, Val Acc: 0.7130\n","Epoch 19/100, Train Loss: 0.6681, Train Acc: 0.7273, Val Loss: 0.6897, Val Acc: 0.7193\n","Epoch 20/100, Train Loss: 0.6671, Train Acc: 0.7274, Val Loss: 0.7033, Val Acc: 0.7154\n","Epoch 21/100, Train Loss: 0.6646, Train Acc: 0.7293, Val Loss: 0.6938, Val Acc: 0.7195\n","Epoch 22/100, Train Loss: 0.6605, Train Acc: 0.7331, Val Loss: 0.6884, Val Acc: 0.7194\n","Epoch 23/100, Train Loss: 0.6599, Train Acc: 0.7296, Val Loss: 0.6985, Val Acc: 0.7190\n","Epoch 24/100, Train Loss: 0.6558, Train Acc: 0.7335, Val Loss: 0.6934, Val Acc: 0.7181\n","Epoch 25/100, Train Loss: 0.6560, Train Acc: 0.7341, Val Loss: 0.7050, Val Acc: 0.7155\n","Epoch 26/100, Train Loss: 0.6537, Train Acc: 0.7334, Val Loss: 0.6946, Val Acc: 0.7176\n","Epoch 27/100, Train Loss: 0.6510, Train Acc: 0.7373, Val Loss: 0.6958, Val Acc: 0.7184\n","Epoch 28/100, Train Loss: 0.6490, Train Acc: 0.7376, Val Loss: 0.7035, Val Acc: 0.7200\n","Epoch 29/100, Train Loss: 0.6487, Train Acc: 0.7381, Val Loss: 0.7043, Val Acc: 0.7162\n","Epoch 30/100, Train Loss: 0.6468, Train Acc: 0.7368, Val Loss: 0.7017, Val Acc: 0.7169\n","Epoch 31/100, Train Loss: 0.6446, Train Acc: 0.7391, Val Loss: 0.6994, Val Acc: 0.7174\n","Epoch 32/100, Train Loss: 0.6413, Train Acc: 0.7399, Val Loss: 0.6958, Val Acc: 0.7184\n","Epoch 33/100, Train Loss: 0.6407, Train Acc: 0.7406, Val Loss: 0.7018, Val Acc: 0.7139\n","Epoch 34/100, Train Loss: 0.6371, Train Acc: 0.7435, Val Loss: 0.7038, Val Acc: 0.7127\n","Epoch 35/100, Train Loss: 0.6346, Train Acc: 0.7450, Val Loss: 0.6963, Val Acc: 0.7164\n","Epoch 36/100, Train Loss: 0.6368, Train Acc: 0.7443, Val Loss: 0.7007, Val Acc: 0.7180\n","Epoch 37/100, Train Loss: 0.6330, Train Acc: 0.7431, Val Loss: 0.7008, Val Acc: 0.7157\n","Epoch 38/100, Train Loss: 0.6302, Train Acc: 0.7447, Val Loss: 0.7031, Val Acc: 0.7218\n","Early stopping at epoch 38\n","Test Accuracy: 0.7184\n","Test Macro F1 Score: 0.5692\n","Confusion Matrix shape: (4, 4)\n","Model saved as sparse_ft_linear_tuned_jannis.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.7191 (p-value: 0.0000)\n","\n","=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 16:38:59,733] A new study created in memory with name: no-name-d3ecc555-0e2d-4c9c-a518-67add40a8b50\n","[I 2025-03-05 16:41:49,724] Trial 0 finished with value: 0.918200671672821 and parameters: {'d_token': 99, 'num_heads': 3, 'num_layers': 1, 'd_ffn': 145, 'lr': 0.003115500580837451, 'dropout': 0.12154685054366748, 'n_bins': 10}. Best is trial 0 with value: 0.918200671672821.\n","[I 2025-03-05 16:47:30,991] Trial 1 finished with value: 0.7392362654209137 and parameters: {'d_token': 49, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 244, 'lr': 0.0005758445906528505, 'dropout': 0.24213949899422166, 'n_bins': 7}. Best is trial 1 with value: 0.7392362654209137.\n","[I 2025-03-05 16:51:22,121] Trial 2 finished with value: 0.7577266097068787 and parameters: {'d_token': 60, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 137, 'lr': 0.00195986792418468, 'dropout': 0.3621898480702306, 'n_bins': 6}. Best is trial 1 with value: 0.7392362654209137.\n","[I 2025-03-05 16:55:18,259] Trial 3 finished with value: 0.9158950746059418 and parameters: {'d_token': 86, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 148, 'lr': 0.00012671779674935178, 'dropout': 0.4748614915430051, 'n_bins': 10}. Best is trial 1 with value: 0.7392362654209137.\n","[I 2025-03-05 16:59:29,328] Trial 4 finished with value: 0.7715992331504822 and parameters: {'d_token': 34, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 167, 'lr': 0.00551887014118255, 'dropout': 0.15110468647871916, 'n_bins': 7}. Best is trial 1 with value: 0.7392362654209137.\n","[I 2025-03-05 17:04:52,146] Trial 5 finished with value: 0.7359145879745483 and parameters: {'d_token': 45, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 226, 'lr': 0.000263958921319289, 'dropout': 0.06546564875662936, 'n_bins': 9}. Best is trial 5 with value: 0.7359145879745483.\n","[I 2025-03-05 17:07:34,276] Trial 6 pruned. \n","[I 2025-03-05 17:09:47,348] Trial 7 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.7359\n","  Params:\n","    d_token: 45\n","    num_heads: 8\n","    num_layers: 2\n","    d_ffn: 226\n","    lr: 0.000263958921319289\n","    dropout: 0.06546564875662936\n","    n_bins: 9\n","\n","=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.0072, Train Acc: 0.5279, Val Loss: 0.8720, Val Acc: 0.6096\n","Epoch 2/100, Train Loss: 0.8538, Train Acc: 0.6245, Val Loss: 0.8341, Val Acc: 0.6316\n","Epoch 3/100, Train Loss: 0.8275, Train Acc: 0.6410, Val Loss: 0.8120, Val Acc: 0.6440\n","Epoch 4/100, Train Loss: 0.8081, Train Acc: 0.6532, Val Loss: 0.7974, Val Acc: 0.6517\n","Epoch 5/100, Train Loss: 0.7920, Train Acc: 0.6605, Val Loss: 0.7830, Val Acc: 0.6592\n","Epoch 6/100, Train Loss: 0.7801, Train Acc: 0.6667, Val Loss: 0.7764, Val Acc: 0.6637\n","Epoch 7/100, Train Loss: 0.7718, Train Acc: 0.6710, Val Loss: 0.7737, Val Acc: 0.6674\n","Epoch 8/100, Train Loss: 0.7653, Train Acc: 0.6755, Val Loss: 0.7640, Val Acc: 0.6709\n","Epoch 9/100, Train Loss: 0.7609, Train Acc: 0.6762, Val Loss: 0.7613, Val Acc: 0.6749\n","Epoch 10/100, Train Loss: 0.7563, Train Acc: 0.6787, Val Loss: 0.7553, Val Acc: 0.6749\n","Epoch 11/100, Train Loss: 0.7521, Train Acc: 0.6793, Val Loss: 0.7555, Val Acc: 0.6727\n","Epoch 12/100, Train Loss: 0.7482, Train Acc: 0.6831, Val Loss: 0.7562, Val Acc: 0.6770\n","Epoch 13/100, Train Loss: 0.7454, Train Acc: 0.6861, Val Loss: 0.7494, Val Acc: 0.6818\n","Epoch 14/100, Train Loss: 0.7420, Train Acc: 0.6872, Val Loss: 0.7470, Val Acc: 0.6811\n","Epoch 15/100, Train Loss: 0.7389, Train Acc: 0.6892, Val Loss: 0.7470, Val Acc: 0.6822\n","Epoch 16/100, Train Loss: 0.7375, Train Acc: 0.6921, Val Loss: 0.7442, Val Acc: 0.6834\n","Epoch 17/100, Train Loss: 0.7343, Train Acc: 0.6910, Val Loss: 0.7398, Val Acc: 0.6852\n","Epoch 18/100, Train Loss: 0.7317, Train Acc: 0.6927, Val Loss: 0.7462, Val Acc: 0.6839\n","Epoch 19/100, Train Loss: 0.7301, Train Acc: 0.6954, Val Loss: 0.7428, Val Acc: 0.6856\n","Epoch 20/100, Train Loss: 0.7284, Train Acc: 0.6942, Val Loss: 0.7385, Val Acc: 0.6882\n","Epoch 21/100, Train Loss: 0.7266, Train Acc: 0.6935, Val Loss: 0.7403, Val Acc: 0.6859\n","Epoch 22/100, Train Loss: 0.7235, Train Acc: 0.6978, Val Loss: 0.7393, Val Acc: 0.6830\n","Epoch 23/100, Train Loss: 0.7239, Train Acc: 0.6986, Val Loss: 0.7438, Val Acc: 0.6872\n","Epoch 24/100, Train Loss: 0.7203, Train Acc: 0.6999, Val Loss: 0.7401, Val Acc: 0.6846\n","Epoch 25/100, Train Loss: 0.7188, Train Acc: 0.7010, Val Loss: 0.7320, Val Acc: 0.6919\n","Epoch 26/100, Train Loss: 0.7193, Train Acc: 0.7005, Val Loss: 0.7379, Val Acc: 0.6890\n","Epoch 27/100, Train Loss: 0.7143, Train Acc: 0.7035, Val Loss: 0.7329, Val Acc: 0.6929\n","Epoch 28/100, Train Loss: 0.7140, Train Acc: 0.7035, Val Loss: 0.7318, Val Acc: 0.6940\n","Epoch 29/100, Train Loss: 0.7131, Train Acc: 0.7035, Val Loss: 0.7353, Val Acc: 0.6909\n","Epoch 30/100, Train Loss: 0.7093, Train Acc: 0.7049, Val Loss: 0.7340, Val Acc: 0.6932\n","Epoch 31/100, Train Loss: 0.7093, Train Acc: 0.7055, Val Loss: 0.7371, Val Acc: 0.6878\n","Epoch 32/100, Train Loss: 0.7093, Train Acc: 0.7053, Val Loss: 0.7353, Val Acc: 0.6896\n","Epoch 33/100, Train Loss: 0.7070, Train Acc: 0.7057, Val Loss: 0.7337, Val Acc: 0.6919\n","Epoch 34/100, Train Loss: 0.7063, Train Acc: 0.7054, Val Loss: 0.7282, Val Acc: 0.6958\n","Epoch 35/100, Train Loss: 0.7054, Train Acc: 0.7081, Val Loss: 0.7345, Val Acc: 0.6916\n","Epoch 36/100, Train Loss: 0.7029, Train Acc: 0.7096, Val Loss: 0.7359, Val Acc: 0.6914\n","Epoch 37/100, Train Loss: 0.7019, Train Acc: 0.7096, Val Loss: 0.7279, Val Acc: 0.6961\n","Epoch 38/100, Train Loss: 0.7024, Train Acc: 0.7103, Val Loss: 0.7294, Val Acc: 0.6960\n","Epoch 39/100, Train Loss: 0.7001, Train Acc: 0.7100, Val Loss: 0.7282, Val Acc: 0.6979\n","Epoch 40/100, Train Loss: 0.6962, Train Acc: 0.7118, Val Loss: 0.7294, Val Acc: 0.6953\n","Epoch 41/100, Train Loss: 0.6960, Train Acc: 0.7114, Val Loss: 0.7283, Val Acc: 0.6963\n","Epoch 42/100, Train Loss: 0.6958, Train Acc: 0.7121, Val Loss: 0.7275, Val Acc: 0.6971\n","Epoch 43/100, Train Loss: 0.6942, Train Acc: 0.7142, Val Loss: 0.7301, Val Acc: 0.6938\n","Epoch 44/100, Train Loss: 0.6923, Train Acc: 0.7146, Val Loss: 0.7285, Val Acc: 0.6964\n","Epoch 45/100, Train Loss: 0.6912, Train Acc: 0.7144, Val Loss: 0.7305, Val Acc: 0.6926\n","Epoch 46/100, Train Loss: 0.6901, Train Acc: 0.7157, Val Loss: 0.7310, Val Acc: 0.6979\n","Epoch 47/100, Train Loss: 0.6884, Train Acc: 0.7161, Val Loss: 0.7375, Val Acc: 0.6900\n","Epoch 48/100, Train Loss: 0.6894, Train Acc: 0.7166, Val Loss: 0.7297, Val Acc: 0.6977\n","Epoch 49/100, Train Loss: 0.6882, Train Acc: 0.7161, Val Loss: 0.7316, Val Acc: 0.6945\n","Epoch 50/100, Train Loss: 0.6858, Train Acc: 0.7176, Val Loss: 0.7371, Val Acc: 0.6964\n","Epoch 51/100, Train Loss: 0.6837, Train Acc: 0.7195, Val Loss: 0.7294, Val Acc: 0.6937\n","Epoch 52/100, Train Loss: 0.6841, Train Acc: 0.7200, Val Loss: 0.7300, Val Acc: 0.6970\n","Epoch 53/100, Train Loss: 0.6839, Train Acc: 0.7200, Val Loss: 0.7262, Val Acc: 0.6982\n","Epoch 54/100, Train Loss: 0.6804, Train Acc: 0.7210, Val Loss: 0.7260, Val Acc: 0.6998\n","Epoch 55/100, Train Loss: 0.6794, Train Acc: 0.7220, Val Loss: 0.7292, Val Acc: 0.6972\n","Epoch 56/100, Train Loss: 0.6813, Train Acc: 0.7204, Val Loss: 0.7287, Val Acc: 0.6990\n","Epoch 57/100, Train Loss: 0.6782, Train Acc: 0.7216, Val Loss: 0.7372, Val Acc: 0.6947\n","Epoch 58/100, Train Loss: 0.6770, Train Acc: 0.7228, Val Loss: 0.7350, Val Acc: 0.6967\n","Epoch 59/100, Train Loss: 0.6759, Train Acc: 0.7233, Val Loss: 0.7301, Val Acc: 0.6922\n","Epoch 60/100, Train Loss: 0.6751, Train Acc: 0.7232, Val Loss: 0.7276, Val Acc: 0.6971\n","Epoch 61/100, Train Loss: 0.6729, Train Acc: 0.7226, Val Loss: 0.7316, Val Acc: 0.6951\n","Epoch 62/100, Train Loss: 0.6718, Train Acc: 0.7245, Val Loss: 0.7300, Val Acc: 0.6963\n","Epoch 63/100, Train Loss: 0.6725, Train Acc: 0.7230, Val Loss: 0.7337, Val Acc: 0.6914\n","Epoch 64/100, Train Loss: 0.6711, Train Acc: 0.7250, Val Loss: 0.7349, Val Acc: 0.6958\n","Epoch 65/100, Train Loss: 0.6685, Train Acc: 0.7259, Val Loss: 0.7283, Val Acc: 0.6994\n","Epoch 66/100, Train Loss: 0.6683, Train Acc: 0.7273, Val Loss: 0.7324, Val Acc: 0.6939\n","Epoch 67/100, Train Loss: 0.6675, Train Acc: 0.7264, Val Loss: 0.7349, Val Acc: 0.6927\n","Epoch 68/100, Train Loss: 0.6647, Train Acc: 0.7277, Val Loss: 0.7364, Val Acc: 0.6942\n","Epoch 69/100, Train Loss: 0.6663, Train Acc: 0.7267, Val Loss: 0.7342, Val Acc: 0.6928\n","Epoch 70/100, Train Loss: 0.6632, Train Acc: 0.7295, Val Loss: 0.7361, Val Acc: 0.6953\n","Early stopping at epoch 70\n","Test Accuracy: 0.6971\n","Test Macro F1 Score: 0.5297\n","Confusion Matrix shape: (4, 4)\n","Model saved as sparse_ft_piecewise_tuned_jannis.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.6975 (p-value: 0.0000)\n","\n","=== Comparison of Tuned Models ===\n","FT Transformer (Linear Tuned): Accuracy=0.7151, F1=0.5510\n","FT Transformer (Piecewise Tuned): Accuracy=0.6943, F1=0.5462\n","Sparse FT Transformer (Linear Tuned): Accuracy=0.7184, F1=0.5692\n","Sparse FT Transformer (Piecewise Tuned): Accuracy=0.6971, F1=0.5297\n","\n","=== Comparison of PFI-Attention Correlations (Tuned Models) ===\n","FT Transformer (Linear Tuned): ρ=0.8116, p-value=0.0000\n","FT Transformer (Piecewise Tuned): ρ=0.8066, p-value=0.0000\n","Sparse FT Transformer (Linear Tuned): ρ=0.7191, p-value=0.0000\n","Sparse FT Transformer (Piecewise Tuned): ρ=0.6975, p-value=0.0000\n","\n","Visualizations saved as 'model_comparison_jannis.png' and 'feature_importance_comparison_jannis.png'\n","Results saved as results_jannis.json\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from google.colab import drive\n","\n","def save_all_files_to_drive(folder_name='Jannis_Files'):\n","  \"\"\"Saves all files in the current Colab environment to a new folder in Google Drive.\n","\n","  Args:\n","    folder_name: The name of the folder to create in Google Drive. Defaults to 'Colab_Files'.\n","  \"\"\"\n","\n","  # Mount Google Drive\n","  drive.mount('/content/drive')\n","\n","  # Create the folder in Google Drive\n","  folder_path = os.path.join('/content/drive/My Drive', folder_name)\n","  os.makedirs(folder_path, exist_ok=True)\n","\n","  # Get a list of all files in the current directory\n","  files = os.listdir('.')\n","\n","  # Copy each file to the Google Drive folder\n","  for file in files:\n","    source_path = os.path.join('.', file)\n","    destination_path = os.path.join(folder_path, file)\n","    os.system(f'cp \"{source_path}\" \"{destination_path}\"')  # Using os.system for file copying\n","\n","  print(f\"All files saved to Google Drive: /content/drive/My Drive/{folder_name}\")\n","\n","save_all_files_to_drive()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exIKH02UxXgp","executionInfo":{"status":"ok","timestamp":1741196249243,"user_tz":-60,"elapsed":25195,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"66ad9056-57a2-467b-de3e-f8f86268c0c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","All files saved to Google Drive: /content/drive/My Drive/Jannis_Files\n"]}]}]}