{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOY6jEuVvJUh/viutHo1mnl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install optuna\n","%pip install sparsemax # https://pypi.org/project/sparsemax/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Tc3NgvLqeox8","executionInfo":{"status":"ok","timestamp":1741174316917,"user_tz":-60,"elapsed":125618,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"4aa55c39-27a2-41fa-bcbb-82c5773e2dc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n","Collecting sparsemax\n","  Downloading sparsemax-0.1.9-py2.py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from sparsemax) (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->sparsemax)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sparsemax)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sparsemax)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sparsemax)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sparsemax)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sparsemax)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->sparsemax) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->sparsemax) (3.0.2)\n","Downloading sparsemax-0.1.9-py2.py3-none-any.whl (5.5 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sparsemax\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sparsemax-0.1.9\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sparsemax import Sparsemax\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.datasets import fetch_openml\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","from scipy.stats import spearmanr\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import optuna\n","import json\n","import os\n","from urllib.request import urlretrieve\n","import zipfile\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","sparsemax = Sparsemax(dim=-1)\n","\n","class TabularDataset(Dataset):\n","    \"\"\"Dataset for tabular data with continuous features\"\"\"\n","    def __init__(self, X, y=None):\n","        # Continuous features\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","\n","        # Target\n","        if y is not None:\n","            self.y = torch.tensor(y, dtype=torch.long)\n","        else:\n","            self.y = None\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.X[idx], self.y[idx]\n","        else:\n","            return self.X[idx]\n","\n","'''\n","The code below has been adapted from the original codebase.\n","\n","For the implementation of the FT Transformer, please check out this repository: https://github.com/yandex-research/rtdl-revisiting-models\n","\n","For the implementation of the Piecewise Linear Embedding, please check out: https://github.com/yandex-research/rtdl-num-embeddings\n","'''\n","\n","class LinearEmbedding(nn.Module):\n","    \"\"\"Linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token):\n","        super().__init__()\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(1, d_token) for _ in range(num_features)\n","        ])\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_cont_features)\n","        batch_size = x.shape[0]\n","        num_features = x.shape[1]\n","\n","        # Embed each continuous feature\n","        embedded = torch.zeros((batch_size, num_features, self.embeddings[0].out_features),\n","                              device=x.device)\n","\n","        for i in range(num_features):\n","            embedded[:, i] = self.embeddings[i](x[:, i].unsqueeze(-1)).squeeze(-1)\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","class PiecewiseLinearEmbedding(nn.Module):\n","    \"\"\"Piecewise linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token, num_bins=20):\n","        super().__init__()\n","        self.num_features = num_features\n","        self.d_token = d_token\n","        self.num_bins = num_bins\n","\n","        # Create embeddings for each feature\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(num_bins, d_token) for _ in range(num_features)\n","        ])\n","\n","        # Create parameters for bin boundaries (learnable)\n","        self.bin_boundaries = nn.Parameter(torch.randn(num_features, num_bins-1))\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        batch_size = x.shape[0]\n","\n","        # Output will contain embedded tokens for each feature\n","        embedded = torch.zeros((batch_size, self.num_features, self.d_token), device=x.device)\n","\n","        for i in range(self.num_features):\n","            # Get feature values for current feature\n","            feature_values = x[:, i].unsqueeze(1)  # (batch_size, 1)\n","\n","            # Get sorted boundaries for this feature\n","            boundaries = torch.sort(self.bin_boundaries[i]).values  # (num_bins-1)\n","\n","            # Calculate bin activations using cumulative distribution\n","            # Start with all in the first bin\n","            bin_activations = torch.ones((batch_size, self.num_bins), device=x.device)\n","\n","            # Update bin activations based on feature values and boundaries\n","            for j in range(self.num_bins-1):\n","                boundary = boundaries[j]\n","                # Calculate contribution to bins based on boundary comparison\n","                condition = feature_values > boundary\n","                # Move activations to next bin when condition is true\n","                bin_activations[:, j+1:] = torch.where(\n","                    condition.expand(-1, self.num_bins-j-1),\n","                    bin_activations[:, j:self.num_bins-1],\n","                    bin_activations[:, j+1:]\n","                )\n","                bin_activations[:, j] = torch.where(\n","                    condition.squeeze(1),\n","                    0.0,\n","                    bin_activations[:, j]\n","                )\n","\n","            # Apply linear transformation to get embeddings\n","            feature_embedding = self.embeddings[i](bin_activations)  # (batch_size, d_token)\n","            embedded[:, i] = feature_embedding\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","# Custom attention module to capture attention weights\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply softmax to get attention weights\n","        attention_weights = F.softmax(scores, dim=-1)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","# Custom transformer layer to capture attention weights\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20, num_classes=100):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","        self.num_classes = num_classes\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            TransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for multiclass classification\n","        self.output_layer = nn.Linear(d_token, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","# Sparse attention variants\n","class sparseMultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply sparsemax to get attention weights\n","        attention_weights = sparsemax(scores)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","class sparseTransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = sparseMultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class sparseFTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20, num_classes=100):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","        self.num_classes = num_classes\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers with sparse attention\n","        self.transformer_layers = nn.ModuleList([\n","            sparseTransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for multiclass classification\n","        self.output_layer = nn.Linear(d_token, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (logits)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","def calculate_pfi(model, X_val, y_val, num_permutations=5):\n","    \"\"\"Calculate Permutation Feature Importance (PFI) for multiclass classification\"\"\"\n","    # Convert to PyTorch tensors\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_val, dtype=torch.long).to(device)\n","\n","    # Get baseline performance\n","    model.eval()\n","    with torch.no_grad():\n","        baseline_preds = model(X)\n","        baseline_loss = F.cross_entropy(baseline_preds, y).item()\n","        baseline_preds_class = torch.argmax(baseline_preds, dim=1)\n","        baseline_accuracy = (baseline_preds_class == y).float().mean().item()\n","\n","    # Calculate importance for each feature\n","    importances = []\n","\n","    for feat_idx in range(X.shape[1]):\n","        accuracies = []\n","\n","        for _ in range(num_permutations):\n","            # Create a permuted copy of the data\n","            X_permuted = X.clone()\n","\n","            # Permute the feature\n","            perm_idx = torch.randperm(X.shape[0])\n","            X_permuted[:, feat_idx] = X_permuted[perm_idx, feat_idx]\n","\n","            # Calculate loss with permuted feature\n","            with torch.no_grad():\n","                perm_preds = model(X_permuted)\n","                perm_preds_class = torch.argmax(perm_preds, dim=1)\n","                perm_accuracy = (perm_preds_class == y).float().mean().item()\n","\n","            # Feature importance is the decrease in accuracy\n","            accuracies.append(baseline_accuracy - perm_accuracy)\n","\n","        # Average over permutations (higher = more important)\n","        importances.append(np.mean(accuracies))\n","\n","    return np.array(importances)\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=100, early_stopping=16):\n","    \"\"\"Train the model with early stopping\"\"\"\n","    model.to(device)\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","    best_state = None\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_correct += (predicted == y_batch).sum().item()\n","            train_total += y_batch.size(0)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","\n","        with torch.no_grad():\n","            for X_batch, y_batch in val_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                val_loss += loss.item()\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(outputs.data, 1)\n","                val_correct += (predicted == y_batch).sum().item()\n","                val_total += y_batch.size(0)\n","\n","        train_loss /= len(train_loader)\n","        train_accuracy = train_correct / train_total\n","        val_loss /= len(val_loader)\n","        val_accuracy = val_correct / val_total\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n","              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","            # Save best model state dict\n","            best_state = model.state_dict()\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= early_stopping:\n","                print(f\"Early stopping at epoch {epoch+1}\")\n","                break\n","\n","    # Load best model\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test, device):\n","    \"\"\"Evaluate model performance for multiclass classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    X = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_test, dtype=torch.long).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(X)\n","        _, predicted = torch.max(outputs.data, 1)\n","        predicted = predicted.cpu().numpy()\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, predicted)\n","    f1_macro = f1_score(y_test, predicted, average='macro')\n","    f1_weighted = f1_score(y_test, predicted, average='weighted')\n","\n","    # Confusion matrix (might be large for many classes)\n","    # If there are many classes, we'll just save the confusion matrix without printing it\n","    cm = confusion_matrix(y_test, predicted)\n","\n","    print(f\"Test Accuracy: {accuracy:.4f}\")\n","    print(f\"Test Macro F1 Score: {f1_macro:.4f}\")\n","    print(f\"Test Weighted F1 Score: {f1_weighted:.4f}\")\n","    print(f\"Confusion Matrix shape: {cm.shape}\")\n","\n","    return {\n","        'accuracy': accuracy,\n","        'f1_macro': f1_macro,\n","        'f1_weighted': f1_weighted,\n","        'confusion_matrix': cm.tolist() if cm.shape[0] <= 10 else \"Too large to include\"\n","    }\n","\n","def analyze_pfi_attention_correlation(model, X_val, y_val, feature_names, device):\n","    \"\"\"Analyze correlation between PFI and attention scores for multiclass classification\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    # Get attention scores\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        _ = model(X)  # Forward pass to compute attention\n","        attention_scores = model.get_cls_attention().cpu().numpy()\n","\n","    # Average attention scores across samples\n","    avg_attention = attention_scores.mean(axis=0)\n","\n","    # Calculate PFI\n","    pfi_scores = calculate_pfi(model, X_val, y_val)\n","\n","    # Calculate Spearman rank correlation\n","    correlation, p_value = spearmanr(pfi_scores, avg_attention)\n","\n","    print(f\"Spearman Rank Correlation: {correlation:.4f} (p-value: {p_value:.4f})\")\n","\n","    # Create a visualization\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    # Create a scatter plot\n","    scatter = ax.scatter(pfi_scores, avg_attention, alpha=0.7)\n","\n","    # Add feature labels (if not too many)\n","    if len(feature_names) <= 30:\n","        for i, name in enumerate(feature_names):\n","            ax.annotate(name, (pfi_scores[i], avg_attention[i]),\n","                       textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8)\n","\n","    # Add best fit line\n","    z = np.polyfit(pfi_scores, avg_attention, 1)\n","    p = np.poly1d(z)\n","    ax.plot(np.sort(pfi_scores), p(np.sort(pfi_scores)), \"r--\", alpha=0.7)\n","\n","    # Add correlation information\n","    ax.text(0.05, 0.95, f\"Spearman ρ: {correlation:.4f}\\np-value: {p_value:.4f}\",\n","            transform=ax.transAxes, verticalalignment='top',\n","            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n","\n","    ax.set_xlabel('Permutation Feature Importance')\n","    ax.set_ylabel('CLS Token Attention Score')\n","    ax.set_title('PFI vs CLS Token Attention Correlation')\n","\n","    plt.tight_layout()\n","    plt.savefig('pfi_attention_correlation_helena.png')\n","    plt.close()\n","\n","    # Return results\n","    results = {\n","        'correlation': correlation,\n","        'p_value': p_value,\n","        'pfi_scores': pfi_scores.tolist(),\n","        'attention_scores': avg_attention.tolist(),\n","        'feature_names': feature_names\n","    }\n","\n","    return results\n","\n","def load_helena_dataset():\n","    \"\"\"\n","    Load the Helena dataset (anonymized dataset from Guyon et al. 2019) from OpenML.\n","\n","    Returns:\n","    - X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes\n","    \"\"\"\n","    print(\"Fetching Helena dataset from OpenML...\")\n","    data = fetch_openml(name=\"helena\", version=1, as_frame=False)\n","    X = data.data\n","    y = data.target.astype(np.int32)  # Ensure target is of integer type\n","    feature_names = data.feature_names if hasattr(data, \"feature_names\") else [f\"feature_{i+1}\" for i in range(X.shape[1])]\n","\n","    # Determine number of classes\n","    num_classes = len(np.unique(y))\n","\n","    # Split the data into training, validation, and test sets\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","    # Impute missing values using median imputation\n","    imputer = SimpleImputer(strategy='median')\n","    X_train = imputer.fit_transform(X_train)\n","    X_val = imputer.transform(X_val)\n","    X_test = imputer.transform(X_test)\n","\n","    # Standardize features\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","    X_test = scaler.transform(X_test)\n","\n","    print(f\"Dataset loaded - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n","    print(f\"Number of classes: {num_classes}\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes\n","\n","\n","\n","def tune_hyperparameters(X_train, y_train, X_val, y_val, num_classes, embedding_type='linear', n_trials=20, sparse=False):\n","    \"\"\"Tune hyperparameters using Optuna for multiclass classification\"\"\"\n","\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=8192)\n","\n","    num_features = X_train.shape[1]\n","\n","    def objective(trial):\n","        # Define hyperparameters to tune\n","        d_token = trial.suggest_int('d_token', 32, 128)\n","        num_heads = trial.suggest_int('num_heads', 2, 8)\n","        num_layers = trial.suggest_int('num_layers', 1, 3)\n","        d_ffn = trial.suggest_int('d_ffn', 64, 256)\n","        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n","        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n","        n_bins = trial.suggest_int('n_bins', 2, 50)\n","\n","        # Ensure d_token is divisible by num_heads\n","        d_token = (d_token // num_heads) * num_heads\n","\n","        # Create model with trial hyperparameters\n","        if not sparse:\n","            model = FTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins,\n","                num_classes=num_classes\n","            )\n","        else:\n","            model = sparseFTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins,\n","                num_classes=num_classes\n","            )\n","\n","        # Define criterion and optimizer for multiclass classification\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","        # Train for a few epochs\n","        model.to(device)\n","        best_val_loss = float('inf')\n","\n","        patience = 5\n","        patience_counter = 0\n","        num_epochs = 20\n","\n","        # Short training loop for hyperparameter search\n","        for epoch in range(num_epochs):\n","            # Training\n","            model.train()\n","            for X_batch, y_batch in train_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                loss.backward()\n","                optimizer.step()\n","\n","            # Validation\n","            model.eval()\n","            val_loss = 0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for X_batch, y_batch in val_loader:\n","                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","                    outputs = model(X_batch)\n","                    loss = criterion(outputs, y_batch)\n","                    val_loss += loss.item()\n","\n","                    # Calculate accuracy\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    val_correct += (predicted == y_batch).sum().item()\n","                    val_total += y_batch.size(0)\n","\n","            val_loss /= len(val_loader)\n","            val_accuracy = val_correct / val_total\n","\n","            # Update best validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter > patience:\n","                    break\n","\n","            trial.report(val_loss, epoch)\n","\n","            if trial.should_prune():\n","                raise optuna.TrialPruned()\n","\n","        return best_val_loss\n","\n","    # Create Optuna study\n","    study = optuna.create_study(\n","        direction=\"minimize\",\n","        pruner=optuna.pruners.MedianPruner( # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n","            n_startup_trials=5,\n","            n_warmup_steps=10,\n","            interval_steps=2\n","        )\n","    )\n","    study.optimize(objective, n_trials=n_trials)\n","\n","    # Print best parameters\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","    print(f\"  Value (validation loss): {trial.value:.4f}\")\n","    print(\"  Params:\")\n","    for key, value in trial.params.items():\n","        print(f\"    {key}: {value}\")\n","\n","    # Return best parameters\n","    return trial.params\n","\n","def train_with_best_params(X_train, y_train, X_val, y_val, X_test, y_test, best_params,\n","                         num_classes, embedding_type='linear', sparse=False):\n","    \"\"\"Train a model with the best hyperparameters for multiclass classification\"\"\"\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=8192)\n","\n","    # Ensure d_token is divisible by num_heads\n","    d_token = (best_params['d_token'] // best_params['num_heads']) * best_params['num_heads']\n","\n","    # Create model with best hyperparameters\n","    if not sparse:\n","        model = FTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins'],\n","            num_classes=num_classes\n","        )\n","    else:\n","        model = sparseFTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins'],\n","            num_classes=num_classes\n","        )\n","\n","    # Define criterion for multiclass classification\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=1e-5)\n","\n","    # Train the model with early stopping\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        device=device,\n","        epochs=100\n","    )\n","\n","    # Evaluate on test set\n","    results = evaluate_model(model, X_test, y_test, device)\n","\n","    return model, results\n","\n","def visualize_all_models(results, feature_names):\n","    \"\"\"Create a comprehensive visualization comparing all models\"\"\"\n","\n","    # Create a figure with 2x2 subplots\n","    fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n","\n","    # Plot performance metrics\n","    models = list(results.keys())\n","    acc_values = [results[model]['accuracy'] for model in models]\n","    f1_macro_values = [results[model]['f1_macro'] for model in models]\n","    f1_weighted_values = [results[model]['f1_weighted'] for model in models]\n","\n","    # Accuracy comparison\n","    axs[0, 0].bar(models, acc_values)\n","    axs[0, 0].set_title('Accuracy Comparison (Helena)')\n","    axs[0, 0].set_ylabel('Accuracy')\n","    axs[0, 0].tick_params(axis='x', rotation=45)\n","\n","    # F1 score comparison\n","    x = np.arange(len(models))\n","    width = 0.35\n","    axs[0, 1].bar(x - width/2, f1_macro_values, width, label='F1 Macro')\n","    axs[0, 1].bar(x + width/2, f1_weighted_values, width, label='F1 Weighted')\n","    axs[0, 1].set_title('F1 Score Comparison (Helena)')\n","    axs[0, 1].set_xticks(x)\n","    axs[0, 1].set_xticklabels(models, rotation=45)\n","    axs[0, 1].set_ylabel('F1 Score')\n","    axs[0, 1].legend()\n","\n","    # Correlation comparison\n","    correlations = [results[model]['correlation_analysis']['correlation'] for model in models]\n","    p_values = [results[model]['correlation_analysis']['p_value'] for model in models]\n","\n","    axs[1, 0].bar(models, correlations)\n","    axs[1, 0].set_title('PFI-Attention Correlation Comparison (Helena)')\n","    axs[1, 0].set_ylabel('Spearman Correlation')\n","    axs[1, 0].tick_params(axis='x', rotation=45)\n","\n","    # Feature importance summary (top 10 features)\n","    axs[1, 1].axis('off')  # Turn off the axis for the text summary\n","\n","    summary_text = \"Top 10 Important Features Summary:\\n\\n\"\n","\n","    for model in models:\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Get top 10 features by PFI\n","        pfi_top_indices = np.argsort(-pfi_scores)[:10]\n","        pfi_top_features = [feature_names[i] for i in pfi_top_indices]\n","\n","        # Get top 10 features by attention\n","        attn_top_indices = np.argsort(-attn_scores)[:10]\n","        attn_top_features = [feature_names[i] for i in attn_top_indices]\n","\n","        summary_text += f\"{model}:\\n\"\n","        summary_text += f\"  Top PFI features: {', '.join(pfi_top_features)}\\n\"\n","        summary_text += f\"  Top attention features: {', '.join(attn_top_features)}\\n\\n\"\n","\n","    axs[1, 1].text(0.05, 0.95, summary_text, transform=axs[1, 1].transAxes,\n","                 verticalalignment='top', fontsize=12)\n","\n","    plt.tight_layout()\n","    plt.savefig('model_comparison_helena.png')\n","    plt.close()\n","\n","    # Create additional visualization for feature importance comparison\n","    # For top 20 features only to avoid cluttering\n","    num_top_features = min(20, len(feature_names))\n","    fig, axs = plt.subplots(len(models), 1, figsize=(14, 5 * len(models)))\n","\n","    if len(models) == 1:\n","        axs = [axs]  # Convert to list if there's only one model\n","\n","    for i, model in enumerate(models):\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Sort features by PFI for visualization (top 20)\n","        sorted_indices = np.argsort(-pfi_scores)[:num_top_features]\n","        sorted_features = [feature_names[j] for j in sorted_indices]\n","        sorted_pfi = [pfi_scores[j] for j in sorted_indices]\n","        sorted_attn = [attn_scores[j] for j in sorted_indices]\n","\n","        x = np.arange(len(sorted_features))\n","        width = 0.35\n","\n","        axs[i].bar(x - width/2, sorted_pfi, width, label='PFI')\n","        axs[i].bar(x + width/2, sorted_attn, width, label='Attention')\n","\n","        axs[i].set_title(f'Top 20 Feature Importance (Helena): {model}')\n","        axs[i].set_ylabel('Importance Score')\n","        axs[i].set_xticks(x)\n","        axs[i].set_xticklabels(sorted_features, rotation=45, ha='right')\n","        axs[i].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig('feature_importance_comparison_helena.png')\n","    plt.close()\n","\n","    print(\"\\nVisualizations saved as 'model_comparison_helena.png' and 'feature_importance_comparison_helena.png'\")\n","\n","def save_model(model, filename):\n","    torch.save(model.state_dict(), filename)\n","    print(f\"Model saved as {filename}\")\n","\n","def save_results(results, filename):\n","    # Convert numpy arrays to lists for json serialization\n","    for model in results:\n","        if 'correlation_analysis' in results[model]:\n","            if isinstance(results[model]['correlation_analysis']['pfi_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['pfi_scores'] = results[model]['correlation_analysis']['pfi_scores'].tolist()\n","            if isinstance(results[model]['correlation_analysis']['attention_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['attention_scores'] = results[model]['correlation_analysis']['attention_scores'].tolist()\n","\n","    with open(filename, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    print(f\"Results saved as {filename}\")\n","\n","def main_with_tuning():\n","    \"\"\"Main function to run the Helena dataset experiments\"\"\"\n","    # Set random seed for reproducibility\n","    torch.manual_seed(42)\n","    np.random.seed(42)\n","\n","    # Set device\n","    print(f\"Using device: {device}\")\n","\n","    # Load Helena dataset\n","    X_train, X_val, X_test, y_train, y_val, y_test, feature_names, num_classes = load_helena_dataset()\n","\n","    models = {}\n","    results = {}\n","\n","    # Tune hyperparameters for Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\")\n","    linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='linear',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Linear Embedding (Tuned) ===\")\n","    ft_linear_tuned, linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=linear_best_params,\n","        num_classes=num_classes,\n","        embedding_type='linear'\n","    )\n","\n","    save_model(ft_linear_tuned, 'ft_linear_tuned_helena.pth')\n","\n","    models['ft_linear_tuned'] = ft_linear_tuned\n","    results['ft_linear_tuned'] = linear_results\n","\n","    # Analyze PFI and attention correlation for tuned linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\")\n","    linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_linear_tuned']['correlation_analysis'] = linear_tuned_correlation\n","\n","    # Tune hyperparameters for Piecewise Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\")\n","    piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='piecewise',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Piecewise Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    ft_piecewise_tuned, piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=piecewise_best_params,\n","        num_classes=num_classes,\n","        embedding_type='piecewise'\n","    )\n","\n","    save_model(ft_piecewise_tuned, 'ft_piecewise_tuned_helena.pth')\n","\n","    models['ft_piecewise_tuned'] = ft_piecewise_tuned\n","    results['ft_piecewise_tuned'] = piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\")\n","    piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_piecewise_tuned']['correlation_analysis'] = piecewise_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\")\n","    sparse_linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='linear',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Linear Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\")\n","    sparse_ft_linear_tuned, sparse_linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_linear_best_params,\n","        num_classes=num_classes,\n","        embedding_type='linear',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_linear_tuned, 'sparse_ft_linear_tuned_helena.pth')\n","\n","    models['sparse_ft_linear_tuned'] = sparse_ft_linear_tuned\n","    results['sparse_ft_linear_tuned'] = sparse_linear_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\")\n","    sparse_linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_linear_tuned']['correlation_analysis'] = sparse_linear_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\")\n","    sparse_piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        num_classes=num_classes,\n","        embedding_type='piecewise',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    sparse_ft_piecewise_tuned, sparse_piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_piecewise_best_params,\n","        num_classes=num_classes,\n","        embedding_type='piecewise',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_piecewise_tuned, 'sparse_ft_piecewise_tuned_helena.pth')\n","\n","    models['sparse_ft_piecewise_tuned'] = sparse_ft_piecewise_tuned\n","    results['sparse_ft_piecewise_tuned'] = sparse_piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\")\n","    sparse_piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_piecewise_tuned']['correlation_analysis'] = sparse_piecewise_tuned_correlation\n","\n","    # Compare the results\n","    print(\"\\n=== Comparison of Tuned Models ===\")\n","    print(f\"FT Transformer (Linear Tuned): Accuracy={results['ft_linear_tuned']['accuracy']:.4f}, F1 Macro={results['ft_linear_tuned']['f1_macro']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): Accuracy={results['ft_piecewise_tuned']['accuracy']:.4f}, F1 Macro={results['ft_piecewise_tuned']['f1_macro']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): Accuracy={results['sparse_ft_linear_tuned']['accuracy']:.4f}, F1 Macro={results['sparse_ft_linear_tuned']['f1_macro']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): Accuracy={results['sparse_ft_piecewise_tuned']['accuracy']:.4f}, F1 Macro={results['sparse_ft_piecewise_tuned']['f1_macro']:.4f}\")\n","\n","    print(\"\\n=== Comparison of PFI-Attention Correlations (Tuned Models) ===\")\n","    print(f\"FT Transformer (Linear Tuned): ρ={linear_tuned_correlation['correlation']:.4f}, p-value={linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): ρ={piecewise_tuned_correlation['correlation']:.4f}, p-value={piecewise_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): ρ={sparse_linear_tuned_correlation['correlation']:.4f}, p-value={sparse_linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): ρ={sparse_piecewise_tuned_correlation['correlation']:.4f}, p-value={sparse_piecewise_tuned_correlation['p_value']:.4f}\")\n","\n","    # Create visualization comparing all models\n","    visualize_all_models(\n","        results=results,\n","        feature_names=feature_names\n","    )\n","\n","    save_results(results, 'results_helena.json')\n","\n","    return models, results\n","\n","if __name__ == \"__main__\":\n","    main_with_tuning()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoLqkxBXcJLr","outputId":"847f6eed-484a-454d-b299-c43f09a630fa","executionInfo":{"status":"ok","timestamp":1741186384310,"user_tz":-60,"elapsed":12067389,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Fetching Helena dataset from OpenML...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 11:32:15,346] A new study created in memory with name: no-name-5bafd14a-e45a-4b5e-baeb-ba3446770ba3\n"]},{"output_type":"stream","name":"stdout","text":["Dataset loaded - Train: (45637, 27), Val: (9779, 27), Test: (9780, 27)\n","Number of classes: 100\n","\n","=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 11:32:53,419] Trial 0 finished with value: 2.8719139099121094 and parameters: {'d_token': 86, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 212, 'lr': 0.0070009447743713685, 'dropout': 0.4187854322123039, 'n_bins': 45}. Best is trial 0 with value: 2.8719139099121094.\n","[I 2025-03-05 11:33:23,069] Trial 1 finished with value: 2.761746644973755 and parameters: {'d_token': 34, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 240, 'lr': 0.0009297455475909623, 'dropout': 0.1888155081719124, 'n_bins': 43}. Best is trial 1 with value: 2.761746644973755.\n","[I 2025-03-05 11:33:52,523] Trial 2 finished with value: 2.977734923362732 and parameters: {'d_token': 36, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 234, 'lr': 0.0005302899783373215, 'dropout': 0.43453178499032824, 'n_bins': 38}. Best is trial 1 with value: 2.761746644973755.\n","[I 2025-03-05 11:34:29,517] Trial 3 finished with value: 2.8524181842803955 and parameters: {'d_token': 97, 'num_heads': 2, 'num_layers': 2, 'd_ffn': 129, 'lr': 0.00014256730635144285, 'dropout': 0.31236111121389404, 'n_bins': 22}. Best is trial 1 with value: 2.761746644973755.\n","[I 2025-03-05 11:35:18,852] Trial 4 finished with value: 2.9761611223220825 and parameters: {'d_token': 67, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 226, 'lr': 0.00979143918615421, 'dropout': 0.472079068257759, 'n_bins': 14}. Best is trial 1 with value: 2.761746644973755.\n","[I 2025-03-05 11:35:58,091] Trial 5 finished with value: 2.727551221847534 and parameters: {'d_token': 50, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 165, 'lr': 0.00022431570101309715, 'dropout': 0.054332472668213116, 'n_bins': 41}. Best is trial 5 with value: 2.727551221847534.\n","[I 2025-03-05 11:36:21,555] Trial 6 pruned. \n","[I 2025-03-05 11:37:10,260] Trial 7 finished with value: 2.7031222581863403 and parameters: {'d_token': 70, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 176, 'lr': 0.00024941012345005946, 'dropout': 0.17350905223093965, 'n_bins': 11}. Best is trial 7 with value: 2.7031222581863403.\n","[I 2025-03-05 11:37:56,435] Trial 8 finished with value: 2.7640247344970703 and parameters: {'d_token': 87, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 71, 'lr': 0.00011846643827720756, 'dropout': 0.1761048895245783, 'n_bins': 5}. Best is trial 7 with value: 2.7031222581863403.\n","[I 2025-03-05 11:38:37,391] Trial 9 finished with value: 2.7522143125534058 and parameters: {'d_token': 32, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 184, 'lr': 0.0060092007521534, 'dropout': 0.43745984069066834, 'n_bins': 14}. Best is trial 7 with value: 2.7031222581863403.\n","[I 2025-03-05 11:39:26,068] Trial 10 finished with value: 2.6404041051864624 and parameters: {'d_token': 125, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 115, 'lr': 0.0021205155252197127, 'dropout': 0.3023682454782811, 'n_bins': 2}. Best is trial 10 with value: 2.6404041051864624.\n","[I 2025-03-05 11:40:04,322] Trial 11 finished with value: 2.664352774620056 and parameters: {'d_token': 119, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 116, 'lr': 0.0027336853024166946, 'dropout': 0.30463581785735827, 'n_bins': 2}. Best is trial 10 with value: 2.6404041051864624.\n","[I 2025-03-05 11:40:44,786] Trial 12 finished with value: 2.6601520776748657 and parameters: {'d_token': 128, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 110, 'lr': 0.0022821771525977017, 'dropout': 0.31876040106301223, 'n_bins': 4}. Best is trial 10 with value: 2.6404041051864624.\n","[I 2025-03-05 11:41:23,565] Trial 13 finished with value: 2.664297103881836 and parameters: {'d_token': 128, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 97, 'lr': 0.0024330636361768717, 'dropout': 0.3171383864916808, 'n_bins': 26}. Best is trial 10 with value: 2.6404041051864624.\n","[I 2025-03-05 11:42:06,321] Trial 14 finished with value: 2.6417571306228638 and parameters: {'d_token': 109, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 134, 'lr': 0.002336183650184101, 'dropout': 0.3669440096878471, 'n_bins': 7}. Best is trial 10 with value: 2.6404041051864624.\n","[I 2025-03-05 11:42:49,360] Trial 15 finished with value: 2.6328641176223755 and parameters: {'d_token': 107, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 148, 'lr': 0.0010266892126054848, 'dropout': 0.3686107773866204, 'n_bins': 20}. Best is trial 15 with value: 2.6328641176223755.\n","[I 2025-03-05 11:43:31,563] Trial 16 finished with value: 2.5874065160751343 and parameters: {'d_token': 107, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 148, 'lr': 0.0011307753683893033, 'dropout': 0.2404640502448573, 'n_bins': 22}. Best is trial 16 with value: 2.5874065160751343.\n","[I 2025-03-05 11:44:01,084] Trial 17 finished with value: 2.6937774419784546 and parameters: {'d_token': 108, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 141, 'lr': 0.0008057789779785608, 'dropout': 0.2303916554481431, 'n_bins': 20}. Best is trial 16 with value: 2.5874065160751343.\n","[I 2025-03-05 11:44:46,577] Trial 18 finished with value: 2.599784731864929 and parameters: {'d_token': 101, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 201, 'lr': 0.0004895745587791291, 'dropout': 0.12182379668643692, 'n_bins': 30}. Best is trial 16 with value: 2.5874065160751343.\n","[I 2025-03-05 11:45:30,986] Trial 19 finished with value: 2.6108559370040894 and parameters: {'d_token': 97, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 204, 'lr': 0.00044657398418844084, 'dropout': 0.11031764221496959, 'n_bins': 29}. Best is trial 16 with value: 2.5874065160751343.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 2.5874\n","  Params:\n","    d_token: 107\n","    num_heads: 8\n","    num_layers: 2\n","    d_ffn: 148\n","    lr: 0.0011307753683893033\n","    dropout: 0.2404640502448573\n","    n_bins: 22\n","\n","=== Training FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 3.5731, Train Acc: 0.1939, Val Loss: 3.0334, Val Acc: 0.2850\n","Epoch 2/100, Train Loss: 2.9930, Train Acc: 0.2902, Val Loss: 2.8764, Val Acc: 0.3082\n","Epoch 3/100, Train Loss: 2.8754, Train Acc: 0.3092, Val Loss: 2.7850, Val Acc: 0.3231\n","Epoch 4/100, Train Loss: 2.8094, Train Acc: 0.3206, Val Loss: 2.7592, Val Acc: 0.3319\n","Epoch 5/100, Train Loss: 2.7664, Train Acc: 0.3286, Val Loss: 2.7141, Val Acc: 0.3389\n","Epoch 6/100, Train Loss: 2.7316, Train Acc: 0.3352, Val Loss: 2.6960, Val Acc: 0.3472\n","Epoch 7/100, Train Loss: 2.7095, Train Acc: 0.3397, Val Loss: 2.6794, Val Acc: 0.3494\n","Epoch 8/100, Train Loss: 2.6890, Train Acc: 0.3445, Val Loss: 2.6657, Val Acc: 0.3536\n","Epoch 9/100, Train Loss: 2.6665, Train Acc: 0.3484, Val Loss: 2.6648, Val Acc: 0.3550\n","Epoch 10/100, Train Loss: 2.6503, Train Acc: 0.3504, Val Loss: 2.6453, Val Acc: 0.3560\n","Epoch 11/100, Train Loss: 2.6299, Train Acc: 0.3540, Val Loss: 2.6589, Val Acc: 0.3527\n","Epoch 12/100, Train Loss: 2.6222, Train Acc: 0.3561, Val Loss: 2.6431, Val Acc: 0.3619\n","Epoch 13/100, Train Loss: 2.6065, Train Acc: 0.3596, Val Loss: 2.6357, Val Acc: 0.3613\n","Epoch 14/100, Train Loss: 2.5974, Train Acc: 0.3608, Val Loss: 2.6290, Val Acc: 0.3614\n","Epoch 15/100, Train Loss: 2.5828, Train Acc: 0.3633, Val Loss: 2.6182, Val Acc: 0.3626\n","Epoch 16/100, Train Loss: 2.5729, Train Acc: 0.3646, Val Loss: 2.6065, Val Acc: 0.3685\n","Epoch 17/100, Train Loss: 2.5595, Train Acc: 0.3703, Val Loss: 2.6233, Val Acc: 0.3656\n","Epoch 18/100, Train Loss: 2.5510, Train Acc: 0.3686, Val Loss: 2.5995, Val Acc: 0.3724\n","Epoch 19/100, Train Loss: 2.5430, Train Acc: 0.3727, Val Loss: 2.6264, Val Acc: 0.3668\n","Epoch 20/100, Train Loss: 2.5330, Train Acc: 0.3711, Val Loss: 2.6269, Val Acc: 0.3670\n","Epoch 21/100, Train Loss: 2.5205, Train Acc: 0.3736, Val Loss: 2.5903, Val Acc: 0.3701\n","Epoch 22/100, Train Loss: 2.5162, Train Acc: 0.3743, Val Loss: 2.6051, Val Acc: 0.3699\n","Epoch 23/100, Train Loss: 2.5097, Train Acc: 0.3793, Val Loss: 2.5947, Val Acc: 0.3728\n","Epoch 24/100, Train Loss: 2.5005, Train Acc: 0.3798, Val Loss: 2.5991, Val Acc: 0.3720\n","Epoch 25/100, Train Loss: 2.4957, Train Acc: 0.3781, Val Loss: 2.6011, Val Acc: 0.3689\n","Epoch 26/100, Train Loss: 2.4965, Train Acc: 0.3816, Val Loss: 2.5943, Val Acc: 0.3726\n","Epoch 27/100, Train Loss: 2.4770, Train Acc: 0.3817, Val Loss: 2.6195, Val Acc: 0.3739\n","Epoch 28/100, Train Loss: 2.4755, Train Acc: 0.3814, Val Loss: 2.5911, Val Acc: 0.3743\n","Epoch 29/100, Train Loss: 2.4684, Train Acc: 0.3829, Val Loss: 2.6021, Val Acc: 0.3719\n","Epoch 30/100, Train Loss: 2.4608, Train Acc: 0.3857, Val Loss: 2.5982, Val Acc: 0.3740\n","Epoch 31/100, Train Loss: 2.4551, Train Acc: 0.3883, Val Loss: 2.5912, Val Acc: 0.3716\n","Epoch 32/100, Train Loss: 2.4498, Train Acc: 0.3847, Val Loss: 2.6119, Val Acc: 0.3736\n","Epoch 33/100, Train Loss: 2.4384, Train Acc: 0.3897, Val Loss: 2.6011, Val Acc: 0.3738\n","Epoch 34/100, Train Loss: 2.4392, Train Acc: 0.3889, Val Loss: 2.5912, Val Acc: 0.3803\n","Epoch 35/100, Train Loss: 2.4302, Train Acc: 0.3906, Val Loss: 2.6003, Val Acc: 0.3776\n","Epoch 36/100, Train Loss: 2.4303, Train Acc: 0.3906, Val Loss: 2.6081, Val Acc: 0.3762\n","Epoch 37/100, Train Loss: 2.4251, Train Acc: 0.3905, Val Loss: 2.6042, Val Acc: 0.3760\n","Early stopping at epoch 37\n","Test Accuracy: 0.3746\n","Test Macro F1 Score: 0.2209\n","Test Weighted F1 Score: 0.3431\n","Confusion Matrix shape: (100, 100)\n","Model saved as ft_linear_tuned_helena.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.9176 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 11:47:11,502] A new study created in memory with name: no-name-d210ac2a-074b-4096-a308-78e34ff7a722\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 11:48:47,858] Trial 0 finished with value: 2.8392539024353027 and parameters: {'d_token': 52, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 86, 'lr': 0.00045537765326472305, 'dropout': 0.20300343379917768, 'n_bins': 10}. Best is trial 0 with value: 2.8392539024353027.\n","[I 2025-03-05 11:51:09,484] Trial 1 finished with value: 2.6562435626983643 and parameters: {'d_token': 99, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 252, 'lr': 0.0005349324830889021, 'dropout': 0.11359685896906307, 'n_bins': 16}. Best is trial 1 with value: 2.6562435626983643.\n","[I 2025-03-05 11:52:15,488] Trial 2 finished with value: 3.02019464969635 and parameters: {'d_token': 112, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 86, 'lr': 0.00021016683024414445, 'dropout': 0.226254410044479, 'n_bins': 3}. Best is trial 1 with value: 2.6562435626983643.\n","[I 2025-03-05 11:57:14,206] Trial 3 finished with value: 2.7028138637542725 and parameters: {'d_token': 52, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 191, 'lr': 0.007947786008944625, 'dropout': 0.06826421410713968, 'n_bins': 43}. Best is trial 1 with value: 2.6562435626983643.\n","[I 2025-03-05 11:58:36,947] Trial 4 finished with value: 2.740552544593811 and parameters: {'d_token': 95, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 205, 'lr': 0.0020601372611159545, 'dropout': 0.16605334920956394, 'n_bins': 7}. Best is trial 1 with value: 2.6562435626983643.\n","[I 2025-03-05 11:59:21,829] Trial 5 pruned. \n","[I 2025-03-05 12:05:10,960] Trial 6 finished with value: 2.655588388442993 and parameters: {'d_token': 117, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 212, 'lr': 0.000463923382387466, 'dropout': 0.23439522691645126, 'n_bins': 49}. Best is trial 6 with value: 2.655588388442993.\n","[I 2025-03-05 12:10:49,652] Trial 7 finished with value: 2.681922197341919 and parameters: {'d_token': 72, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 194, 'lr': 0.0002482624559578661, 'dropout': 0.1755172828447899, 'n_bins': 47}. Best is trial 6 with value: 2.655588388442993.\n","[I 2025-03-05 12:11:36,529] Trial 8 pruned. \n","[I 2025-03-05 12:12:30,563] Trial 9 pruned. \n","[I 2025-03-05 12:15:45,090] Trial 10 pruned. \n","[I 2025-03-05 12:17:20,390] Trial 11 pruned. \n","[I 2025-03-05 12:20:18,267] Trial 12 finished with value: 2.6264604330062866 and parameters: {'d_token': 96, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 224, 'lr': 0.0008869878442377959, 'dropout': 0.06719376411561462, 'n_bins': 22}. Best is trial 12 with value: 2.6264604330062866.\n","[I 2025-03-05 12:24:19,849] Trial 13 finished with value: 2.642686605453491 and parameters: {'d_token': 78, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 215, 'lr': 0.001134117768123604, 'dropout': 0.28127130700171477, 'n_bins': 32}. Best is trial 12 with value: 2.6264604330062866.\n","[I 2025-03-05 12:28:32,918] Trial 14 finished with value: 2.6250953674316406 and parameters: {'d_token': 73, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 225, 'lr': 0.0011903623409526525, 'dropout': 0.3135770354416086, 'n_bins': 32}. Best is trial 14 with value: 2.6250953674316406.\n","[I 2025-03-05 12:30:21,405] Trial 15 pruned. \n","[I 2025-03-05 12:34:38,094] Trial 16 finished with value: 2.6539794206619263 and parameters: {'d_token': 68, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 228, 'lr': 0.0009160894738565188, 'dropout': 0.3969578661792374, 'n_bins': 33}. Best is trial 14 with value: 2.6250953674316406.\n","[I 2025-03-05 12:36:53,895] Trial 17 pruned. \n","[I 2025-03-05 12:39:17,830] Trial 18 pruned. \n","[I 2025-03-05 12:42:23,865] Trial 19 finished with value: 2.6504207849502563 and parameters: {'d_token': 107, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 147, 'lr': 0.0015827235150980728, 'dropout': 0.016366553950261098, 'n_bins': 28}. Best is trial 14 with value: 2.6250953674316406.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 2.6251\n","  Params:\n","    d_token: 73\n","    num_heads: 7\n","    num_layers: 3\n","    d_ffn: 225\n","    lr: 0.0011903623409526525\n","    dropout: 0.3135770354416086\n","    n_bins: 32\n","\n","=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 3.8407, Train Acc: 0.1373, Val Loss: 3.2743, Val Acc: 0.2461\n","Epoch 2/100, Train Loss: 3.1646, Train Acc: 0.2607, Val Loss: 2.9696, Val Acc: 0.2940\n","Epoch 3/100, Train Loss: 2.9857, Train Acc: 0.2906, Val Loss: 2.8882, Val Acc: 0.3074\n","Epoch 4/100, Train Loss: 2.8992, Train Acc: 0.3031, Val Loss: 2.8021, Val Acc: 0.3204\n","Epoch 5/100, Train Loss: 2.8499, Train Acc: 0.3105, Val Loss: 2.7589, Val Acc: 0.3346\n","Epoch 6/100, Train Loss: 2.8049, Train Acc: 0.3203, Val Loss: 2.7326, Val Acc: 0.3385\n","Epoch 7/100, Train Loss: 2.7764, Train Acc: 0.3264, Val Loss: 2.7154, Val Acc: 0.3425\n","Epoch 8/100, Train Loss: 2.7493, Train Acc: 0.3325, Val Loss: 2.7072, Val Acc: 0.3470\n","Epoch 9/100, Train Loss: 2.7427, Train Acc: 0.3316, Val Loss: 2.6989, Val Acc: 0.3460\n","Epoch 10/100, Train Loss: 2.7149, Train Acc: 0.3383, Val Loss: 2.6776, Val Acc: 0.3515\n","Epoch 11/100, Train Loss: 2.7059, Train Acc: 0.3403, Val Loss: 2.6889, Val Acc: 0.3456\n","Epoch 12/100, Train Loss: 2.6920, Train Acc: 0.3408, Val Loss: 2.6723, Val Acc: 0.3509\n","Epoch 13/100, Train Loss: 2.6784, Train Acc: 0.3462, Val Loss: 2.6678, Val Acc: 0.3539\n","Epoch 14/100, Train Loss: 2.6556, Train Acc: 0.3503, Val Loss: 2.6644, Val Acc: 0.3569\n","Epoch 15/100, Train Loss: 2.6473, Train Acc: 0.3505, Val Loss: 2.6569, Val Acc: 0.3556\n","Epoch 16/100, Train Loss: 2.6411, Train Acc: 0.3514, Val Loss: 2.6544, Val Acc: 0.3585\n","Epoch 17/100, Train Loss: 2.6395, Train Acc: 0.3526, Val Loss: 2.6445, Val Acc: 0.3594\n","Epoch 18/100, Train Loss: 2.6257, Train Acc: 0.3554, Val Loss: 2.6424, Val Acc: 0.3610\n","Epoch 19/100, Train Loss: 2.6081, Train Acc: 0.3593, Val Loss: 2.6387, Val Acc: 0.3630\n","Epoch 20/100, Train Loss: 2.6105, Train Acc: 0.3567, Val Loss: 2.6368, Val Acc: 0.3609\n","Epoch 21/100, Train Loss: 2.5951, Train Acc: 0.3621, Val Loss: 2.6220, Val Acc: 0.3664\n","Epoch 22/100, Train Loss: 2.5883, Train Acc: 0.3649, Val Loss: 2.6241, Val Acc: 0.3635\n","Epoch 23/100, Train Loss: 2.5774, Train Acc: 0.3643, Val Loss: 2.6281, Val Acc: 0.3671\n","Epoch 24/100, Train Loss: 2.5697, Train Acc: 0.3639, Val Loss: 2.6414, Val Acc: 0.3649\n","Epoch 25/100, Train Loss: 2.5680, Train Acc: 0.3648, Val Loss: 2.6338, Val Acc: 0.3617\n","Epoch 26/100, Train Loss: 2.5587, Train Acc: 0.3652, Val Loss: 2.6326, Val Acc: 0.3652\n","Epoch 27/100, Train Loss: 2.5538, Train Acc: 0.3701, Val Loss: 2.6192, Val Acc: 0.3651\n","Epoch 28/100, Train Loss: 2.5430, Train Acc: 0.3699, Val Loss: 2.6148, Val Acc: 0.3683\n","Epoch 29/100, Train Loss: 2.5353, Train Acc: 0.3718, Val Loss: 2.6179, Val Acc: 0.3667\n","Epoch 30/100, Train Loss: 2.5375, Train Acc: 0.3704, Val Loss: 2.6198, Val Acc: 0.3722\n","Epoch 31/100, Train Loss: 2.5271, Train Acc: 0.3748, Val Loss: 2.6077, Val Acc: 0.3705\n","Epoch 32/100, Train Loss: 2.5153, Train Acc: 0.3753, Val Loss: 2.6310, Val Acc: 0.3659\n","Epoch 33/100, Train Loss: 2.5199, Train Acc: 0.3758, Val Loss: 2.6075, Val Acc: 0.3671\n","Epoch 34/100, Train Loss: 2.5084, Train Acc: 0.3784, Val Loss: 2.6374, Val Acc: 0.3669\n","Epoch 35/100, Train Loss: 2.4978, Train Acc: 0.3783, Val Loss: 2.6124, Val Acc: 0.3717\n","Epoch 36/100, Train Loss: 2.5002, Train Acc: 0.3765, Val Loss: 2.6219, Val Acc: 0.3705\n","Epoch 37/100, Train Loss: 2.4964, Train Acc: 0.3795, Val Loss: 2.6162, Val Acc: 0.3703\n","Epoch 38/100, Train Loss: 2.4889, Train Acc: 0.3802, Val Loss: 2.6150, Val Acc: 0.3702\n","Epoch 39/100, Train Loss: 2.4822, Train Acc: 0.3790, Val Loss: 2.6148, Val Acc: 0.3719\n","Epoch 40/100, Train Loss: 2.4798, Train Acc: 0.3803, Val Loss: 2.6116, Val Acc: 0.3691\n","Epoch 41/100, Train Loss: 2.4674, Train Acc: 0.3852, Val Loss: 2.6222, Val Acc: 0.3732\n","Epoch 42/100, Train Loss: 2.4646, Train Acc: 0.3854, Val Loss: 2.6199, Val Acc: 0.3680\n","Epoch 43/100, Train Loss: 2.4650, Train Acc: 0.3827, Val Loss: 2.6184, Val Acc: 0.3748\n","Epoch 44/100, Train Loss: 2.4609, Train Acc: 0.3860, Val Loss: 2.6089, Val Acc: 0.3729\n","Epoch 45/100, Train Loss: 2.4528, Train Acc: 0.3863, Val Loss: 2.6304, Val Acc: 0.3717\n","Epoch 46/100, Train Loss: 2.4450, Train Acc: 0.3858, Val Loss: 2.6297, Val Acc: 0.3692\n","Epoch 47/100, Train Loss: 2.4440, Train Acc: 0.3865, Val Loss: 2.6147, Val Acc: 0.3736\n","Epoch 48/100, Train Loss: 2.4447, Train Acc: 0.3881, Val Loss: 2.6220, Val Acc: 0.3756\n","Epoch 49/100, Train Loss: 2.4354, Train Acc: 0.3894, Val Loss: 2.6352, Val Acc: 0.3696\n","Early stopping at epoch 49\n","Test Accuracy: 0.3704\n","Test Macro F1 Score: 0.2187\n","Test Weighted F1 Score: 0.3396\n","Confusion Matrix shape: (100, 100)\n","Model saved as ft_piecewise_tuned_helena.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.8291 (p-value: 0.0000)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 12:53:44,074] A new study created in memory with name: no-name-1df674ea-4436-452b-b0f7-4a56a5889f0f\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 12:55:22,090] Trial 0 finished with value: 2.626972198486328 and parameters: {'d_token': 97, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 217, 'lr': 0.0033274412966155112, 'dropout': 0.008588973825872648, 'n_bins': 39}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 12:56:23,439] Trial 1 finished with value: 2.7228076457977295 and parameters: {'d_token': 80, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 73, 'lr': 0.004401761424535928, 'dropout': 0.1614705086902602, 'n_bins': 48}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 12:56:58,829] Trial 2 finished with value: 2.867244839668274 and parameters: {'d_token': 125, 'num_heads': 2, 'num_layers': 1, 'd_ffn': 152, 'lr': 0.0026458101950654496, 'dropout': 0.006188480817093001, 'n_bins': 7}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 12:58:51,743] Trial 3 finished with value: 2.6743968725204468 and parameters: {'d_token': 116, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 114, 'lr': 0.00011818561565897731, 'dropout': 0.15344322551742795, 'n_bins': 43}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:01:00,865] Trial 4 finished with value: 2.849204182624817 and parameters: {'d_token': 39, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 143, 'lr': 0.00037491735993546593, 'dropout': 0.4965331729444745, 'n_bins': 6}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:01:33,008] Trial 5 finished with value: 3.0189636945724487 and parameters: {'d_token': 102, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 206, 'lr': 0.007314181104772426, 'dropout': 0.4355466412869645, 'n_bins': 28}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:03:37,720] Trial 6 finished with value: 2.6414527893066406 and parameters: {'d_token': 93, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 177, 'lr': 0.0001321775678136766, 'dropout': 0.023096581870627964, 'n_bins': 11}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:03:58,718] Trial 7 pruned. \n","[I 2025-03-05 13:04:44,551] Trial 8 pruned. \n","[I 2025-03-05 13:05:19,426] Trial 9 finished with value: 3.1343462467193604 and parameters: {'d_token': 124, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 197, 'lr': 0.008612419638630747, 'dropout': 0.0037198772646678258, 'n_bins': 36}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:06:46,537] Trial 10 finished with value: 2.629077911376953 and parameters: {'d_token': 56, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 251, 'lr': 0.0012686038433043295, 'dropout': 0.32029457415325574, 'n_bins': 33}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:08:13,711] Trial 11 finished with value: 2.6293221712112427 and parameters: {'d_token': 56, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 255, 'lr': 0.0013646731909344762, 'dropout': 0.32499202839838015, 'n_bins': 32}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:09:40,551] Trial 12 finished with value: 2.6452847719192505 and parameters: {'d_token': 60, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 239, 'lr': 0.000965718191781845, 'dropout': 0.3008834072969994, 'n_bins': 39}. Best is trial 0 with value: 2.626972198486328.\n","[I 2025-03-05 13:10:38,745] Trial 13 pruned. \n","[I 2025-03-05 13:11:28,183] Trial 14 pruned. \n","[I 2025-03-05 13:11:53,236] Trial 15 pruned. \n","[I 2025-03-05 13:13:14,709] Trial 16 pruned. \n","[I 2025-03-05 13:15:03,078] Trial 17 pruned. \n","[I 2025-03-05 13:15:28,003] Trial 18 pruned. \n","[I 2025-03-05 13:16:39,545] Trial 19 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 2.6270\n","  Params:\n","    d_token: 97\n","    num_heads: 7\n","    num_layers: 2\n","    d_ffn: 217\n","    lr: 0.0033274412966155112\n","    dropout: 0.008588973825872648\n","    n_bins: 39\n","\n","=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 3.2306, Train Acc: 0.2502, Val Loss: 2.9353, Val Acc: 0.2936\n","Epoch 2/100, Train Loss: 2.8608, Train Acc: 0.3101, Val Loss: 2.8091, Val Acc: 0.3161\n","Epoch 3/100, Train Loss: 2.7828, Train Acc: 0.3254, Val Loss: 2.8022, Val Acc: 0.3227\n","Epoch 4/100, Train Loss: 2.7317, Train Acc: 0.3323, Val Loss: 2.7356, Val Acc: 0.3343\n","Epoch 5/100, Train Loss: 2.6943, Train Acc: 0.3408, Val Loss: 2.7337, Val Acc: 0.3331\n","Epoch 6/100, Train Loss: 2.6644, Train Acc: 0.3458, Val Loss: 2.6930, Val Acc: 0.3369\n","Epoch 7/100, Train Loss: 2.6241, Train Acc: 0.3534, Val Loss: 2.6969, Val Acc: 0.3467\n","Epoch 8/100, Train Loss: 2.6105, Train Acc: 0.3563, Val Loss: 2.6723, Val Acc: 0.3486\n","Epoch 9/100, Train Loss: 2.5907, Train Acc: 0.3597, Val Loss: 2.6831, Val Acc: 0.3471\n","Epoch 10/100, Train Loss: 2.5679, Train Acc: 0.3645, Val Loss: 2.6565, Val Acc: 0.3499\n","Epoch 11/100, Train Loss: 2.5578, Train Acc: 0.3626, Val Loss: 2.6707, Val Acc: 0.3514\n","Epoch 12/100, Train Loss: 2.5399, Train Acc: 0.3656, Val Loss: 2.6631, Val Acc: 0.3492\n","Epoch 13/100, Train Loss: 2.5256, Train Acc: 0.3674, Val Loss: 2.6496, Val Acc: 0.3587\n","Epoch 14/100, Train Loss: 2.5127, Train Acc: 0.3729, Val Loss: 2.6525, Val Acc: 0.3585\n","Epoch 15/100, Train Loss: 2.4909, Train Acc: 0.3759, Val Loss: 2.6675, Val Acc: 0.3565\n","Epoch 16/100, Train Loss: 2.4792, Train Acc: 0.3757, Val Loss: 2.6719, Val Acc: 0.3583\n","Epoch 17/100, Train Loss: 2.4638, Train Acc: 0.3792, Val Loss: 2.6636, Val Acc: 0.3530\n","Epoch 18/100, Train Loss: 2.4570, Train Acc: 0.3810, Val Loss: 2.6504, Val Acc: 0.3555\n","Epoch 19/100, Train Loss: 2.4491, Train Acc: 0.3789, Val Loss: 2.6688, Val Acc: 0.3545\n","Epoch 20/100, Train Loss: 2.4417, Train Acc: 0.3829, Val Loss: 2.6615, Val Acc: 0.3616\n","Epoch 21/100, Train Loss: 2.4335, Train Acc: 0.3844, Val Loss: 2.6448, Val Acc: 0.3634\n","Epoch 22/100, Train Loss: 2.4135, Train Acc: 0.3875, Val Loss: 2.6582, Val Acc: 0.3653\n","Epoch 23/100, Train Loss: 2.4043, Train Acc: 0.3863, Val Loss: 2.6648, Val Acc: 0.3633\n","Epoch 24/100, Train Loss: 2.3872, Train Acc: 0.3902, Val Loss: 2.6682, Val Acc: 0.3562\n","Epoch 25/100, Train Loss: 2.3881, Train Acc: 0.3917, Val Loss: 2.6673, Val Acc: 0.3563\n","Epoch 26/100, Train Loss: 2.3707, Train Acc: 0.3950, Val Loss: 2.6761, Val Acc: 0.3603\n","Epoch 27/100, Train Loss: 2.3662, Train Acc: 0.3950, Val Loss: 2.6894, Val Acc: 0.3593\n","Epoch 28/100, Train Loss: 2.3486, Train Acc: 0.3978, Val Loss: 2.7030, Val Acc: 0.3583\n","Epoch 29/100, Train Loss: 2.3663, Train Acc: 0.3955, Val Loss: 2.7030, Val Acc: 0.3627\n","Epoch 30/100, Train Loss: 2.3663, Train Acc: 0.3936, Val Loss: 2.6860, Val Acc: 0.3646\n","Epoch 31/100, Train Loss: 2.3505, Train Acc: 0.3966, Val Loss: 2.6738, Val Acc: 0.3639\n","Epoch 32/100, Train Loss: 2.3379, Train Acc: 0.4000, Val Loss: 2.7111, Val Acc: 0.3572\n","Epoch 33/100, Train Loss: 2.3268, Train Acc: 0.4016, Val Loss: 2.7024, Val Acc: 0.3588\n","Epoch 34/100, Train Loss: 2.3181, Train Acc: 0.4000, Val Loss: 2.6927, Val Acc: 0.3607\n","Epoch 35/100, Train Loss: 2.3042, Train Acc: 0.4076, Val Loss: 2.7091, Val Acc: 0.3618\n","Epoch 36/100, Train Loss: 2.2809, Train Acc: 0.4107, Val Loss: 2.6960, Val Acc: 0.3661\n","Epoch 37/100, Train Loss: 2.2679, Train Acc: 0.4098, Val Loss: 2.7068, Val Acc: 0.3610\n","Early stopping at epoch 37\n","Test Accuracy: 0.3575\n","Test Macro F1 Score: 0.2199\n","Test Weighted F1 Score: 0.3346\n","Confusion Matrix shape: (100, 100)\n","Model saved as sparse_ft_linear_tuned_helena.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.6826 (p-value: 0.0001)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 13:21:20,199] A new study created in memory with name: no-name-261a8f5a-07a0-4957-bdc2-02ab6ced1bf5\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-05 13:24:19,225] Trial 0 finished with value: 2.731738567352295 and parameters: {'d_token': 46, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 184, 'lr': 0.001141667302185147, 'dropout': 0.15978389722580766, 'n_bins': 21}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:31:32,944] Trial 1 finished with value: 2.775459408760071 and parameters: {'d_token': 68, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 107, 'lr': 0.00013472188613684137, 'dropout': 0.1815983911170434, 'n_bins': 49}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:36:55,302] Trial 2 finished with value: 2.7333595752716064 and parameters: {'d_token': 59, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 71, 'lr': 0.0004986413713264766, 'dropout': 0.48763975891332956, 'n_bins': 34}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:39:19,771] Trial 3 finished with value: 2.8452706336975098 and parameters: {'d_token': 59, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 193, 'lr': 0.004628702581173634, 'dropout': 0.20138135442029143, 'n_bins': 16}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:42:28,712] Trial 4 finished with value: 2.851996064186096 and parameters: {'d_token': 115, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 154, 'lr': 0.0004098302086082311, 'dropout': 0.38927554441287354, 'n_bins': 22}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:45:20,707] Trial 5 finished with value: 2.7464373111724854 and parameters: {'d_token': 52, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 141, 'lr': 0.002352202912064674, 'dropout': 0.4434626012613511, 'n_bins': 15}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:46:29,046] Trial 6 pruned. \n","[I 2025-03-05 13:47:58,316] Trial 7 finished with value: 3.4870100021362305 and parameters: {'d_token': 116, 'num_heads': 2, 'num_layers': 2, 'd_ffn': 154, 'lr': 0.00840731419389305, 'dropout': 0.03992237790149178, 'n_bins': 21}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 13:50:40,019] Trial 8 pruned. \n","[I 2025-03-05 13:53:40,229] Trial 9 pruned. \n","[I 2025-03-05 13:54:23,320] Trial 10 pruned. \n","[I 2025-03-05 13:59:08,435] Trial 11 finished with value: 2.7336223125457764 and parameters: {'d_token': 50, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 75, 'lr': 0.0005393716576428972, 'dropout': 0.31297918729793117, 'n_bins': 33}. Best is trial 0 with value: 2.731738567352295.\n","[I 2025-03-05 14:04:29,528] Trial 12 finished with value: 2.6525957584381104 and parameters: {'d_token': 76, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 204, 'lr': 0.000881136770112076, 'dropout': 0.36262503514858613, 'n_bins': 31}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:08:41,479] Trial 13 finished with value: 2.6652735471725464 and parameters: {'d_token': 84, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 206, 'lr': 0.0011632474080013786, 'dropout': 0.32026640491907776, 'n_bins': 28}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:13:12,870] Trial 14 finished with value: 2.663939118385315 and parameters: {'d_token': 84, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 217, 'lr': 0.0008020930612078705, 'dropout': 0.3611871878955646, 'n_bins': 30}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:19:06,960] Trial 15 finished with value: 2.6958982944488525 and parameters: {'d_token': 94, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 217, 'lr': 0.0004037273550627339, 'dropout': 0.37543495261651877, 'n_bins': 43}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:24:16,208] Trial 16 finished with value: 2.6564524173736572 and parameters: {'d_token': 76, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 252, 'lr': 0.0006905509360401981, 'dropout': 0.38102885704096495, 'n_bins': 28}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:27:40,324] Trial 17 pruned. \n","[I 2025-03-05 14:32:39,060] Trial 18 finished with value: 2.676283836364746 and parameters: {'d_token': 73, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 236, 'lr': 0.002109374163258885, 'dropout': 0.41002540458917724, 'n_bins': 26}. Best is trial 12 with value: 2.6525957584381104.\n","[I 2025-03-05 14:38:08,946] Trial 19 finished with value: 2.622326970100403 and parameters: {'d_token': 102, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 255, 'lr': 0.00074498713248751, 'dropout': 0.2562146574077927, 'n_bins': 37}. Best is trial 19 with value: 2.622326970100403.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 2.6223\n","  Params:\n","    d_token: 102\n","    num_heads: 5\n","    num_layers: 3\n","    d_ffn: 255\n","    lr: 0.00074498713248751\n","    dropout: 0.2562146574077927\n","    n_bins: 37\n","\n","=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 3.6953, Train Acc: 0.1750, Val Loss: 3.1780, Val Acc: 0.2652\n","Epoch 2/100, Train Loss: 3.1186, Train Acc: 0.2737, Val Loss: 2.9484, Val Acc: 0.2997\n","Epoch 3/100, Train Loss: 2.9588, Train Acc: 0.2973, Val Loss: 2.8645, Val Acc: 0.3095\n","Epoch 4/100, Train Loss: 2.8818, Train Acc: 0.3099, Val Loss: 2.7892, Val Acc: 0.3277\n","Epoch 5/100, Train Loss: 2.8283, Train Acc: 0.3207, Val Loss: 2.7633, Val Acc: 0.3288\n","Epoch 6/100, Train Loss: 2.7915, Train Acc: 0.3254, Val Loss: 2.7494, Val Acc: 0.3393\n","Epoch 7/100, Train Loss: 2.7546, Train Acc: 0.3333, Val Loss: 2.7124, Val Acc: 0.3445\n","Epoch 8/100, Train Loss: 2.7281, Train Acc: 0.3371, Val Loss: 2.7111, Val Acc: 0.3474\n","Epoch 9/100, Train Loss: 2.7134, Train Acc: 0.3412, Val Loss: 2.6873, Val Acc: 0.3494\n","Epoch 10/100, Train Loss: 2.6873, Train Acc: 0.3451, Val Loss: 2.6746, Val Acc: 0.3513\n","Epoch 11/100, Train Loss: 2.6623, Train Acc: 0.3500, Val Loss: 2.6757, Val Acc: 0.3541\n","Epoch 12/100, Train Loss: 2.6463, Train Acc: 0.3535, Val Loss: 2.6580, Val Acc: 0.3564\n","Epoch 13/100, Train Loss: 2.6318, Train Acc: 0.3535, Val Loss: 2.6533, Val Acc: 0.3596\n","Epoch 14/100, Train Loss: 2.6220, Train Acc: 0.3569, Val Loss: 2.6404, Val Acc: 0.3606\n","Epoch 15/100, Train Loss: 2.6040, Train Acc: 0.3602, Val Loss: 2.6513, Val Acc: 0.3566\n","Epoch 16/100, Train Loss: 2.5925, Train Acc: 0.3618, Val Loss: 2.6387, Val Acc: 0.3623\n","Epoch 17/100, Train Loss: 2.5826, Train Acc: 0.3644, Val Loss: 2.6349, Val Acc: 0.3624\n","Epoch 18/100, Train Loss: 2.5658, Train Acc: 0.3692, Val Loss: 2.6294, Val Acc: 0.3670\n","Epoch 19/100, Train Loss: 2.5568, Train Acc: 0.3692, Val Loss: 2.6476, Val Acc: 0.3607\n","Epoch 20/100, Train Loss: 2.5503, Train Acc: 0.3718, Val Loss: 2.6347, Val Acc: 0.3594\n","Epoch 21/100, Train Loss: 2.5347, Train Acc: 0.3747, Val Loss: 2.6269, Val Acc: 0.3609\n","Epoch 22/100, Train Loss: 2.5175, Train Acc: 0.3778, Val Loss: 2.6275, Val Acc: 0.3677\n","Epoch 23/100, Train Loss: 2.5175, Train Acc: 0.3773, Val Loss: 2.6192, Val Acc: 0.3633\n","Epoch 24/100, Train Loss: 2.5111, Train Acc: 0.3776, Val Loss: 2.6311, Val Acc: 0.3652\n","Epoch 25/100, Train Loss: 2.5002, Train Acc: 0.3795, Val Loss: 2.6268, Val Acc: 0.3648\n","Epoch 26/100, Train Loss: 2.4895, Train Acc: 0.3831, Val Loss: 2.6095, Val Acc: 0.3695\n","Epoch 27/100, Train Loss: 2.4890, Train Acc: 0.3822, Val Loss: 2.6215, Val Acc: 0.3637\n","Epoch 28/100, Train Loss: 2.4728, Train Acc: 0.3821, Val Loss: 2.6219, Val Acc: 0.3703\n","Epoch 29/100, Train Loss: 2.4694, Train Acc: 0.3850, Val Loss: 2.6233, Val Acc: 0.3672\n","Epoch 30/100, Train Loss: 2.4595, Train Acc: 0.3861, Val Loss: 2.6155, Val Acc: 0.3702\n","Epoch 31/100, Train Loss: 2.4450, Train Acc: 0.3907, Val Loss: 2.5975, Val Acc: 0.3729\n","Epoch 32/100, Train Loss: 2.4398, Train Acc: 0.3908, Val Loss: 2.6107, Val Acc: 0.3728\n","Epoch 33/100, Train Loss: 2.4299, Train Acc: 0.3932, Val Loss: 2.6225, Val Acc: 0.3690\n","Epoch 34/100, Train Loss: 2.4198, Train Acc: 0.3934, Val Loss: 2.6106, Val Acc: 0.3730\n","Epoch 35/100, Train Loss: 2.4142, Train Acc: 0.3955, Val Loss: 2.6211, Val Acc: 0.3696\n","Epoch 36/100, Train Loss: 2.4082, Train Acc: 0.3975, Val Loss: 2.6199, Val Acc: 0.3694\n","Epoch 37/100, Train Loss: 2.3959, Train Acc: 0.3970, Val Loss: 2.6305, Val Acc: 0.3669\n","Epoch 38/100, Train Loss: 2.3878, Train Acc: 0.3992, Val Loss: 2.6191, Val Acc: 0.3700\n","Epoch 39/100, Train Loss: 2.3812, Train Acc: 0.4011, Val Loss: 2.6409, Val Acc: 0.3680\n","Epoch 40/100, Train Loss: 2.3699, Train Acc: 0.4021, Val Loss: 2.6306, Val Acc: 0.3717\n","Epoch 41/100, Train Loss: 2.3684, Train Acc: 0.4039, Val Loss: 2.6324, Val Acc: 0.3683\n","Epoch 42/100, Train Loss: 2.3709, Train Acc: 0.4002, Val Loss: 2.6322, Val Acc: 0.3680\n","Epoch 43/100, Train Loss: 2.3552, Train Acc: 0.4048, Val Loss: 2.6413, Val Acc: 0.3655\n","Epoch 44/100, Train Loss: 2.3472, Train Acc: 0.4066, Val Loss: 2.6254, Val Acc: 0.3711\n","Epoch 45/100, Train Loss: 2.3501, Train Acc: 0.4050, Val Loss: 2.6382, Val Acc: 0.3692\n","Epoch 46/100, Train Loss: 2.3380, Train Acc: 0.4102, Val Loss: 2.6287, Val Acc: 0.3700\n","Epoch 47/100, Train Loss: 2.3317, Train Acc: 0.4105, Val Loss: 2.6273, Val Acc: 0.3681\n","Early stopping at epoch 47\n","Test Accuracy: 0.3720\n","Test Macro F1 Score: 0.2296\n","Test Weighted F1 Score: 0.3491\n","Confusion Matrix shape: (100, 100)\n","Model saved as sparse_ft_piecewise_tuned_helena.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.4640 (p-value: 0.0148)\n","\n","=== Comparison of Tuned Models ===\n","FT Transformer (Linear Tuned): Accuracy=0.3746, F1 Macro=0.2209\n","FT Transformer (Piecewise Tuned): Accuracy=0.3704, F1 Macro=0.2187\n","Sparse FT Transformer (Linear Tuned): Accuracy=0.3575, F1 Macro=0.2199\n","Sparse FT Transformer (Piecewise Tuned): Accuracy=0.3720, F1 Macro=0.2296\n","\n","=== Comparison of PFI-Attention Correlations (Tuned Models) ===\n","FT Transformer (Linear Tuned): ρ=0.9176, p-value=0.0000\n","FT Transformer (Piecewise Tuned): ρ=0.8291, p-value=0.0000\n","Sparse FT Transformer (Linear Tuned): ρ=0.6826, p-value=0.0001\n","Sparse FT Transformer (Piecewise Tuned): ρ=0.4640, p-value=0.0148\n","\n","Visualizations saved as 'model_comparison_helena.png' and 'feature_importance_comparison_helena.png'\n","Results saved as results_helena.json\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from google.colab import drive\n","\n","def save_all_files_to_drive(folder_name='Jannis_Files'):\n","  \"\"\"Saves all files in the current Colab environment to a new folder in Google Drive.\n","\n","  Args:\n","    folder_name: The name of the folder to create in Google Drive. Defaults to 'Colab_Files'.\n","  \"\"\"\n","\n","  # Mount Google Drive\n","  drive.mount('/content/drive')\n","\n","  # Create the folder in Google Drive\n","  folder_path = os.path.join('/content/drive/My Drive', folder_name)\n","  os.makedirs(folder_path, exist_ok=True)\n","\n","  # Get a list of all files in the current directory\n","  files = os.listdir('.')\n","\n","  # Copy each file to the Google Drive folder\n","  for file in files:\n","    source_path = os.path.join('.', file)\n","    destination_path = os.path.join(folder_path, file)\n","    os.system(f'cp \"{source_path}\" \"{destination_path}\"')  # Using os.system for file copying\n","\n","  print(f\"All files saved to Google Drive: /content/drive/My Drive/{folder_name}\")\n","\n","save_all_files_to_drive()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZk3O9Zpzb1Y","executionInfo":{"status":"ok","timestamp":1741186567361,"user_tz":-60,"elapsed":17995,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"31419f5d-56da-4adc-9a57-aa22442e437c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","All files saved to Google Drive: /content/drive/My Drive/Jannis_Files\n"]}]}]}