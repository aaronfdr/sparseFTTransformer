{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1cPcyPwvNtcHBM8QJAZrDjwSJWP0Wq3MH","authorship_tag":"ABX9TyO73ECOMIoMgf1cHb7EjDEs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install optuna\n","%pip install sparsemax # https://pypi.org/project/sparsemax/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Tc3NgvLqeox8","executionInfo":{"status":"ok","timestamp":1741121064062,"user_tz":-60,"elapsed":118135,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"7d9329d3-0bf9-4baa-ac16-52d3f88b20f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n","Collecting sparsemax\n","  Downloading sparsemax-0.1.9-py2.py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from sparsemax) (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->sparsemax)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sparsemax)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sparsemax)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sparsemax)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sparsemax)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sparsemax)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sparsemax)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->sparsemax) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->sparsemax) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->sparsemax) (3.0.2)\n","Downloading sparsemax-0.1.9-py2.py3-none-any.whl (5.5 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sparsemax\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sparsemax-0.1.9\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sparsemax import Sparsemax\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from sklearn.datasets import fetch_california_housing\n","from scipy.stats import spearmanr\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import optuna\n","import json\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","sparsemax = Sparsemax(dim=-1)\n","\n","class TabularDataset(Dataset):\n","    \"\"\"Dataset for tabular data with continuous features\"\"\"\n","    def __init__(self, X, y=None):\n","        # Continuous features\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","\n","        # Target\n","        if y is not None:\n","            self.y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n","        else:\n","            self.y = None\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.X[idx], self.y[idx]\n","        else:\n","            return self.X[idx]\n","\n","'''\n","The code below has been adapted from the original codebase.\n","\n","For the implementation of the FT Transformer, please check out this repository: https://github.com/yandex-research/rtdl-revisiting-models\n","\n","For the implementation of the Piecewise Linear Embedding, please check out: https://github.com/yandex-research/rtdl-num-embeddings\n","'''\n","\n","class LinearEmbedding(nn.Module):\n","    \"\"\"Linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token):\n","        super().__init__()\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(1, d_token) for _ in range(num_features)\n","        ])\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_cont_features)\n","        batch_size = x.shape[0]\n","        num_features = x.shape[1]\n","\n","        # Embed each continuous feature\n","        embedded = torch.zeros((batch_size, num_features, self.embeddings[0].out_features),\n","                              device=x.device)\n","\n","        for i in range(num_features):\n","            embedded[:, i] = self.embeddings[i](x[:, i].unsqueeze(-1)).squeeze(-1)\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","class PiecewiseLinearEmbedding(nn.Module):\n","    \"\"\"Piecewise linear embedding for continuous features\"\"\"\n","    def __init__(self, num_features, d_token, num_bins=20):\n","        super().__init__()\n","        self.num_features = num_features\n","        self.d_token = d_token\n","        self.num_bins = num_bins\n","\n","        # Create embeddings for each feature\n","        self.embeddings = nn.ModuleList([\n","            nn.Linear(num_bins, d_token) for _ in range(num_features)\n","        ])\n","\n","        # Create parameters for bin boundaries (learnable)\n","        self.bin_boundaries = nn.Parameter(torch.randn(num_features, num_bins-1))\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        batch_size = x.shape[0]\n","\n","        # Output will contain embedded tokens for each feature\n","        embedded = torch.zeros((batch_size, self.num_features, self.d_token), device=x.device)\n","\n","        for i in range(self.num_features):\n","            # Get feature values for current feature\n","            feature_values = x[:, i].unsqueeze(1)  # (batch_size, 1)\n","\n","            # Get sorted boundaries for this feature\n","            boundaries = torch.sort(self.bin_boundaries[i]).values  # (num_bins-1)\n","\n","            # Calculate bin activations using cumulative distribution\n","            # Start with all in the first bin\n","            bin_activations = torch.ones((batch_size, self.num_bins), device=x.device)\n","\n","            # Update bin activations based on feature values and boundaries\n","            for j in range(self.num_bins-1):\n","                boundary = boundaries[j]\n","                # Calculate contribution to bins based on boundary comparison\n","                condition = feature_values > boundary\n","                # Move activations to next bin when condition is true\n","                bin_activations[:, j+1:] = torch.where(\n","                    condition.expand(-1, self.num_bins-j-1),\n","                    bin_activations[:, j:self.num_bins-1],\n","                    bin_activations[:, j+1:]\n","                )\n","                bin_activations[:, j] = torch.where(\n","                    condition.squeeze(1),\n","                    0.0,\n","                    bin_activations[:, j]\n","                )\n","\n","            # Apply linear transformation to get embeddings\n","            feature_embedding = self.embeddings[i](bin_activations)  # (batch_size, d_token)\n","            embedded[:, i] = feature_embedding\n","\n","        return embedded  # (batch_size, num_features, d_token)\n","\n","# Custom attention module to capture attention weights\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply softmax to get attention weights\n","        attention_weights = F.softmax(scores, dim=-1)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","# Custom transformer layer to capture attention weights\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            TransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for regression (single value)\n","        self.output_layer = nn.Linear(d_token, 1)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (no activation for regression)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","# Sparse attention variants\n","class sparseMultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n","\n","        # Linear projections\n","        self.q_proj = nn.Linear(d_model, d_model)\n","        self.k_proj = nn.Linear(d_model, d_model)\n","        self.v_proj = nn.Linear(d_model, d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        # For storing attention weights\n","        self.attention_weights = None\n","\n","    def forward(self, query, key, value, attn_mask=None):\n","        batch_size = query.shape[0]\n","\n","        # Linear projections\n","        q = self.q_proj(query)  # (batch_size, seq_len, d_model)\n","        k = self.k_proj(key)    # (batch_size, seq_len, d_model)\n","        v = self.v_proj(value)  # (batch_size, seq_len, d_model)\n","\n","        # Reshape for multi-head attention\n","        q = q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","        # Calculate attention scores\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","\n","        # Apply mask if provided\n","        if attn_mask is not None:\n","            scores = scores.masked_fill(attn_mask == 0, -1e9)\n","\n","        # Apply sparsemax to get attention weights\n","        attention_weights = sparsemax(scores)\n","        self.attention_weights = attention_weights  # Store for later use\n","\n","        # Apply attention weights to values\n","        out = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, head_dim)\n","\n","        # Reshape back\n","        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n","\n","        # Final linear projection\n","        out = self.out_proj(out)\n","\n","        return out\n","\n","class sparseTransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = sparseMultiHeadAttention(d_model, nhead)\n","\n","        # Feed-forward network\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # Layer norm\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Self-attention\n","        attn_output = self.self_attn(src, src, src, attn_mask=src_mask)\n","        src = src + self.dropout1(attn_output)\n","        src = self.norm1(src)\n","\n","        # Feed-forward network\n","        ff_output = self.linear2(self.dropout(F.relu(self.linear1(src))))\n","        src = src + self.dropout2(ff_output)\n","        src = self.norm2(src)\n","\n","        return src\n","\n","class sparseFTTransformer(nn.Module):\n","    def __init__(self, num_features, d_token=64, num_heads=8, num_layers=2,\n","                 d_ffn=128, dropout=0.1, embedding_type='linear', n_bins=20):\n","        super().__init__()\n","        self.d_token = d_token\n","        self.num_features = num_features\n","        self.embedding_type = embedding_type\n","\n","        # CLS token parameter\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token))\n","\n","        # Feature tokenizer\n","        if embedding_type == 'linear':\n","            self.feature_tokenizer = LinearEmbedding(num_features, d_token)\n","        elif embedding_type == 'piecewise':\n","            self.feature_tokenizer = PiecewiseLinearEmbedding(num_features, d_token, num_bins=n_bins)\n","        else:\n","            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n","\n","        # Feature positional embedding\n","        self.feature_pos_embedding = nn.Parameter(torch.randn(1, num_features, d_token))\n","\n","        # Custom transformer layers\n","        self.transformer_layers = nn.ModuleList([\n","            sparseTransformerEncoderLayer(d_model=d_token, nhead=num_heads,\n","                                   dim_feedforward=d_ffn, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Output layer for regression\n","        self.output_layer = nn.Linear(d_token, 1)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","\n","        # Tokenize features\n","        tokens = self.feature_tokenizer(x)  # (batch_size, num_features, d_token)\n","\n","        # Add positional embedding\n","        tokens = tokens + self.feature_pos_embedding\n","\n","        # Add CLS token\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        sequence = torch.cat([cls_tokens, tokens], dim=1)  # (batch_size, num_features+1, d_token)\n","\n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            sequence = layer(sequence)\n","\n","        # Use CLS token for prediction\n","        cls_output = sequence[:, 0]\n","\n","        # Final prediction (no activation for regression)\n","        output = self.output_layer(cls_output)\n","\n","        return output\n","\n","    def get_cls_attention(self):\n","        \"\"\"Return the attention weights from CLS token to feature tokens (average over all layers)\"\"\"\n","        # Average attention weights across all layers\n","        cls_attention = []\n","\n","        for layer in self.transformer_layers:\n","            # Extract CLS token attention to features\n","            # layer_weights shape: (batch_size, num_heads, seq_len, seq_len)\n","            if layer.self_attn.attention_weights is not None:\n","                # Get attention from CLS (idx 0) to features (idx 1:)\n","                layer_weights = layer.self_attn.attention_weights\n","                cls_to_features = layer_weights[:, :, 0, 1:].mean(dim=1)  # Average over heads\n","                cls_attention.append(cls_to_features)\n","            else:\n","                raise ValueError(\"Attention weights not available. Run forward first.\")\n","\n","        # Average over layers\n","        avg_attention = torch.stack(cls_attention).mean(dim=0)\n","        return avg_attention\n","\n","def calculate_pfi(model, X_val, y_val, num_permutations=5):\n","    \"\"\"Calculate Permutation Feature Importance (PFI) for regression\"\"\"\n","    # Convert to PyTorch tensors\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1).to(device)\n","\n","    # Get baseline performance\n","    model.eval()\n","    with torch.no_grad():\n","        baseline_preds = model(X)\n","        baseline_mse = F.mse_loss(baseline_preds, y).item()\n","\n","    # Calculate importance for each feature\n","    importances = []\n","\n","    for feat_idx in range(X.shape[1]):\n","        mse_increases = []\n","\n","        for _ in range(num_permutations):\n","            # Create a permuted copy of the data\n","            X_permuted = X.clone()\n","\n","            # Permute the feature\n","            perm_idx = torch.randperm(X.shape[0])\n","            X_permuted[:, feat_idx] = X_permuted[perm_idx, feat_idx]\n","\n","            # Calculate MSE with permuted feature\n","            with torch.no_grad():\n","                perm_preds = model(X_permuted)\n","                perm_mse = F.mse_loss(perm_preds, y).item()\n","\n","            # Feature importance is the increase in MSE\n","            mse_increases.append(perm_mse - baseline_mse)\n","\n","        # Average over permutations (higher = more important)\n","        importances.append(np.mean(mse_increases))\n","\n","    return np.array(importances)\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=100, early_stopping=16):\n","    \"\"\"Train the model with early stopping\"\"\"\n","    model.to(device)\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","    best_state = None\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","\n","        with torch.no_grad():\n","            for X_batch, y_batch in val_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                val_loss += loss.item()\n","\n","        train_loss /= len(train_loader)\n","        val_loss /= len(val_loader)\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","            # Save best model state dict\n","            best_state = model.state_dict()\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= early_stopping:\n","                print(f\"Early stopping at epoch {epoch+1}\")\n","                break\n","\n","    # Load best model\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test, device):\n","    \"\"\"Evaluate model performance for regression\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    X = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    y = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1).to(device)\n","\n","    with torch.no_grad():\n","        y_pred = model(X).cpu().numpy()\n","\n","    y_test = y_test.reshape(-1, 1)\n","\n","    # Calculate metrics\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","\n","    print(f\"Test MSE: {mse:.4f}\")\n","    print(f\"Test RMSE: {rmse:.4f}\")\n","    print(f\"Test R²: {r2:.4f}\")\n","    print(f\"Test MAE: {mae:.4f}\")\n","\n","    return {\n","        'mse': mse,\n","        'rmse': rmse,\n","        'r2': r2,\n","        'mae': mae\n","    }\n","\n","def analyze_pfi_attention_correlation(model, X_val, y_val, feature_names, device):\n","    \"\"\"Analyze correlation between PFI and attention scores for regression\"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    # Get attention scores\n","    X = torch.tensor(X_val, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        _ = model(X)  # Forward pass to compute attention\n","        attention_scores = model.get_cls_attention().cpu().numpy()\n","\n","    # Average attention scores across samples\n","    avg_attention = attention_scores.mean(axis=0)\n","\n","    # Calculate PFI\n","    pfi_scores = calculate_pfi(model, X_val, y_val)\n","\n","    # Calculate Spearman rank correlation\n","    correlation, p_value = spearmanr(pfi_scores, avg_attention)\n","\n","    print(f\"Spearman Rank Correlation: {correlation:.4f} (p-value: {p_value:.4f})\")\n","\n","    # Create a visualization\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    # Create a scatter plot\n","    scatter = ax.scatter(pfi_scores, avg_attention, alpha=0.7)\n","\n","    # Add feature labels\n","    for i, name in enumerate(feature_names):\n","        ax.annotate(name, (pfi_scores[i], avg_attention[i]),\n","                   textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8)\n","\n","    # Add best fit line\n","    z = np.polyfit(pfi_scores, avg_attention, 1)\n","    p = np.poly1d(z)\n","    ax.plot(np.sort(pfi_scores), p(np.sort(pfi_scores)), \"r--\", alpha=0.7)\n","\n","    # Add correlation information\n","    ax.text(0.05, 0.95, f\"Spearman ρ: {correlation:.4f}\\np-value: {p_value:.4f}\",\n","            transform=ax.transAxes, verticalalignment='top',\n","            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n","\n","    ax.set_xlabel('Permutation Feature Importance')\n","    ax.set_ylabel('CLS Token Attention Score')\n","    ax.set_title('PFI vs CLS Token Attention Correlation')\n","\n","    plt.tight_layout()\n","    plt.savefig('pfi_attention_correlation_california.png')\n","    plt.close()\n","\n","    # Return results\n","    results = {\n","        'correlation': correlation,\n","        'p_value': p_value,\n","        'pfi_scores': pfi_scores.tolist(),\n","        'attention_scores': avg_attention.tolist(),\n","        'feature_names': feature_names\n","    }\n","\n","    return results\n","\n","def load_california_housing_dataset():\n","    \"\"\"Load and preprocess the California Housing dataset\"\"\"\n","    print(\"Loading California Housing dataset...\")\n","\n","    # Load the dataset using sklearn\n","    housing = fetch_california_housing()\n","    X = housing.data\n","    y = housing.target\n","    feature_names = housing.feature_names\n","\n","    print(f\"Dataset shape: {X.shape}\")\n","    print(f\"Features: {feature_names}\")\n","\n","    # Split data\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","    # Standardize features\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","    X_test = scaler.transform(X_test)\n","\n","    print(f\"Dataset splits - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test, feature_names\n","\n","def tune_hyperparameters(X_train, y_train, X_val, y_val, embedding_type='linear', n_trials=20, sparse=False):\n","    \"\"\"Tune hyperparameters using Optuna for regression\"\"\"\n","\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=128)\n","\n","    num_features = X_train.shape[1]\n","\n","    def objective(trial):\n","        # Define hyperparameters to tune\n","        d_token = trial.suggest_int('d_token', 32, 128)\n","        num_heads = trial.suggest_int('num_heads', 2, 8)\n","        num_layers = trial.suggest_int('num_layers', 1, 3)\n","        d_ffn = trial.suggest_int('d_ffn', 64, 256)\n","        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n","        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n","        n_bins = trial.suggest_int('n_bins', 10, 100)\n","\n","        # Ensure d_token is divisible by num_heads\n","        d_token = (d_token // num_heads) * num_heads\n","\n","        # Create model with trial hyperparameters\n","        if not sparse:\n","            model = FTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","        else:\n","            model = sparseFTTransformer(\n","                num_features=num_features,\n","                d_token=d_token,\n","                num_heads=num_heads,\n","                num_layers=num_layers,\n","                d_ffn=d_ffn,\n","                dropout=dropout,\n","                embedding_type=embedding_type,\n","                n_bins=n_bins\n","            )\n","\n","        # Define criterion and optimizer for regression\n","        criterion = nn.MSELoss()\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","        # Train for a few epochs\n","        model.to(device)\n","        best_val_loss = float('inf')\n","\n","        patience = 5\n","        patience_counter = 0\n","        num_epochs = 20\n","\n","        # Short training loop for hyperparameter search\n","        for epoch in range(num_epochs):\n","            # Training\n","            model.train()\n","            for X_batch, y_batch in train_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                loss.backward()\n","                optimizer.step()\n","\n","            # Validation\n","            model.eval()\n","            val_loss = 0\n","\n","            with torch.no_grad():\n","                for X_batch, y_batch in val_loader:\n","                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","                    outputs = model(X_batch)\n","                    loss = criterion(outputs, y_batch)\n","                    val_loss += loss.item()\n","\n","            val_loss /= len(val_loader)\n","\n","            # Update best validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter > patience:\n","                    break\n","\n","            trial.report(val_loss, epoch)\n","\n","            if trial.should_prune():\n","                raise optuna.TrialPruned()\n","\n","        return best_val_loss\n","\n","    # Create Optuna study\n","    study = optuna.create_study(\n","        direction=\"minimize\",\n","        pruner=optuna.pruners.MedianPruner( # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n","            n_startup_trials=5,\n","            n_warmup_steps=10,\n","            interval_steps=2\n","        )\n","    )\n","    study.optimize(objective, n_trials=n_trials, timeout=1800)\n","\n","    # Print best parameters\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","    print(f\"  Value (validation loss): {trial.value:.4f}\")\n","    print(\"  Params:\")\n","    for key, value in trial.params.items():\n","        print(f\"    {key}: {value}\")\n","\n","    # Return best parameters\n","    return trial.params\n","\n","def train_with_best_params(X_train, y_train, X_val, y_val, X_test, y_test, best_params,\n","                         embedding_type='linear', sparse=False):\n","    \"\"\"Train a model with the best hyperparameters for regression\"\"\"\n","    # Create datasets\n","    train_dataset = TabularDataset(X_train, y_train)\n","    val_dataset = TabularDataset(X_val, y_val)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=1024)\n","\n","    # Ensure d_token is divisible by num_heads\n","    d_token = (best_params['d_token'] // best_params['num_heads']) * best_params['num_heads']\n","\n","    # Create model with best hyperparameters\n","    if not sparse:\n","        model = FTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","    else:\n","        model = sparseFTTransformer(\n","            num_features=X_train.shape[1],\n","            d_token=d_token,\n","            num_heads=best_params['num_heads'],\n","            num_layers=best_params['num_layers'],\n","            d_ffn=best_params['d_ffn'],\n","            dropout=best_params['dropout'],\n","            embedding_type=embedding_type,\n","            n_bins=best_params['n_bins']\n","        )\n","\n","    # Define criterion for regression\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=1e-5)\n","\n","    # Train the model with early stopping\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        device=device,\n","        epochs=100\n","    )\n","\n","    # Evaluate on test set\n","    results = evaluate_model(model, X_test, y_test, device)\n","\n","    return model, results\n","\n","def visualize_all_models(results, feature_names):\n","    \"\"\"Create a comprehensive visualization comparing all regression models\"\"\"\n","\n","    # Create a figure with 2x2 subplots\n","    fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n","\n","    # Plot performance metrics\n","    models = list(results.keys())\n","    rmse_values = [results[model]['rmse'] for model in models]\n","    r2_values = [results[model]['r2'] for model in models]\n","\n","    # RMSE comparison\n","    axs[0, 0].bar(models, rmse_values)\n","    axs[0, 0].set_title('RMSE Comparison (California Housing)')\n","    axs[0, 0].set_ylabel('RMSE')\n","    axs[0, 0].tick_params(axis='x', rotation=45)\n","\n","    # R² comparison\n","    axs[0, 1].bar(models, r2_values)\n","    axs[0, 1].set_title('R² Comparison (California Housing)')\n","    axs[0, 1].set_ylabel('R²')\n","    axs[0, 1].tick_params(axis='x', rotation=45)\n","\n","    # Correlation comparison\n","    correlations = [results[model]['correlation_analysis']['correlation'] for model in models]\n","    p_values = [results[model]['correlation_analysis']['p_value'] for model in models]\n","\n","    axs[1, 0].bar(models, correlations)\n","    axs[1, 0].set_title('PFI-Attention Correlation Comparison (California Housing)')\n","    axs[1, 0].set_ylabel('Spearman Correlation')\n","    axs[1, 0].tick_params(axis='x', rotation=45)\n","\n","    # Feature importance comparison across models (top 3 features)\n","    axs[1, 1].axis('off')  # Turn off the axis for the text summary\n","\n","    summary_text = \"Feature Importance Summary:\\n\\n\"\n","\n","    for model in models:\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Get top 3 features by PFI\n","        pfi_top_indices = np.argsort(-pfi_scores)[:3]\n","        pfi_top_features = [feature_names[i] for i in pfi_top_indices]\n","\n","        # Get top 3 features by attention\n","        attn_top_indices = np.argsort(-attn_scores)[:3]\n","        attn_top_features = [feature_names[i] for i in attn_top_indices]\n","\n","        summary_text += f\"{model}:\\n\"\n","        summary_text += f\"  Top PFI features: {', '.join(pfi_top_features)}\\n\"\n","        summary_text += f\"  Top attention features: {', '.join(attn_top_features)}\\n\\n\"\n","\n","    axs[1, 1].text(0.05, 0.95, summary_text, transform=axs[1, 1].transAxes,\n","                 verticalalignment='top', fontsize=12)\n","\n","    plt.tight_layout()\n","    plt.savefig('model_comparison_california.png')\n","    plt.close()\n","\n","    # Create additional visualization for feature importance comparison\n","    fig, axs = plt.subplots(len(models), 1, figsize=(14, 5 * len(models)))\n","\n","    if len(models) == 1:\n","        axs = [axs]  # Convert to list if there's only one model\n","\n","    for i, model in enumerate(models):\n","        pfi_scores = np.array(results[model]['correlation_analysis']['pfi_scores'])\n","        attn_scores = np.array(results[model]['correlation_analysis']['attention_scores'])\n","        feature_names = results[model]['correlation_analysis']['feature_names']\n","\n","        # Sort features by PFI for visualization\n","        sorted_indices = np.argsort(-pfi_scores)\n","        sorted_features = [feature_names[j] for j in sorted_indices]\n","        sorted_pfi = [pfi_scores[j] for j in sorted_indices]\n","        sorted_attn = [attn_scores[j] for j in sorted_indices]\n","\n","        x = np.arange(len(sorted_features))\n","        width = 0.35\n","\n","        axs[i].bar(x - width/2, sorted_pfi, width, label='PFI')\n","        axs[i].bar(x + width/2, sorted_attn, width, label='Attention')\n","\n","        axs[i].set_title(f'Feature Importance (California Housing): {model}')\n","        axs[i].set_ylabel('Importance Score')\n","        axs[i].set_xticks(x)\n","        axs[i].set_xticklabels(sorted_features, rotation=45, ha='right')\n","        axs[i].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig('feature_importance_comparison_california.png')\n","    plt.close()\n","\n","    print(\"\\nVisualizations saved as 'model_comparison_california.png' and 'feature_importance_comparison_california.png'\")\n","\n","def save_model(model, filename):\n","    torch.save(model.state_dict(), filename)\n","    print(f\"Model saved as {filename}\")\n","\n","def save_results(results, filename):\n","    # Convert numpy arrays to lists for json serialization\n","    for model in results:\n","        if 'correlation_analysis' in results[model]:\n","            if isinstance(results[model]['correlation_analysis']['pfi_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['pfi_scores'] = results[model]['correlation_analysis']['pfi_scores'].tolist()\n","            if isinstance(results[model]['correlation_analysis']['attention_scores'], np.ndarray):\n","                results[model]['correlation_analysis']['attention_scores'] = results[model]['correlation_analysis']['attention_scores'].tolist()\n","\n","    with open(filename, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    print(f\"Results saved as {filename}\")\n","\n","def main_with_tuning():\n","    \"\"\"Main function to run the California Housing dataset experiments\"\"\"\n","    # Set random seed for reproducibility\n","    torch.manual_seed(42)\n","    np.random.seed(42)\n","\n","    # Set device\n","    print(f\"Using device: {device}\")\n","\n","    # Load California Housing dataset\n","    X_train, X_val, X_test, y_train, y_val, y_test, feature_names = load_california_housing_dataset()\n","\n","    models = {}\n","    results = {}\n","\n","    # Tune hyperparameters for Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\")\n","    linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='linear',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Linear Embedding (Tuned) ===\")\n","    ft_linear_tuned, linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=linear_best_params,\n","        embedding_type='linear'\n","    )\n","\n","    save_model(ft_linear_tuned, 'ft_linear_tuned_california.pth')\n","\n","    models['ft_linear_tuned'] = ft_linear_tuned\n","    results['ft_linear_tuned'] = linear_results\n","\n","    # Analyze PFI and attention correlation for tuned linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\")\n","    linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_linear_tuned']['correlation_analysis'] = linear_tuned_correlation\n","\n","    # Tune hyperparameters for Piecewise Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\")\n","    piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='piecewise',\n","        n_trials=20\n","    )\n","\n","    # Train with best parameters for Piecewise Linear Embedding\n","    print(\"\\n=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    ft_piecewise_tuned, piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=piecewise_best_params,\n","        embedding_type='piecewise'\n","    )\n","\n","    save_model(ft_piecewise_tuned, 'ft_piecewise_tuned_california.pth')\n","\n","    models['ft_piecewise_tuned'] = ft_piecewise_tuned\n","    results['ft_piecewise_tuned'] = piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\")\n","    piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['ft_piecewise_tuned']['correlation_analysis'] = piecewise_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Linear Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\")\n","    sparse_linear_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='linear',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Linear Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\")\n","    sparse_ft_linear_tuned, sparse_linear_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_linear_best_params,\n","        embedding_type='linear',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_linear_tuned, 'sparse_ft_linear_tuned_california.pth')\n","\n","    models['sparse_ft_linear_tuned'] = sparse_ft_linear_tuned\n","    results['sparse_ft_linear_tuned'] = sparse_linear_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse linear model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\")\n","    sparse_linear_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_linear_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_linear_tuned']['correlation_analysis'] = sparse_linear_tuned_correlation\n","\n","    # Tune hyperparameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\")\n","    sparse_piecewise_best_params = tune_hyperparameters(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        embedding_type='piecewise',\n","        n_trials=20,\n","        sparse=True\n","    )\n","\n","    # Train with best parameters for Sparse Piecewise Embedding\n","    print(\"\\n=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\")\n","    sparse_ft_piecewise_tuned, sparse_piecewise_results = train_with_best_params(\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_val=X_val,\n","        y_val=y_val,\n","        X_test=X_test,\n","        y_test=y_test,\n","        best_params=sparse_piecewise_best_params,\n","        embedding_type='piecewise',\n","        sparse=True\n","    )\n","\n","    save_model(sparse_ft_piecewise_tuned, 'sparse_ft_piecewise_tuned_california.pth')\n","\n","    models['sparse_ft_piecewise_tuned'] = sparse_ft_piecewise_tuned\n","    results['sparse_ft_piecewise_tuned'] = sparse_piecewise_results\n","\n","    # Analyze PFI and attention correlation for tuned sparse piecewise model\n","    print(\"\\n=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\")\n","    sparse_piecewise_tuned_correlation = analyze_pfi_attention_correlation(\n","        model=sparse_ft_piecewise_tuned,\n","        X_val=X_val,\n","        y_val=y_val,\n","        feature_names=feature_names,\n","        device=device\n","    )\n","    results['sparse_ft_piecewise_tuned']['correlation_analysis'] = sparse_piecewise_tuned_correlation\n","\n","    # Compare the results\n","    print(\"\\n=== Comparison of Tuned Models ===\")\n","    print(f\"FT Transformer (Linear Tuned): RMSE={results['ft_linear_tuned']['rmse']:.4f}, R²={results['ft_linear_tuned']['r2']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): RMSE={results['ft_piecewise_tuned']['rmse']:.4f}, R²={results['ft_piecewise_tuned']['r2']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): RMSE={results['sparse_ft_linear_tuned']['rmse']:.4f}, R²={results['sparse_ft_linear_tuned']['r2']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): RMSE={results['sparse_ft_piecewise_tuned']['rmse']:.4f}, R²={results['sparse_ft_piecewise_tuned']['r2']:.4f}\")\n","\n","    print(\"\\n=== Comparison of PFI-Attention Correlations (Tuned Models) ===\")\n","    print(f\"FT Transformer (Linear Tuned): ρ={linear_tuned_correlation['correlation']:.4f}, p-value={linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"FT Transformer (Piecewise Tuned): ρ={piecewise_tuned_correlation['correlation']:.4f}, p-value={piecewise_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Linear Tuned): ρ={sparse_linear_tuned_correlation['correlation']:.4f}, p-value={sparse_linear_tuned_correlation['p_value']:.4f}\")\n","    print(f\"Sparse FT Transformer (Piecewise Tuned): ρ={sparse_piecewise_tuned_correlation['correlation']:.4f}, p-value={sparse_piecewise_tuned_correlation['p_value']:.4f}\")\n","\n","    # Create visualization comparing all models\n","    visualize_all_models(\n","        results=results,\n","        feature_names=feature_names\n","    )\n","\n","    save_results(results, 'results_california.json')\n","\n","    return models, results\n","\n","if __name__ == \"__main__\":\n","    main_with_tuning()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoLqkxBXcJLr","executionInfo":{"status":"ok","timestamp":1741127328620,"user_tz":-60,"elapsed":6264555,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"222d605d-f693-4430-9236-bfb6222e6992"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Loading California Housing dataset...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 20:44:28,802] A new study created in memory with name: no-name-becd26b5-6896-4d5f-824d-3d91d46ac5f6\n"]},{"output_type":"stream","name":"stdout","text":["Dataset shape: (20640, 8)\n","Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n","Dataset splits - Train: (14448, 8), Val: (3096, 8), Test: (3096, 8)\n","\n","=== Tuning Hyperparameters for FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 20:45:08,874] Trial 0 finished with value: 0.4700487005710602 and parameters: {'d_token': 97, 'num_heads': 4, 'num_layers': 2, 'd_ffn': 78, 'lr': 0.005229665463833917, 'dropout': 0.41954752003865214, 'n_bins': 58}. Best is trial 0 with value: 0.4700487005710602.\n","[I 2025-03-04 20:46:04,012] Trial 1 finished with value: 0.2960692125558853 and parameters: {'d_token': 74, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 86, 'lr': 0.0005848011795173988, 'dropout': 0.34695049624693125, 'n_bins': 33}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:46:35,960] Trial 2 finished with value: 0.3211324429512024 and parameters: {'d_token': 59, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 205, 'lr': 0.0006136487544673718, 'dropout': 0.11018974049895375, 'n_bins': 40}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:47:03,226] Trial 3 finished with value: 0.8904365491867066 and parameters: {'d_token': 88, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 113, 'lr': 0.007923030151085711, 'dropout': 0.22333075971855265, 'n_bins': 62}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:47:43,559] Trial 4 finished with value: 0.32755792021751406 and parameters: {'d_token': 53, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 250, 'lr': 0.0003695988096283936, 'dropout': 0.25743145525398664, 'n_bins': 72}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:48:13,715] Trial 5 pruned. \n","[I 2025-03-04 20:48:53,939] Trial 6 finished with value: 0.32031348288059236 and parameters: {'d_token': 123, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 99, 'lr': 0.0006954659619323649, 'dropout': 0.3076309465644065, 'n_bins': 31}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:49:18,556] Trial 7 pruned. \n","[I 2025-03-04 20:49:35,988] Trial 8 pruned. \n","[I 2025-03-04 20:49:52,893] Trial 9 pruned. \n","[I 2025-03-04 20:50:40,867] Trial 10 finished with value: 0.3035954999923706 and parameters: {'d_token': 72, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 183, 'lr': 0.002091671547789248, 'dropout': 0.0021689167580304924, 'n_bins': 10}. Best is trial 1 with value: 0.2960692125558853.\n","[I 2025-03-04 20:51:34,946] Trial 11 finished with value: 0.29470034420490265 and parameters: {'d_token': 73, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 185, 'lr': 0.0019945503819336755, 'dropout': 0.0429190581074651, 'n_bins': 11}. Best is trial 11 with value: 0.29470034420490265.\n","[I 2025-03-04 20:52:08,188] Trial 12 finished with value: 0.29170804560184477 and parameters: {'d_token': 76, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 178, 'lr': 0.0018761278857460702, 'dropout': 0.11220762928405564, 'n_bins': 100}. Best is trial 12 with value: 0.29170804560184477.\n","[I 2025-03-04 20:52:48,449] Trial 13 finished with value: 0.3073159688711166 and parameters: {'d_token': 107, 'num_heads': 7, 'num_layers': 2, 'd_ffn': 189, 'lr': 0.0017082566259163236, 'dropout': 0.09105320901167505, 'n_bins': 88}. Best is trial 12 with value: 0.29170804560184477.\n","[I 2025-03-04 20:53:29,928] Trial 14 finished with value: 0.2905747157335281 and parameters: {'d_token': 32, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 165, 'lr': 0.002668499340879217, 'dropout': 0.12095807781149959, 'n_bins': 99}. Best is trial 14 with value: 0.2905747157335281.\n","[I 2025-03-04 20:54:11,986] Trial 15 finished with value: 0.30346087634563446 and parameters: {'d_token': 34, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 158, 'lr': 0.003307366185697258, 'dropout': 0.1706375303517313, 'n_bins': 100}. Best is trial 14 with value: 0.2905747157335281.\n","[I 2025-03-04 20:54:54,159] Trial 16 finished with value: 0.2983678561449051 and parameters: {'d_token': 43, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 214, 'lr': 0.001192073083373443, 'dropout': 0.14342188061427322, 'n_bins': 99}. Best is trial 14 with value: 0.2905747157335281.\n","[I 2025-03-04 20:55:25,909] Trial 17 finished with value: 0.29972387850284576 and parameters: {'d_token': 32, 'num_heads': 6, 'num_layers': 2, 'd_ffn': 129, 'lr': 0.0036018041002175883, 'dropout': 0.06103369123931805, 'n_bins': 86}. Best is trial 14 with value: 0.2905747157335281.\n","[I 2025-03-04 20:55:48,917] Trial 18 pruned. \n","[I 2025-03-04 20:56:12,067] Trial 19 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.2906\n","  Params:\n","    d_token: 32\n","    num_heads: 6\n","    num_layers: 2\n","    d_ffn: 165\n","    lr: 0.002668499340879217\n","    dropout: 0.12095807781149959\n","    n_bins: 99\n","\n","=== Training FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.1812, Val Loss: 0.8097\n","Epoch 2/100, Train Loss: 0.5862, Val Loss: 0.6031\n","Epoch 3/100, Train Loss: 0.4903, Val Loss: 0.5133\n","Epoch 4/100, Train Loss: 0.4018, Val Loss: 0.4176\n","Epoch 5/100, Train Loss: 0.3585, Val Loss: 0.4195\n","Epoch 6/100, Train Loss: 0.3364, Val Loss: 0.4084\n","Epoch 7/100, Train Loss: 0.3234, Val Loss: 0.3808\n","Epoch 8/100, Train Loss: 0.3193, Val Loss: 0.3676\n","Epoch 9/100, Train Loss: 0.3178, Val Loss: 0.3591\n","Epoch 10/100, Train Loss: 0.3195, Val Loss: 0.3690\n","Epoch 11/100, Train Loss: 0.3084, Val Loss: 0.3543\n","Epoch 12/100, Train Loss: 0.2952, Val Loss: 0.3653\n","Epoch 13/100, Train Loss: 0.2945, Val Loss: 0.3639\n","Epoch 14/100, Train Loss: 0.2923, Val Loss: 0.3655\n","Epoch 15/100, Train Loss: 0.2924, Val Loss: 0.3787\n","Epoch 16/100, Train Loss: 0.2911, Val Loss: 0.4026\n","Epoch 17/100, Train Loss: 0.3002, Val Loss: 0.3376\n","Epoch 18/100, Train Loss: 0.2824, Val Loss: 0.3542\n","Epoch 19/100, Train Loss: 0.2801, Val Loss: 0.3194\n","Epoch 20/100, Train Loss: 0.2737, Val Loss: 0.3477\n","Epoch 21/100, Train Loss: 0.2736, Val Loss: 0.3129\n","Epoch 22/100, Train Loss: 0.2765, Val Loss: 0.3250\n","Epoch 23/100, Train Loss: 0.2793, Val Loss: 0.3279\n","Epoch 24/100, Train Loss: 0.2719, Val Loss: 0.3471\n","Epoch 25/100, Train Loss: 0.2814, Val Loss: 0.3419\n","Epoch 26/100, Train Loss: 0.2706, Val Loss: 0.3158\n","Epoch 27/100, Train Loss: 0.2679, Val Loss: 0.3147\n","Epoch 28/100, Train Loss: 0.2645, Val Loss: 0.3252\n","Epoch 29/100, Train Loss: 0.2647, Val Loss: 0.3155\n","Epoch 30/100, Train Loss: 0.2645, Val Loss: 0.3342\n","Epoch 31/100, Train Loss: 0.2641, Val Loss: 0.3222\n","Epoch 32/100, Train Loss: 0.2649, Val Loss: 0.2889\n","Epoch 33/100, Train Loss: 0.2590, Val Loss: 0.3041\n","Epoch 34/100, Train Loss: 0.2582, Val Loss: 0.2954\n","Epoch 35/100, Train Loss: 0.2645, Val Loss: 0.3118\n","Epoch 36/100, Train Loss: 0.2614, Val Loss: 0.3209\n","Epoch 37/100, Train Loss: 0.2583, Val Loss: 0.3061\n","Epoch 38/100, Train Loss: 0.2544, Val Loss: 0.3025\n","Epoch 39/100, Train Loss: 0.2626, Val Loss: 0.3329\n","Epoch 40/100, Train Loss: 0.2594, Val Loss: 0.2959\n","Epoch 41/100, Train Loss: 0.2576, Val Loss: 0.2997\n","Epoch 42/100, Train Loss: 0.2566, Val Loss: 0.2834\n","Epoch 43/100, Train Loss: 0.2593, Val Loss: 0.2955\n","Epoch 44/100, Train Loss: 0.2541, Val Loss: 0.3278\n","Epoch 45/100, Train Loss: 0.2540, Val Loss: 0.3031\n","Epoch 46/100, Train Loss: 0.2481, Val Loss: 0.2836\n","Epoch 47/100, Train Loss: 0.2483, Val Loss: 0.3147\n","Epoch 48/100, Train Loss: 0.2491, Val Loss: 0.2954\n","Epoch 49/100, Train Loss: 0.2587, Val Loss: 0.3226\n","Epoch 50/100, Train Loss: 0.2512, Val Loss: 0.2782\n","Epoch 51/100, Train Loss: 0.2425, Val Loss: 0.3030\n","Epoch 52/100, Train Loss: 0.2424, Val Loss: 0.2924\n","Epoch 53/100, Train Loss: 0.2456, Val Loss: 0.3033\n","Epoch 54/100, Train Loss: 0.2462, Val Loss: 0.2851\n","Epoch 55/100, Train Loss: 0.2430, Val Loss: 0.3282\n","Epoch 56/100, Train Loss: 0.2437, Val Loss: 0.2884\n","Epoch 57/100, Train Loss: 0.2429, Val Loss: 0.2849\n","Epoch 58/100, Train Loss: 0.2394, Val Loss: 0.2705\n","Epoch 59/100, Train Loss: 0.2413, Val Loss: 0.2927\n","Epoch 60/100, Train Loss: 0.2416, Val Loss: 0.2708\n","Epoch 61/100, Train Loss: 0.2410, Val Loss: 0.2821\n","Epoch 62/100, Train Loss: 0.2448, Val Loss: 0.3241\n","Epoch 63/100, Train Loss: 0.2372, Val Loss: 0.3067\n","Epoch 64/100, Train Loss: 0.2392, Val Loss: 0.2922\n","Epoch 65/100, Train Loss: 0.2383, Val Loss: 0.2850\n","Epoch 66/100, Train Loss: 0.2403, Val Loss: 0.2822\n","Epoch 67/100, Train Loss: 0.2387, Val Loss: 0.2926\n","Epoch 68/100, Train Loss: 0.2297, Val Loss: 0.2801\n","Epoch 69/100, Train Loss: 0.2310, Val Loss: 0.2970\n","Epoch 70/100, Train Loss: 0.2321, Val Loss: 0.2853\n","Epoch 71/100, Train Loss: 0.2358, Val Loss: 0.3091\n","Epoch 72/100, Train Loss: 0.2320, Val Loss: 0.3129\n","Epoch 73/100, Train Loss: 0.2332, Val Loss: 0.3204\n","Epoch 74/100, Train Loss: 0.2383, Val Loss: 0.2714\n","Early stopping at epoch 74\n","Test MSE: 0.2386\n","Test RMSE: 0.4885\n","Test R²: 0.8195\n","Test MAE: 0.3448\n","Model saved as ft_linear_tuned_california.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.8810 (p-value: 0.0039)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 20:56:59,682] A new study created in memory with name: no-name-f04d3de0-1935-43c3-a7fd-d6d9069d5103\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 21:00:11,513] Trial 0 finished with value: 0.37675600171089174 and parameters: {'d_token': 74, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 256, 'lr': 0.00034060031951906966, 'dropout': 0.32462864952140685, 'n_bins': 31}. Best is trial 0 with value: 0.37675600171089174.\n","[I 2025-03-04 21:06:06,280] Trial 1 finished with value: 0.3135442239046097 and parameters: {'d_token': 118, 'num_heads': 2, 'num_layers': 3, 'd_ffn': 124, 'lr': 0.00027916202597893705, 'dropout': 0.38064392750118, 'n_bins': 63}. Best is trial 1 with value: 0.3135442239046097.\n","[I 2025-03-04 21:12:27,547] Trial 2 finished with value: 0.7146687269210815 and parameters: {'d_token': 96, 'num_heads': 3, 'num_layers': 1, 'd_ffn': 180, 'lr': 0.0064932993388807075, 'dropout': 0.0024777060118402194, 'n_bins': 93}. Best is trial 1 with value: 0.3135442239046097.\n","[I 2025-03-04 21:17:40,952] Trial 3 finished with value: 0.37265430867671967 and parameters: {'d_token': 60, 'num_heads': 4, 'num_layers': 1, 'd_ffn': 234, 'lr': 0.0001241850271640272, 'dropout': 0.2704569309965434, 'n_bins': 59}. Best is trial 1 with value: 0.3135442239046097.\n","[I 2025-03-04 21:21:25,894] Trial 4 finished with value: 0.8127604508399964 and parameters: {'d_token': 120, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 91, 'lr': 0.006077924756831039, 'dropout': 0.3350739807031468, 'n_bins': 36}. Best is trial 1 with value: 0.3135442239046097.\n","[I 2025-03-04 21:29:01,846] Trial 5 finished with value: 0.33257718741893766 and parameters: {'d_token': 33, 'num_heads': 3, 'num_layers': 1, 'd_ffn': 169, 'lr': 0.003804207862665668, 'dropout': 0.28613019213026986, 'n_bins': 89}. Best is trial 1 with value: 0.3135442239046097.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.3135\n","  Params:\n","    d_token: 118\n","    num_heads: 2\n","    num_layers: 3\n","    d_ffn: 124\n","    lr: 0.00027916202597893705\n","    dropout: 0.38064392750118\n","    n_bins: 63\n","\n","=== Training FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.1817, Val Loss: 0.8533\n","Epoch 2/100, Train Loss: 0.6809, Val Loss: 0.7501\n","Epoch 3/100, Train Loss: 0.5419, Val Loss: 0.6596\n","Epoch 4/100, Train Loss: 0.4563, Val Loss: 0.5212\n","Epoch 5/100, Train Loss: 0.4217, Val Loss: 0.5351\n","Epoch 6/100, Train Loss: 0.3978, Val Loss: 0.4773\n","Epoch 7/100, Train Loss: 0.3802, Val Loss: 0.4785\n","Epoch 8/100, Train Loss: 0.3670, Val Loss: 0.4735\n","Epoch 9/100, Train Loss: 0.3595, Val Loss: 0.4653\n","Epoch 10/100, Train Loss: 0.3487, Val Loss: 0.4458\n","Epoch 11/100, Train Loss: 0.3448, Val Loss: 0.4847\n","Epoch 12/100, Train Loss: 0.3349, Val Loss: 0.4492\n","Epoch 13/100, Train Loss: 0.3352, Val Loss: 0.4344\n","Epoch 14/100, Train Loss: 0.3266, Val Loss: 0.4102\n","Epoch 15/100, Train Loss: 0.3259, Val Loss: 0.4305\n","Epoch 16/100, Train Loss: 0.3188, Val Loss: 0.4276\n","Epoch 17/100, Train Loss: 0.3194, Val Loss: 0.4226\n","Epoch 18/100, Train Loss: 0.3089, Val Loss: 0.4110\n","Epoch 19/100, Train Loss: 0.3121, Val Loss: 0.4023\n","Epoch 20/100, Train Loss: 0.3021, Val Loss: 0.4410\n","Epoch 21/100, Train Loss: 0.3056, Val Loss: 0.3840\n","Epoch 22/100, Train Loss: 0.3034, Val Loss: 0.3984\n","Epoch 23/100, Train Loss: 0.3030, Val Loss: 0.3769\n","Epoch 24/100, Train Loss: 0.2932, Val Loss: 0.3734\n","Epoch 25/100, Train Loss: 0.2930, Val Loss: 0.3666\n","Epoch 26/100, Train Loss: 0.2998, Val Loss: 0.3582\n","Epoch 27/100, Train Loss: 0.2951, Val Loss: 0.3590\n","Epoch 28/100, Train Loss: 0.2914, Val Loss: 0.3681\n","Epoch 29/100, Train Loss: 0.2873, Val Loss: 0.3787\n","Epoch 30/100, Train Loss: 0.2895, Val Loss: 0.3500\n","Epoch 31/100, Train Loss: 0.2853, Val Loss: 0.3368\n","Epoch 32/100, Train Loss: 0.2827, Val Loss: 0.4345\n","Epoch 33/100, Train Loss: 0.2878, Val Loss: 0.3566\n","Epoch 34/100, Train Loss: 0.2839, Val Loss: 0.3549\n","Epoch 35/100, Train Loss: 0.2771, Val Loss: 0.3525\n","Epoch 36/100, Train Loss: 0.2773, Val Loss: 0.3377\n","Epoch 37/100, Train Loss: 0.2766, Val Loss: 0.3619\n","Epoch 38/100, Train Loss: 0.2750, Val Loss: 0.3463\n","Epoch 39/100, Train Loss: 0.2765, Val Loss: 0.3466\n","Epoch 40/100, Train Loss: 0.2878, Val Loss: 0.3731\n","Epoch 41/100, Train Loss: 0.2743, Val Loss: 0.3485\n","Epoch 42/100, Train Loss: 0.2753, Val Loss: 0.3691\n","Epoch 43/100, Train Loss: 0.2726, Val Loss: 0.3443\n","Epoch 44/100, Train Loss: 0.2717, Val Loss: 0.4020\n","Epoch 45/100, Train Loss: 0.2702, Val Loss: 0.3336\n","Epoch 46/100, Train Loss: 0.2691, Val Loss: 0.3393\n","Epoch 47/100, Train Loss: 0.2668, Val Loss: 0.3809\n","Epoch 48/100, Train Loss: 0.2662, Val Loss: 0.3471\n","Epoch 49/100, Train Loss: 0.2782, Val Loss: 0.3585\n","Epoch 50/100, Train Loss: 0.2614, Val Loss: 0.3279\n","Epoch 51/100, Train Loss: 0.2688, Val Loss: 0.3577\n","Epoch 52/100, Train Loss: 0.2628, Val Loss: 0.3354\n","Epoch 53/100, Train Loss: 0.2640, Val Loss: 0.3353\n","Epoch 54/100, Train Loss: 0.2587, Val Loss: 0.3609\n","Epoch 55/100, Train Loss: 0.2641, Val Loss: 0.3836\n","Epoch 56/100, Train Loss: 0.2620, Val Loss: 0.3657\n","Epoch 57/100, Train Loss: 0.2630, Val Loss: 0.3385\n","Epoch 58/100, Train Loss: 0.2547, Val Loss: 0.3649\n","Epoch 59/100, Train Loss: 0.2645, Val Loss: 0.3349\n","Epoch 60/100, Train Loss: 0.2650, Val Loss: 0.3538\n","Epoch 61/100, Train Loss: 0.2561, Val Loss: 0.3575\n","Epoch 62/100, Train Loss: 0.2593, Val Loss: 0.3344\n","Epoch 63/100, Train Loss: 0.2569, Val Loss: 0.3431\n","Epoch 64/100, Train Loss: 0.2571, Val Loss: 0.3702\n","Epoch 65/100, Train Loss: 0.2558, Val Loss: 0.3285\n","Epoch 66/100, Train Loss: 0.2501, Val Loss: 0.3214\n","Epoch 67/100, Train Loss: 0.2498, Val Loss: 0.3214\n","Epoch 68/100, Train Loss: 0.2514, Val Loss: 0.3847\n","Epoch 69/100, Train Loss: 0.2502, Val Loss: 0.3474\n","Epoch 70/100, Train Loss: 0.2480, Val Loss: 0.3618\n","Epoch 71/100, Train Loss: 0.2454, Val Loss: 0.3276\n","Epoch 72/100, Train Loss: 0.2431, Val Loss: 0.3263\n","Epoch 73/100, Train Loss: 0.2443, Val Loss: 0.3233\n","Epoch 74/100, Train Loss: 0.2426, Val Loss: 0.3473\n","Epoch 75/100, Train Loss: 0.2434, Val Loss: 0.3852\n","Epoch 76/100, Train Loss: 0.2462, Val Loss: 0.3371\n","Epoch 77/100, Train Loss: 0.2447, Val Loss: 0.3902\n","Epoch 78/100, Train Loss: 0.2440, Val Loss: 0.3609\n","Epoch 79/100, Train Loss: 0.2416, Val Loss: 0.3152\n","Epoch 80/100, Train Loss: 0.2377, Val Loss: 0.3258\n","Epoch 81/100, Train Loss: 0.2388, Val Loss: 0.3479\n","Epoch 82/100, Train Loss: 0.2354, Val Loss: 0.3368\n","Epoch 83/100, Train Loss: 0.2361, Val Loss: 0.3272\n","Epoch 84/100, Train Loss: 0.2357, Val Loss: 0.3871\n","Epoch 85/100, Train Loss: 0.2405, Val Loss: 0.3408\n","Epoch 86/100, Train Loss: 0.2313, Val Loss: 0.3497\n","Epoch 87/100, Train Loss: 0.2341, Val Loss: 0.3595\n","Epoch 88/100, Train Loss: 0.2333, Val Loss: 0.3346\n","Epoch 89/100, Train Loss: 0.2345, Val Loss: 0.3439\n","Epoch 90/100, Train Loss: 0.2348, Val Loss: 0.3747\n","Epoch 91/100, Train Loss: 0.2272, Val Loss: 0.3382\n","Epoch 92/100, Train Loss: 0.2291, Val Loss: 0.3744\n","Epoch 93/100, Train Loss: 0.2322, Val Loss: 0.3211\n","Epoch 94/100, Train Loss: 0.2325, Val Loss: 0.3555\n","Epoch 95/100, Train Loss: 0.2263, Val Loss: 0.3226\n","Early stopping at epoch 95\n","Test MSE: 0.2715\n","Test RMSE: 0.5210\n","Test R²: 0.7947\n","Test MAE: 0.3581\n","Model saved as ft_piecewise_tuned_california.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.8571 (p-value: 0.0065)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 21:36:11,519] A new study created in memory with name: no-name-102fbb09-ae6d-4f5f-8bc2-7468364de431\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 21:36:53,485] Trial 0 finished with value: 0.5019448637962342 and parameters: {'d_token': 106, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 72, 'lr': 0.003216982006630175, 'dropout': 0.005153900042998594, 'n_bins': 94}. Best is trial 0 with value: 0.5019448637962342.\n","[I 2025-03-04 21:37:43,253] Trial 1 finished with value: 0.3441982686519623 and parameters: {'d_token': 102, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 107, 'lr': 0.0005882447428556302, 'dropout': 0.4252170024880027, 'n_bins': 93}. Best is trial 1 with value: 0.3441982686519623.\n","[I 2025-03-04 21:38:13,394] Trial 2 finished with value: 0.4590043616294861 and parameters: {'d_token': 62, 'num_heads': 5, 'num_layers': 3, 'd_ffn': 206, 'lr': 0.0030199695612711562, 'dropout': 0.41142402553493534, 'n_bins': 72}. Best is trial 1 with value: 0.3441982686519623.\n","[I 2025-03-04 21:39:03,495] Trial 3 finished with value: 0.4023519229888916 and parameters: {'d_token': 65, 'num_heads': 5, 'num_layers': 2, 'd_ffn': 177, 'lr': 0.004106096009226681, 'dropout': 0.3063298876756682, 'n_bins': 98}. Best is trial 1 with value: 0.3441982686519623.\n","[I 2025-03-04 21:39:22,898] Trial 4 finished with value: 0.5255410408973694 and parameters: {'d_token': 89, 'num_heads': 6, 'num_layers': 1, 'd_ffn': 236, 'lr': 0.009256979690319099, 'dropout': 0.14238654289873826, 'n_bins': 81}. Best is trial 1 with value: 0.3441982686519623.\n","[I 2025-03-04 21:39:45,805] Trial 5 finished with value: 0.809380316734314 and parameters: {'d_token': 78, 'num_heads': 3, 'num_layers': 3, 'd_ffn': 101, 'lr': 0.007004309761809344, 'dropout': 0.37772716742218465, 'n_bins': 66}. Best is trial 1 with value: 0.3441982686519623.\n","[I 2025-03-04 21:40:50,893] Trial 6 finished with value: 0.2917975115776062 and parameters: {'d_token': 76, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 137, 'lr': 0.00012693332036879313, 'dropout': 0.12522034565257845, 'n_bins': 46}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:41:17,853] Trial 7 finished with value: 0.5725965130329133 and parameters: {'d_token': 61, 'num_heads': 6, 'num_layers': 3, 'd_ffn': 68, 'lr': 0.006215688892274827, 'dropout': 0.15395460917877196, 'n_bins': 16}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:42:07,659] Trial 8 finished with value: 0.3322311967611313 and parameters: {'d_token': 80, 'num_heads': 2, 'num_layers': 2, 'd_ffn': 185, 'lr': 0.00011485524259507003, 'dropout': 0.41382558914695805, 'n_bins': 96}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:42:50,514] Trial 9 finished with value: 0.3090431797504425 and parameters: {'d_token': 58, 'num_heads': 3, 'num_layers': 2, 'd_ffn': 136, 'lr': 0.0004177943713186675, 'dropout': 0.3233694161897154, 'n_bins': 78}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:43:26,074] Trial 10 finished with value: 0.315418062210083 and parameters: {'d_token': 33, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 141, 'lr': 0.0002636989990249542, 'dropout': 0.033377976060773945, 'n_bins': 36}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:43:53,690] Trial 11 pruned. \n","[I 2025-03-04 21:44:43,997] Trial 12 finished with value: 0.310098922252655 and parameters: {'d_token': 47, 'num_heads': 2, 'num_layers': 2, 'd_ffn': 123, 'lr': 0.00043572331413801964, 'dropout': 0.27820299657653935, 'n_bins': 55}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:45:03,365] Trial 13 pruned. \n","[I 2025-03-04 21:45:52,120] Trial 14 pruned. \n","[I 2025-03-04 21:46:43,164] Trial 15 finished with value: 0.30894683837890624 and parameters: {'d_token': 74, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 174, 'lr': 0.0009864622538154333, 'dropout': 0.221565101433627, 'n_bins': 79}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:47:43,464] Trial 16 finished with value: 0.32465613782405855 and parameters: {'d_token': 85, 'num_heads': 8, 'num_layers': 3, 'd_ffn': 218, 'lr': 0.001405355873326995, 'dropout': 0.20938048130558443, 'n_bins': 50}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:48:18,796] Trial 17 finished with value: 0.29854244768619537 and parameters: {'d_token': 73, 'num_heads': 7, 'num_layers': 1, 'd_ffn': 173, 'lr': 0.0008147832728699108, 'dropout': 0.08192067504936412, 'n_bins': 40}. Best is trial 6 with value: 0.2917975115776062.\n","[I 2025-03-04 21:48:38,441] Trial 18 pruned. \n","[I 2025-03-04 21:48:57,595] Trial 19 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.2918\n","  Params:\n","    d_token: 76\n","    num_heads: 4\n","    num_layers: 3\n","    d_ffn: 137\n","    lr: 0.00012693332036879313\n","    dropout: 0.12522034565257845\n","    n_bins: 46\n","\n","=== Training sparse FT Transformer with Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.3574, Val Loss: 0.8104\n","Epoch 2/100, Train Loss: 0.6832, Val Loss: 0.7461\n","Epoch 3/100, Train Loss: 0.5984, Val Loss: 0.7058\n","Epoch 4/100, Train Loss: 0.5490, Val Loss: 0.6457\n","Epoch 5/100, Train Loss: 0.5012, Val Loss: 0.5938\n","Epoch 6/100, Train Loss: 0.4682, Val Loss: 0.5757\n","Epoch 7/100, Train Loss: 0.4456, Val Loss: 0.5285\n","Epoch 8/100, Train Loss: 0.4189, Val Loss: 0.5108\n","Epoch 9/100, Train Loss: 0.3981, Val Loss: 0.4594\n","Epoch 10/100, Train Loss: 0.3838, Val Loss: 0.4553\n","Epoch 11/100, Train Loss: 0.3661, Val Loss: 0.4112\n","Epoch 12/100, Train Loss: 0.3543, Val Loss: 0.4105\n","Epoch 13/100, Train Loss: 0.3455, Val Loss: 0.3976\n","Epoch 14/100, Train Loss: 0.3399, Val Loss: 0.3732\n","Epoch 15/100, Train Loss: 0.3343, Val Loss: 0.4195\n","Epoch 16/100, Train Loss: 0.3306, Val Loss: 0.3612\n","Epoch 17/100, Train Loss: 0.3187, Val Loss: 0.3664\n","Epoch 18/100, Train Loss: 0.3245, Val Loss: 0.3655\n","Epoch 19/100, Train Loss: 0.3141, Val Loss: 0.3611\n","Epoch 20/100, Train Loss: 0.3076, Val Loss: 0.3543\n","Epoch 21/100, Train Loss: 0.3083, Val Loss: 0.3582\n","Epoch 22/100, Train Loss: 0.3095, Val Loss: 0.3499\n","Epoch 23/100, Train Loss: 0.3087, Val Loss: 0.3551\n","Epoch 24/100, Train Loss: 0.3045, Val Loss: 0.3471\n","Epoch 25/100, Train Loss: 0.3013, Val Loss: 0.3734\n","Epoch 26/100, Train Loss: 0.3136, Val Loss: 0.3625\n","Epoch 27/100, Train Loss: 0.3055, Val Loss: 0.3610\n","Epoch 28/100, Train Loss: 0.2950, Val Loss: 0.3591\n","Epoch 29/100, Train Loss: 0.2985, Val Loss: 0.3387\n","Epoch 30/100, Train Loss: 0.2995, Val Loss: 0.3500\n","Epoch 31/100, Train Loss: 0.3001, Val Loss: 0.3622\n","Epoch 32/100, Train Loss: 0.2924, Val Loss: 0.3457\n","Epoch 33/100, Train Loss: 0.2896, Val Loss: 0.3428\n","Epoch 34/100, Train Loss: 0.2890, Val Loss: 0.3413\n","Epoch 35/100, Train Loss: 0.2853, Val Loss: 0.3618\n","Epoch 36/100, Train Loss: 0.2882, Val Loss: 0.3306\n","Epoch 37/100, Train Loss: 0.2886, Val Loss: 0.3287\n","Epoch 38/100, Train Loss: 0.2851, Val Loss: 0.3329\n","Epoch 39/100, Train Loss: 0.2897, Val Loss: 0.3435\n","Epoch 40/100, Train Loss: 0.2850, Val Loss: 0.3404\n","Epoch 41/100, Train Loss: 0.2831, Val Loss: 0.3323\n","Epoch 42/100, Train Loss: 0.2860, Val Loss: 0.3374\n","Epoch 43/100, Train Loss: 0.2823, Val Loss: 0.3268\n","Epoch 44/100, Train Loss: 0.2840, Val Loss: 0.3276\n","Epoch 45/100, Train Loss: 0.2767, Val Loss: 0.3373\n","Epoch 46/100, Train Loss: 0.2805, Val Loss: 0.3249\n","Epoch 47/100, Train Loss: 0.2778, Val Loss: 0.3286\n","Epoch 48/100, Train Loss: 0.2772, Val Loss: 0.3341\n","Epoch 49/100, Train Loss: 0.2788, Val Loss: 0.3318\n","Epoch 50/100, Train Loss: 0.2777, Val Loss: 0.3220\n","Epoch 51/100, Train Loss: 0.2771, Val Loss: 0.3272\n","Epoch 52/100, Train Loss: 0.2736, Val Loss: 0.3207\n","Epoch 53/100, Train Loss: 0.2749, Val Loss: 0.3174\n","Epoch 54/100, Train Loss: 0.2743, Val Loss: 0.3421\n","Epoch 55/100, Train Loss: 0.2708, Val Loss: 0.3185\n","Epoch 56/100, Train Loss: 0.2730, Val Loss: 0.3175\n","Epoch 57/100, Train Loss: 0.2687, Val Loss: 0.3217\n","Epoch 58/100, Train Loss: 0.2750, Val Loss: 0.3160\n","Epoch 59/100, Train Loss: 0.2694, Val Loss: 0.3130\n","Epoch 60/100, Train Loss: 0.2670, Val Loss: 0.3166\n","Epoch 61/100, Train Loss: 0.2686, Val Loss: 0.3275\n","Epoch 62/100, Train Loss: 0.2646, Val Loss: 0.3189\n","Epoch 63/100, Train Loss: 0.2640, Val Loss: 0.3052\n","Epoch 64/100, Train Loss: 0.2660, Val Loss: 0.3253\n","Epoch 65/100, Train Loss: 0.2655, Val Loss: 0.3144\n","Epoch 66/100, Train Loss: 0.2675, Val Loss: 0.3226\n","Epoch 67/100, Train Loss: 0.2711, Val Loss: 0.3156\n","Epoch 68/100, Train Loss: 0.2656, Val Loss: 0.3114\n","Epoch 69/100, Train Loss: 0.2626, Val Loss: 0.3240\n","Epoch 70/100, Train Loss: 0.2614, Val Loss: 0.3385\n","Epoch 71/100, Train Loss: 0.2600, Val Loss: 0.3218\n","Epoch 72/100, Train Loss: 0.2603, Val Loss: 0.3254\n","Epoch 73/100, Train Loss: 0.2626, Val Loss: 0.3176\n","Epoch 74/100, Train Loss: 0.2636, Val Loss: 0.3155\n","Epoch 75/100, Train Loss: 0.2551, Val Loss: 0.3044\n","Epoch 76/100, Train Loss: 0.2557, Val Loss: 0.3201\n","Epoch 77/100, Train Loss: 0.2569, Val Loss: 0.3122\n","Epoch 78/100, Train Loss: 0.2579, Val Loss: 0.3150\n","Epoch 79/100, Train Loss: 0.2539, Val Loss: 0.3133\n","Epoch 80/100, Train Loss: 0.2519, Val Loss: 0.3157\n","Epoch 81/100, Train Loss: 0.2571, Val Loss: 0.3088\n","Epoch 82/100, Train Loss: 0.2555, Val Loss: 0.3084\n","Epoch 83/100, Train Loss: 0.2558, Val Loss: 0.3209\n","Epoch 84/100, Train Loss: 0.2608, Val Loss: 0.3145\n","Epoch 85/100, Train Loss: 0.2538, Val Loss: 0.3144\n","Epoch 86/100, Train Loss: 0.2514, Val Loss: 0.3246\n","Epoch 87/100, Train Loss: 0.2556, Val Loss: 0.3156\n","Epoch 88/100, Train Loss: 0.2529, Val Loss: 0.3083\n","Epoch 89/100, Train Loss: 0.2471, Val Loss: 0.3017\n","Epoch 90/100, Train Loss: 0.2522, Val Loss: 0.3172\n","Epoch 91/100, Train Loss: 0.2494, Val Loss: 0.3049\n","Epoch 92/100, Train Loss: 0.2471, Val Loss: 0.3134\n","Epoch 93/100, Train Loss: 0.2523, Val Loss: 0.3066\n","Epoch 94/100, Train Loss: 0.2480, Val Loss: 0.3057\n","Epoch 95/100, Train Loss: 0.2476, Val Loss: 0.3096\n","Epoch 96/100, Train Loss: 0.2438, Val Loss: 0.2913\n","Epoch 97/100, Train Loss: 0.2429, Val Loss: 0.3154\n","Epoch 98/100, Train Loss: 0.2426, Val Loss: 0.2953\n","Epoch 99/100, Train Loss: 0.2479, Val Loss: 0.2981\n","Epoch 100/100, Train Loss: 0.2418, Val Loss: 0.2999\n","Test MSE: 0.2407\n","Test RMSE: 0.4906\n","Test R²: 0.8180\n","Test MAE: 0.3393\n","Model saved as sparse_ft_linear_tuned_california.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Linear Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.7381 (p-value: 0.0366)\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 21:50:36,467] A new study created in memory with name: no-name-1917c520-ab21-46ca-9e55-9a245897a72a\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Tuning Hyperparameters for sparse FT Transformer with Piecewise Linear Embedding ===\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-04 21:52:48,114] Trial 0 finished with value: 0.5436476838588714 and parameters: {'d_token': 61, 'num_heads': 7, 'num_layers': 3, 'd_ffn': 161, 'lr': 0.004405752773034635, 'dropout': 0.3556196652959508, 'n_bins': 65}. Best is trial 0 with value: 0.5436476838588714.\n","[I 2025-03-04 21:59:28,696] Trial 1 finished with value: 0.31122311353683474 and parameters: {'d_token': 83, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 206, 'lr': 0.0004178731104848749, 'dropout': 0.3575829004136913, 'n_bins': 100}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:01:38,554] Trial 2 finished with value: 0.42817248821258547 and parameters: {'d_token': 108, 'num_heads': 7, 'num_layers': 1, 'd_ffn': 212, 'lr': 0.00177567629409646, 'dropout': 0.4478411234412837, 'n_bins': 47}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:03:25,853] Trial 3 finished with value: 1.449229679107666 and parameters: {'d_token': 61, 'num_heads': 2, 'num_layers': 3, 'd_ffn': 246, 'lr': 0.003690625399523865, 'dropout': 0.4802209417504936, 'n_bins': 18}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:04:51,489] Trial 4 finished with value: 0.5695518326759338 and parameters: {'d_token': 47, 'num_heads': 8, 'num_layers': 1, 'd_ffn': 183, 'lr': 0.009556994483164787, 'dropout': 0.255245052422777, 'n_bins': 37}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:07:34,084] Trial 5 finished with value: 1.0316225266456605 and parameters: {'d_token': 50, 'num_heads': 3, 'num_layers': 1, 'd_ffn': 212, 'lr': 0.0023211378338270274, 'dropout': 0.4829175876928009, 'n_bins': 90}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:11:22,085] Trial 6 finished with value: 0.3890440434217453 and parameters: {'d_token': 47, 'num_heads': 4, 'num_layers': 3, 'd_ffn': 222, 'lr': 0.003580029781374736, 'dropout': 0.27793585248601765, 'n_bins': 73}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:15:18,793] Trial 7 finished with value: 0.7859762763977051 and parameters: {'d_token': 114, 'num_heads': 8, 'num_layers': 2, 'd_ffn': 240, 'lr': 0.0056074142108425646, 'dropout': 0.44374828808380706, 'n_bins': 99}. Best is trial 1 with value: 0.31122311353683474.\n","[I 2025-03-04 22:22:37,145] Trial 8 finished with value: 0.3850935649871826 and parameters: {'d_token': 65, 'num_heads': 5, 'num_layers': 1, 'd_ffn': 216, 'lr': 0.0015728870359101527, 'dropout': 0.368773427662798, 'n_bins': 84}. Best is trial 1 with value: 0.31122311353683474.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value (validation loss): 0.3112\n","  Params:\n","    d_token: 83\n","    num_heads: 8\n","    num_layers: 2\n","    d_ffn: 206\n","    lr: 0.0004178731104848749\n","    dropout: 0.3575829004136913\n","    n_bins: 100\n","\n","=== Training sparse FT Transformer with Piecewise Linear Embedding (Tuned) ===\n","Epoch 1/100, Train Loss: 1.4883, Val Loss: 0.7834\n","Epoch 2/100, Train Loss: 0.6942, Val Loss: 0.7022\n","Epoch 3/100, Train Loss: 0.5004, Val Loss: 0.5640\n","Epoch 4/100, Train Loss: 0.4272, Val Loss: 0.5819\n","Epoch 5/100, Train Loss: 0.4069, Val Loss: 0.5234\n","Epoch 6/100, Train Loss: 0.3842, Val Loss: 0.5580\n","Epoch 7/100, Train Loss: 0.3673, Val Loss: 0.4899\n","Epoch 8/100, Train Loss: 0.3664, Val Loss: 0.4755\n","Epoch 9/100, Train Loss: 0.3506, Val Loss: 0.4563\n","Epoch 10/100, Train Loss: 0.3459, Val Loss: 0.4372\n","Epoch 11/100, Train Loss: 0.3463, Val Loss: 0.4406\n","Epoch 12/100, Train Loss: 0.3278, Val Loss: 0.4039\n","Epoch 13/100, Train Loss: 0.3235, Val Loss: 0.3972\n","Epoch 14/100, Train Loss: 0.3299, Val Loss: 0.4338\n","Epoch 15/100, Train Loss: 0.3171, Val Loss: 0.4431\n","Epoch 16/100, Train Loss: 0.3189, Val Loss: 0.4096\n","Epoch 17/100, Train Loss: 0.3116, Val Loss: 0.4184\n","Epoch 18/100, Train Loss: 0.3156, Val Loss: 0.3965\n","Epoch 19/100, Train Loss: 0.3099, Val Loss: 0.3766\n","Epoch 20/100, Train Loss: 0.2991, Val Loss: 0.3790\n","Epoch 21/100, Train Loss: 0.3199, Val Loss: 0.4236\n","Epoch 22/100, Train Loss: 0.3031, Val Loss: 0.3812\n","Epoch 23/100, Train Loss: 0.3024, Val Loss: 0.3679\n","Epoch 24/100, Train Loss: 0.2957, Val Loss: 0.3893\n","Epoch 25/100, Train Loss: 0.2922, Val Loss: 0.3631\n","Epoch 26/100, Train Loss: 0.2911, Val Loss: 0.3946\n","Epoch 27/100, Train Loss: 0.2906, Val Loss: 0.3707\n","Epoch 28/100, Train Loss: 0.2871, Val Loss: 0.3757\n","Epoch 29/100, Train Loss: 0.2837, Val Loss: 0.3612\n","Epoch 30/100, Train Loss: 0.2870, Val Loss: 0.3551\n","Epoch 31/100, Train Loss: 0.2893, Val Loss: 0.3664\n","Epoch 32/100, Train Loss: 0.2780, Val Loss: 0.3727\n","Epoch 33/100, Train Loss: 0.2791, Val Loss: 0.3916\n","Epoch 34/100, Train Loss: 0.2733, Val Loss: 0.3622\n","Epoch 35/100, Train Loss: 0.2769, Val Loss: 0.3925\n","Epoch 36/100, Train Loss: 0.2707, Val Loss: 0.3562\n","Epoch 37/100, Train Loss: 0.2729, Val Loss: 0.3713\n","Epoch 38/100, Train Loss: 0.2708, Val Loss: 0.3292\n","Epoch 39/100, Train Loss: 0.2702, Val Loss: 0.3513\n","Epoch 40/100, Train Loss: 0.2668, Val Loss: 0.3726\n","Epoch 41/100, Train Loss: 0.2662, Val Loss: 0.3660\n","Epoch 42/100, Train Loss: 0.2748, Val Loss: 0.3641\n","Epoch 43/100, Train Loss: 0.2638, Val Loss: 0.3751\n","Epoch 44/100, Train Loss: 0.2601, Val Loss: 0.3675\n","Epoch 45/100, Train Loss: 0.2638, Val Loss: 0.3455\n","Epoch 46/100, Train Loss: 0.2606, Val Loss: 0.3334\n","Epoch 47/100, Train Loss: 0.2569, Val Loss: 0.3616\n","Epoch 48/100, Train Loss: 0.2559, Val Loss: 0.3729\n","Epoch 49/100, Train Loss: 0.2580, Val Loss: 0.3738\n","Epoch 50/100, Train Loss: 0.2534, Val Loss: 0.3672\n","Epoch 51/100, Train Loss: 0.2546, Val Loss: 0.3601\n","Epoch 52/100, Train Loss: 0.2525, Val Loss: 0.3926\n","Epoch 53/100, Train Loss: 0.2516, Val Loss: 0.4330\n","Epoch 54/100, Train Loss: 0.2540, Val Loss: 0.3405\n","Early stopping at epoch 54\n","Test MSE: 0.2564\n","Test RMSE: 0.5064\n","Test R²: 0.8061\n","Test MAE: 0.3544\n","Model saved as sparse_ft_piecewise_tuned_california.pth\n","\n","=== Analyzing PFI vs Attention Correlation for Sparse Piecewise Embedding (Tuned) ===\n","Spearman Rank Correlation: 0.4286 (p-value: 0.2894)\n","\n","=== Comparison of Tuned Models ===\n","FT Transformer (Linear Tuned): RMSE=0.4885, R²=0.8195\n","FT Transformer (Piecewise Tuned): RMSE=0.5210, R²=0.7947\n","Sparse FT Transformer (Linear Tuned): RMSE=0.4906, R²=0.8180\n","Sparse FT Transformer (Piecewise Tuned): RMSE=0.5064, R²=0.8061\n","\n","=== Comparison of PFI-Attention Correlations (Tuned Models) ===\n","FT Transformer (Linear Tuned): ρ=0.8810, p-value=0.0039\n","FT Transformer (Piecewise Tuned): ρ=0.8571, p-value=0.0065\n","Sparse FT Transformer (Linear Tuned): ρ=0.7381, p-value=0.0366\n","Sparse FT Transformer (Piecewise Tuned): ρ=0.4286, p-value=0.2894\n","\n","Visualizations saved as 'model_comparison_california.png' and 'feature_importance_comparison_california.png'\n","Results saved as results_california.json\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","\n","def save_all_files_to_drive(folder_name='CA_Files'):\n","  \"\"\"Saves all files in the current Colab environment to a new folder in Google Drive.\n","\n","  Args:\n","    folder_name: The name of the folder to create in Google Drive. Defaults to 'Colab_Files'.\n","  \"\"\"\n","\n","  # Mount Google Drive\n","  drive.mount('/content/drive')\n","\n","  # Create the folder in Google Drive\n","  folder_path = os.path.join('/content/drive/My Drive', folder_name)\n","  os.makedirs(folder_path, exist_ok=True)\n","\n","  # Get a list of all files in the current directory\n","  files = os.listdir('.')\n","\n","  # Copy each file to the Google Drive folder\n","  for file in files:\n","    source_path = os.path.join('.', file)\n","    destination_path = os.path.join(folder_path, file)\n","    os.system(f'cp \"{source_path}\" \"{destination_path}\"')  # Using os.system for file copying\n","\n","  print(f\"All files saved to Google Drive: /content/drive/My Drive/{folder_name}\")\n","\n","save_all_files_to_drive()"],"metadata":{"id":"-YCEi0O8cest"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_all_files_to_drive()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpkWHpwiS6DM","executionInfo":{"status":"ok","timestamp":1741127686236,"user_tz":-60,"elapsed":15689,"user":{"displayName":"Aaron Fandrei","userId":"15626003384216174610"}},"outputId":"d33e290b-ef12-4eb0-b33e-5eae71da5568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","All files saved to Google Drive: /content/drive/My Drive/CA_Files\n"]}]}]}