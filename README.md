# sparseFTTransformer
Interpretability and Performance of FT Transformer with sparse Attention mechanism and piecewise linear embeddings.

The notebooks have been written in Google Colab. To reproduce the results please select the T4 GPU. After that, the code can be run as is.

